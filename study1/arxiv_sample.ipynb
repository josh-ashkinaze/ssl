{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.json_utils import JsonUtils\n",
    "from src.helpers import path2correct_loc\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging \n",
    "import os \n",
    "\n",
    "\n",
    "start_date = '2025-05-01'\n",
    "end_date = '2025-05-20'\n",
    "allowed_categories = [\"cs.AI\", \"cs.MA\"]\n",
    "allowed_categories_str = \"\".join(f\"{cat} \" for cat in allowed_categories).strip()\n",
    "\n",
    "logging.info(f\"Filtering ArXiv entries from {start_date} to {end_date} for categories: {allowed_categories_str}\")\n",
    "\n",
    "\n",
    "def is_valid(entry, allowed_categories=None, allowed_major_categories=None,\n",
    "             allowed_minor_categories=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Check if an ArXiv entry is valid based on categories and date range.\n",
    "    \"\"\"\n",
    "    # Category check\n",
    "    if any(x is not None for x in [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n",
    "        entry_categories = entry.get('categories', '')\n",
    "        if not entry_categories:\n",
    "            return False\n",
    "\n",
    "        entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "\n",
    "        if allowed_categories is not None:\n",
    "            if not any(cat in allowed_categories for cat in entry_cats):\n",
    "                return False\n",
    "\n",
    "        if allowed_major_categories is not None:\n",
    "            entry_majors = [cat.split('.')[0] if '.' in cat else cat for cat in entry_cats]\n",
    "            if not any(major in allowed_major_categories for major in entry_majors):\n",
    "                return False\n",
    "\n",
    "        if allowed_minor_categories is not None:\n",
    "            entry_minors = [cat.split('.')[1] if '.' in cat and len(cat.split('.')) > 1 else ''\n",
    "                           for cat in entry_cats]\n",
    "            entry_minors = [minor for minor in entry_minors if minor]\n",
    "            if not any(minor in allowed_minor_categories for minor in entry_minors):\n",
    "                return False\n",
    "\n",
    "    # Date check\n",
    "    if start_date is not None or end_date is not None:\n",
    "        update_date = entry.get('update_date', '')\n",
    "        if not update_date:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "\n",
    "            if start_date is not None:\n",
    "                start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                if entry_date < start_dt:\n",
    "                    return False\n",
    "\n",
    "            if end_date is not None:\n",
    "                end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "                if entry_date > end_dt:\n",
    "                    return False\n",
    "        except ValueError:\n",
    "            # Invalid date format\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "validation_criteria = partial(is_valid,\n",
    "                                    allowed_categories=allowed_categories,\n",
    "                                    start_date=start_date,\n",
    "                                    end_date=end_date)\n",
    "\n",
    "# dls to cache\n",
    "path = kagglehub.dataset_download(\"Cornell-University/arxiv/versions/234\")\n",
    "new_location = path2correct_loc(path, \"\")\n",
    "print(f\"New location: {new_location}\")\n",
    "\n",
    "fn = \"arxiv-metadata-oai-snapshot.json\"\n",
    "\n",
    "jutils = JsonUtils()\n",
    "\n",
    "\n",
    "jsons = jutils.read_and_filter_json_file(filename=fn, \n",
    "                                           validator_function=validation_criteria)\n",
    "\n",
    "output_fn = f\"../data/clean/arxiv_{start_date}_{end_date}_{allowed_categories_str}.jsonl\"\n",
    "\n",
    "with open(output_fn, 'w') as f:\n",
    "    for entry in jsons:\n",
    "        f.write(f\"{entry}\\n\")\n",
    "        \n",
    "print(f\"Filtered entries saved to {output_fn}\")\n",
    "logging.info(f\"Filtered entries saved to {output_fn}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89f18d52d54a5d4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"../data/clean/arxiv.json\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7a029a8fca004b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc00d1ee72dee920"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
