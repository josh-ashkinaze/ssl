{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-26T13:39:50.790044Z",
     "start_time": "2025-05-26T13:39:47.535144Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_path = \"../data/raw/arxiv_sample.csv\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4bcb57cfc8970b4"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/Cornell-University/arxiv?dataset_version_number=234...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.44G/1.44G [00:56<00:00, 27.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/joshash/.cache/kagglehub/datasets/Cornell-University/arxiv/versions/234\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def path2correct_loc(source_path, destination_path, copy_instead_of_move=False):\n",
    "    \"\"\"\n",
    "    Move or copy all files from source path to destination path.\n",
    "    \n",
    "    Args:\n",
    "        source_path (str): Path to the source files\n",
    "        destination_path (str): Relative path from current working directory where to move the files\n",
    "        copy_instead_of_move (bool): If True, copy files instead of moving them\n",
    "    \n",
    "    Returns:\n",
    "        str: Absolute path to the destination directory\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to Path objects for easier handling\n",
    "    source = Path(source_path)\n",
    "    # Make destination relative to current working directory\n",
    "    dest = Path.cwd() / destination_path\n",
    "    \n",
    "    # Check if source exists\n",
    "    if not source.exists():\n",
    "        raise FileNotFoundError(f\"Source path does not exist: {source_path}\")\n",
    "    \n",
    "    # Create destination directory if it doesn't exist\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all files in source directory (including subdirectories)\n",
    "    files_moved = 0\n",
    "    total_size = 0\n",
    "    \n",
    "    print(f\"{'Copying' if copy_instead_of_move else 'Moving'} files from {source} to {dest}\")\n",
    "    \n",
    "    # Walk through all files and subdirectories\n",
    "    for item in source.rglob('*'):\n",
    "        if item.is_file():\n",
    "            # Calculate relative path to preserve directory structure\n",
    "            relative_path = item.relative_to(source)\n",
    "            dest_file = dest / relative_path\n",
    "            \n",
    "            # Create subdirectories if needed\n",
    "            dest_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Move or copy the file\n",
    "            try:\n",
    "                if copy_instead_of_move:\n",
    "                    shutil.copy2(item, dest_file)\n",
    "                    action = \"Copied\"\n",
    "                else:\n",
    "                    shutil.move(str(item), str(dest_file))\n",
    "                    action = \"Moved\"\n",
    "                \n",
    "                file_size = dest_file.stat().st_size\n",
    "                total_size += file_size\n",
    "                files_moved += 1\n",
    "                \n",
    "                print(f\"{action}: {relative_path} ({file_size / (1024*1024):.2f} MB)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {item}: {e}\")\n",
    "    \n",
    "    print(f\"\\nCompleted! {files_moved} files {'copied' if copy_instead_of_move else 'moved'}\")\n",
    "    print(f\"Total size: {total_size / (1024*1024*1024):.2f} GB\")\n",
    "    print(f\"Files are now in: {dest.absolute()}\")\n",
    "    \n",
    "    return str(dest.absolute())\n",
    "\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"Cornell-University/arxiv\", )\n",
    "\n",
    "new_location = path2correct_loc(path, \"\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T13:45:33.896530Z",
     "start_time": "2025-05-26T13:44:13.984650Z"
    }
   },
   "id": "85f905054ce2be16",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random sampling 100 entries: 100%|██████████| 2735264/2735264 [00:38<00:00, 70170.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# jsons_fn = \"arxiv-metadata-oai-snapshot.json\"\n",
    "# \n",
    "# import json\n",
    "# import random\n",
    "# import json\n",
    "# import random\n",
    "# from tqdm import tqdm\n",
    "# \n",
    "# def sample_jsons(filename, n, method='first', seed=42):\n",
    "#     \"\"\"\n",
    "#     Sample N entries from a JSON lines file.\n",
    "#     \n",
    "#     Args:\n",
    "#         filename (str): Path to the JSON lines file\n",
    "#         n (int): Number of entries to sample\n",
    "#         method (str): Sampling method - 'first', 'random', or 'last'\n",
    "#         seed (int): Random seed for reproducible random sampling\n",
    "#     \n",
    "#     Returns:\n",
    "#         list: List of parsed JSON objects\n",
    "#     \"\"\"\n",
    "#     \n",
    "#     if method == 'first':\n",
    "#         # Simple: just read first n lines\n",
    "#         samples = []\n",
    "#         with open(filename, 'r', encoding='utf-8') as f:\n",
    "#             pbar = tqdm(desc=f\"Reading first {n} entries\", total=n)\n",
    "#             for i, line in enumerate(f):\n",
    "#                 if i >= n:\n",
    "#                     break\n",
    "#                 if line.strip():\n",
    "#                     samples.append(json.loads(line))\n",
    "#                     pbar.update(1)\n",
    "#             pbar.close()\n",
    "#         return samples\n",
    "#     \n",
    "#     elif method == 'last':\n",
    "#         # Use deque to keep last n entries\n",
    "#         from collections import deque\n",
    "#         samples = deque(maxlen=n)\n",
    "#         with open(filename, 'r', encoding='utf-8') as f:\n",
    "#             # Count total lines first for progress bar\n",
    "#             total_lines = sum(1 for line in f if line.strip())\n",
    "#             f.seek(0)  # Reset file pointer\n",
    "#             \n",
    "#             with tqdm(desc=f\"Reading for last {n} entries\", total=total_lines) as pbar:\n",
    "#                 for line in f:\n",
    "#                     if line.strip():\n",
    "#                         samples.append(json.loads(line))\n",
    "#                         pbar.update(1)\n",
    "#         return list(samples)\n",
    "#     \n",
    "#     elif method == 'random':\n",
    "#         # Set seed for reproducible results\n",
    "#         random.seed(seed)\n",
    "#         \n",
    "#         # Count total lines first for progress bar\n",
    "#         with open(filename, 'r', encoding='utf-8') as f:\n",
    "#             total_lines = sum(1 for line in f if line.strip())\n",
    "#         \n",
    "#         # Reservoir sampling for true random sample\n",
    "#         samples = []\n",
    "#         with open(filename, 'r', encoding='utf-8') as f:\n",
    "#             with tqdm(desc=f\"Random sampling {n} entries\", total=total_lines) as pbar:\n",
    "#                 line_count = 0\n",
    "#                 for line in f:\n",
    "#                     if not line.strip():\n",
    "#                         continue\n",
    "#                         \n",
    "#                     entry = json.loads(line)\n",
    "#                     line_count += 1\n",
    "#                     \n",
    "#                     if len(samples) < n:\n",
    "#                         samples.append(entry)\n",
    "#                     else:\n",
    "#                         j = random.randint(0, line_count - 1)\n",
    "#                         if j < n:\n",
    "#                             samples[j] = entry\n",
    "#                     \n",
    "#                     pbar.update(1)\n",
    "#         \n",
    "#         return samples\n",
    "#     \n",
    "#     else:\n",
    "#         raise ValueError(\"method must be 'first', 'last', or 'random'\")\n",
    "# \n",
    "# # Usage examples:\n",
    "# # sample_jsons(jsons_fn, 100)  # First 100 entries\n",
    "# # sample_jsons(jsons_fn, 100, 'random')  # Random 100 entries with default seed\n",
    "# # sample_jsons(jsons_fn, 100, 'random', seed=123)  # Random with custom seed\n",
    "# # sample_jsons(jsons_fn, 100, 'last')  # Last 100 entries\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# # Usage examples:\n",
    "# # sample_jsons(jsons_fn, 100)  # First 100 entries\n",
    "# # sample_jsons(jsons_fn, 100, 'random')  # Random 100 entries with default seed\n",
    "# sample = sample_jsons(jsons_fn, 100, 'random', seed=123)  # Random with custom seed\n",
    "# # sample_jsons(jsons_fn, 100, 'last')  # Last 100 entries\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:00:48.799478Z",
     "start_time": "2025-05-26T14:00:03.639492Z"
    }
   },
   "id": "874c69abf7a3d252",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sample_jsons() got an unexpected keyword argument 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 98\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m     97\u001B[39m \u001B[38;5;66;03m# Sample the data\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m98\u001B[39m sample = \u001B[43msample_jsons\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsons_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrandom\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m123\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Random with custom seed\u001B[39;00m\n\u001B[32m    100\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mSampled \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(sample)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m entries\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    102\u001B[39m \u001B[38;5;66;03m# Parse the sample\u001B[39;00m\n",
      "\u001B[31mTypeError\u001B[39m: sample_jsons() got an unexpected keyword argument 'seed'"
     ]
    }
   ],
   "source": [
    "# # ArXiv JSON Processing Script\n",
    "# # Run this in a Jupyter notebook cell\n",
    "# \n",
    "# \n",
    "# import json\n",
    "# from datetime import datetime\n",
    "# from pathlib import Path\n",
    "# \n",
    "# def parse_arxiv_entry(entry):\n",
    "#     \"\"\"\n",
    "#     Parse a single ArXiv JSON entry and extract required fields.\n",
    "#     \n",
    "#     Args:\n",
    "#         entry (dict): Single ArXiv paper dictionary\n",
    "#     \n",
    "#     Returns:\n",
    "#         dict: Dictionary with extracted fields\n",
    "#     \"\"\"\n",
    "#     # Get the latest version number from versions list\n",
    "#     version_no = None\n",
    "#     if entry.get('versions') and len(entry['versions']) > 0:\n",
    "#         # Versions are typically in chronological order, so last one is latest\n",
    "#         latest_version = entry['versions'][-1]\n",
    "#         version_no = latest_version.get('version', '').replace('v', '')\n",
    "#     \n",
    "#     return {\n",
    "#         'id': entry.get('id', ''),\n",
    "#         'title': entry.get('title', '').strip(),\n",
    "#         'authors_parsed': entry.get('authors_parsed', []),\n",
    "#         'submitter': entry.get('submitter', ''),\n",
    "#         'categories': entry.get('categories', ''),\n",
    "#         'abstract': entry.get('abstract', '').strip(),\n",
    "#         'doi': entry.get('doi', ''),\n",
    "#         'update_date': entry.get('update_date', ''),\n",
    "#         'version_no': version_no\n",
    "#     }\n",
    "# \n",
    "# def parse_json(entries):\n",
    "#     \"\"\"\n",
    "#     Parse multiple ArXiv JSON entries.\n",
    "#     \n",
    "#     Args:\n",
    "#         entries (list): List of ArXiv paper dictionaries\n",
    "#     \n",
    "#     Returns:\n",
    "#         list: List of parsed entries\n",
    "#     \"\"\"\n",
    "#     return [parse_arxiv_entry(entry) for entry in entries]\n",
    "# \n",
    "# def is_valid(entry, allowed_categories=None, start_date=None, end_date=None):\n",
    "#     \"\"\"\n",
    "#     Check if an ArXiv entry is valid based on categories and date range.\n",
    "#     Highly efficient - operates on raw dict without full parsing.\n",
    "#     \n",
    "#     Args:\n",
    "#         entry (dict): Raw ArXiv paper dictionary\n",
    "#         allowed_categories (list): List of allowed categories (None to skip check)\n",
    "#         start_date (str): Start date in YYYY-MM-DD format (None to skip check)\n",
    "#         end_date (str): End date in YYYY-MM-DD format (None to skip check)\n",
    "#     \n",
    "#     Returns:\n",
    "#         bool: True if entry passes all filters, False otherwise\n",
    "#     \"\"\"\n",
    "#     # Category check\n",
    "#     if allowed_categories is not None:\n",
    "#         entry_categories = entry.get('categories', '')\n",
    "#         if not entry_categories:\n",
    "#             return False\n",
    "#         \n",
    "#         entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "#         if not any(cat in allowed_categories for cat in entry_cats):\n",
    "#             return False\n",
    "#     \n",
    "#     if start_date is not None or end_date is not None:\n",
    "#         update_date = entry.get('update_date', '')\n",
    "#         if not update_date:\n",
    "#             return False\n",
    "#         \n",
    "#         try:\n",
    "#             entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "#             \n",
    "#             if start_date is not None:\n",
    "#                 start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "#                 if entry_date < start_dt:\n",
    "#                     return False\n",
    "#             \n",
    "#             if end_date is not None:\n",
    "#                 end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "#                 if entry_date > end_dt:\n",
    "#                     return False\n",
    "#                     \n",
    "#         except ValueError:\n",
    "#             return False\n",
    "#     \n",
    "#     return True\n",
    "# \n",
    "# # Sample the data\n",
    "# sample = sample_jsons(jsons_fn, 100, 'random', seed=123)  # Random with custom seed\n",
    "# \n",
    "# print(f\"Sampled {len(sample)} entries\")\n",
    "# \n",
    "# # Parse the sample\n",
    "# parsed_jsons = parse_json([i for i in sample])\n",
    "# \n",
    "# print(f\"Parsed {len(parsed_jsons)} entries\")\n",
    "# \n",
    "# # Show a sample parsed entry\n",
    "# if parsed_jsons:\n",
    "#     print(\"\\nSample parsed entry:\")\n",
    "#     entry = parsed_jsons[0]\n",
    "#     print(f\"ID: {entry['id']}\")\n",
    "#     print(f\"Title: {entry['title'][:80]}...\")\n",
    "#     print(f\"Categories: {entry['categories']}\")\n",
    "#     print(f\"Authors: {len(entry['authors_parsed'])} authors\")\n",
    "#     print(f\"DOI: {entry['doi']}\")\n",
    "#     print(f\"Update Date: {entry['update_date']}\")\n",
    "#     print(f\"Version: {entry['version_no']}\")\n",
    "#     print(f\"Abstract: {entry['abstract'][:150]}...\")\n",
    "# \n",
    "# # Optional: Show some statistics\n",
    "# print(f\"\\nStatistics:\")\n",
    "# print(f\"Total entries: {len(parsed_jsons)}\")\n",
    "# print(f\"Entries with DOI: {sum(1 for e in parsed_jsons if e['doi'])}\")\n",
    "# print(f\"Unique categories: {len(set(e['categories'] for e in parsed_jsons))}\")\n",
    "# \n",
    "# # Op"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:21:26.840559Z",
     "start_time": "2025-05-26T14:21:26.758455Z"
    }
   },
   "id": "abb2a9b9ee46c682",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_jsons)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:14:41.570306Z",
     "start_time": "2025-05-26T14:14:41.541987Z"
    }
   },
   "id": "b40a7a58a0749af7",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['astro-ph.HE', 'math.AP', 'hep-th',\n       'cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el',\n       'cs.NI cs.ET', 'quant-ph', 'cs.CV cs.RO', 'math.DG math.AP',\n       'stat.AP stat.ME', 'math.AG', 'hep-th gr-qc', 'math.DS',\n       'physics.plasm-ph', 'quant-ph physics.atom-ph',\n       'cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY', 'stat.ML cs.LG math.DG',\n       'physics.optics', 'cond-mat.str-el cond-mat.mtrl-sci',\n       'physics.data-an cond-mat.stat-mech nlin.PS physics.soc-ph',\n       'math.GR', 'cs.CV',\n       'cond-mat.mtrl-sci cond-mat.soft physics.optics', 'math.PR',\n       'cond-mat.str-el cond-mat.supr-con',\n       'cond-mat.mes-hall physics.atom-ph quant-ph', 'nucl-th hep-lat',\n       'astro-ph.HE astro-ph.CO', 'cs.LG cs.AI', 'q-bio.TO',\n       'cs.CL cs.AI cs.LG', 'math.HO', 'q-fin.ST cs.LG', 'hep-lat',\n       'physics.atom-ph', 'nucl-ex', 'cs.IT math.IT', 'cond-mat.supr-con',\n       'cs.NI', 'cs.RO', 'physics.comp-ph cs.LG hep-ph', 'astro-ph',\n       'astro-ph.HE astro-ph.CO gr-qc', 'cs.GT', 'hep-ex physics.ins-det',\n       'hep-ex', 'cond-mat.mes-hall cond-mat.str-el', 'nucl-th hep-ph',\n       'nlin.SI physics.class-ph', 'physics.optics cs.ET',\n       'astro-ph.GA astro-ph.CO astro-ph.SR',\n       'cond-mat.mes-hall quant-ph', 'cond-mat.stat-mech',\n       'cond-mat.quant-gas', 'cs.LO cs.PL', 'q-fin.TR q-fin.ST',\n       'stat.CO', 'hep-ph hep-lat', 'astro-ph.SR astro-ph.CO astro-ph.HE',\n       'physics.flu-dyn cs.NA math.NA', 'hep-ph', 'math.GM', 'cs.NE',\n       'math.CO', 'stat.ML cs.LG', 'eess.SY cs.SY', 'cs.HC',\n       'quant-ph cs.CC', 'math.ST stat.TH',\n       'cond-mat.str-el hep-th math-ph math.MP',\n       'quant-ph cond-mat.other',\n       'physics.app-ph cond-mat.mes-hall cond-mat.mtrl-sci physics.optics',\n       'cs.AI cs.CL cs.LG', 'cond-mat.mtrl-sci', 'hep-ph astro-ph',\n       'cs.LG stat.ML', 'math.FA', 'math.OA math.FA', 'math.QA',\n       'astro-ph.GA', 'cs.CG'], dtype=object)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['categories'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:15:01.741995Z",
     "start_time": "2025-05-26T14:15:01.734080Z"
    }
   },
   "id": "730379a146648b00",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cs_cats = {\n",
    "    \"cs.AI\": \"Artificial Intelligence\",\n",
    "    \"cs.AR\": \"Hardware Architecture\", \n",
    "    \"cs.CC\": \"Computational Complexity\",\n",
    "    \"cs.CE\": \"Computational Engineering, Finance, and Science\",\n",
    "    \"cs.CG\": \"Computational Geometry\",\n",
    "    \"cs.CL\": \"Computation and Language\",\n",
    "    \"cs.CR\": \"Cryptography and Security\",\n",
    "    \"cs.CV\": \"Computer Vision and Pattern Recognition\",\n",
    "    \"cs.CY\": \"Computers and Society\",\n",
    "    \"cs.DB\": \"Databases\",\n",
    "    \"cs.DC\": \"Distributed, Parallel, and Cluster Computing\",\n",
    "    \"cs.DL\": \"Digital Libraries\",\n",
    "    \"cs.DM\": \"Discrete Mathematics\",\n",
    "    \"cs.DS\": \"Data Structures and Algorithms\",\n",
    "    \"cs.ET\": \"Emerging Technologies\",\n",
    "    \"cs.FL\": \"Formal Languages and Automata Theory\",\n",
    "    \"cs.GL\": \"General Literature\",\n",
    "    \"cs.GR\": \"Graphics\",\n",
    "    \"cs.GT\": \"Computer Science and Game Theory\",\n",
    "    \"cs.HC\": \"Human-Computer Interaction\",\n",
    "    \"cs.IR\": \"Information Retrieval\",\n",
    "    \"cs.IT\": \"Information Theory\",\n",
    "    \"cs.LG\": \"Machine Learning\",\n",
    "    \"cs.LO\": \"Logic in Computer Science\",\n",
    "    \"cs.MA\": \"Multiagent Systems\",\n",
    "    \"cs.MM\": \"Multimedia\",\n",
    "    \"cs.MS\": \"Mathematical Software\",\n",
    "    \"cs.NA\": \"Numerical Analysis\",\n",
    "    \"cs.NE\": \"Neural and Evolutionary Computing\",\n",
    "    \"cs.NI\": \"Networking and Internet Architecture\",\n",
    "    \"cs.OH\": \"Other Computer Science\",\n",
    "    \"cs.OS\": \"Operating Systems\",\n",
    "    \"cs.PF\": \"Performance\",\n",
    "    \"cs.PL\": \"Programming Languages\",\n",
    "    \"cs.RO\": \"Robotics\",\n",
    "    \"cs.SC\": \"Symbolic Computation\",\n",
    "    \"cs.SD\": \"Sound\",\n",
    "    \"cs.SE\": \"Software Engineering\",\n",
    "    \"cs.SI\": \"Social and Information Networks\",\n",
    "    \"cs.SY\": \"Systems and Control\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:18:53.107336Z",
     "start_time": "2025-05-26T14:18:53.087599Z"
    }
   },
   "id": "b46cf133a764e9d5",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Random sampling 100 entries: 100%|██████████| 2735264/2735264 [00:38<00:00, 70782.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 100 entries\n",
      "Sample parsed entry:\n",
      "  id: 2308.09518\n",
      "  title: Efficient Modeling of Heavy Cosmic Rays Propagation in Evolving\n",
      "  Astrophysical Environments\n",
      "  authors_parsed: [['Merten', 'Lukas', ''], ['Da Vela', 'Paolo', ''], ['Reimer', 'Anita', ''], ['Boughelilba', 'Margot', ''], ['Lundquist', 'Jon Paul', ''], ['Vorobiov', 'Serguei', ''], ['Tjus', 'Julia Becker', '']]\n",
      "  submitter: Lukas Merten\n",
      "  categories: astro-ph.HE\n",
      "  abstract: We present a new energy transport code that models the time dependent and\n",
      "non-linear evolution of spectra of cosmic-ray nuclei, their secondaries, and\n",
      "photon target fields. The software can inject an arbitrary chemical composition\n",
      "including heavy elements up to iron nuclei. Energy losses and secondary\n",
      "production due to interactions of cosmic ray nuclei, secondary mesons, leptons,\n",
      "or gamma-rays with a target photon field are available for all relevant\n",
      "processes, e.g., photo-meson production, photo disintegration, synchrotron\n",
      "radiation, Inverse Compton scattering, and more. The resulting x-ray fluxes can\n",
      "be fed back into the simulation chain to correct the initial photon targets,\n",
      "resulting in a non-linear treatment of the energy transport. The modular\n",
      "structure of the code facilitates simple extension of interaction or target\n",
      "field models. We will show how the software can be used to improve predictions\n",
      "of observables in various astrophysical sources such as jetted active galactic\n",
      "nuclei (AGN). Since the software can model the propagation of heavy\n",
      "ultrahigh-energy cosmic rays inside the source it can precisely predict the\n",
      "chemical composition at the source. This will also refine predictions of\n",
      "neutrino emissions - they strongly depend on the chemical composition. This\n",
      "helps in the future to optimize the selection and analyses of data from the\n",
      "IceCube neutrino observatory with the aim to enhance the sensitivity of IceCube\n",
      "and reduce the number of trial factors.\n",
      "  doi: 10.22323/1.444.1466\n",
      "  update_date: 2023-08-21\n",
      "  version_no: 1\n",
      "\n",
      "Filtering examples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PosixPath' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 216\u001B[39m\n\u001B[32m    213\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mFiltering examples:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    215\u001B[39m \u001B[38;5;66;03m# Filter by categories\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m valid_entries = [entry \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m jsons \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_valid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mentry\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallowed_categories\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mastro-ph.HE\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhep-ph\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[32m    217\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mEntries with allowed categories: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(valid_entries)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    219\u001B[39m \u001B[38;5;66;03m# Filter by date range\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 145\u001B[39m, in \u001B[36mis_valid\u001B[39m\u001B[34m(entry, allowed_categories, allowed_major_categories, allowed_minor_categories, start_date, end_date)\u001B[39m\n\u001B[32m    143\u001B[39m \u001B[38;5;66;03m# Category check\u001B[39;00m\n\u001B[32m    144\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n\u001B[32m--> \u001B[39m\u001B[32m145\u001B[39m     entry_categories = \u001B[43mentry\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m(\u001B[33m'\u001B[39m\u001B[33mcategories\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    146\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m entry_categories:\n\u001B[32m    147\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[31mAttributeError\u001B[39m: 'PosixPath' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def sample_jsons(filename, n, method='first', seed=42):\n",
    "    \"\"\"\n",
    "    Sample N entries from a JSON lines file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the JSON lines file\n",
    "        n (int): Number of entries to sample\n",
    "        method (str): Sampling method - 'first', 'random', or 'last'\n",
    "        seed (int): Random seed for reproducible random sampling\n",
    "        validation_function (function or None): If you pass this in, it only returns things that pass a validation function. This function must take in an arxiv dict and output True or False (default: None)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of parsed JSON objects\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'first':\n",
    "        # Simple: just read first n lines\n",
    "        samples = []\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            pbar = tqdm(desc=f\"Reading first {n} entries\", total=n)\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= n:\n",
    "                    break\n",
    "                if line.strip():\n",
    "                    samples.append(json.loads(line))\n",
    "                    pbar.update(1)\n",
    "            pbar.close()\n",
    "        return samples\n",
    "    \n",
    "    elif method == 'last':\n",
    "        # Use deque to keep last n entries\n",
    "        from collections import deque\n",
    "        samples = deque(maxlen=n)\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            # Count total lines first for progress bar\n",
    "            total_lines = sum(1 for line in f if line.strip())\n",
    "            f.seek(0)  # Reset file pointer\n",
    "            \n",
    "            with tqdm(desc=f\"Reading for last {n} entries\", total=total_lines) as pbar:\n",
    "                for line in f:\n",
    "                    if line.strip():\n",
    "                        samples.append(json.loads(line))\n",
    "                        pbar.update(1)\n",
    "        return list(samples)\n",
    "    \n",
    "    elif method == 'random':\n",
    "        # Set seed for reproducible results\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Count total lines first for progress bar\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            total_lines = sum(1 for line in f if line.strip())\n",
    "        \n",
    "        # Reservoir sampling for true random sample\n",
    "        samples = []\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            with tqdm(desc=f\"Random sampling {n} entries\", total=total_lines) as pbar:\n",
    "                line_count = 0\n",
    "                for line in f:\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                        \n",
    "                    entry = json.loads(line)\n",
    "                    line_count += 1\n",
    "                    \n",
    "                    if len(samples) < n:\n",
    "                        samples.append(entry)\n",
    "                    else:\n",
    "                        j = random.randint(0, line_count - 1)\n",
    "                        if j < n:\n",
    "                            samples[j] = entry\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"method must be 'first', 'last', or 'random'\")\n",
    "\n",
    "\n",
    "def parse_arxiv_entry(entry):\n",
    "    \"\"\"\n",
    "    Parse a single ArXiv JSON entry and extract required fields.\n",
    "    \n",
    "    Args:\n",
    "        entry (dict): Single ArXiv paper dictionary\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary with extracted fields\n",
    "    \"\"\"\n",
    "    # Get the latest version number from versions list\n",
    "    version_no = None\n",
    "    if entry.get('versions') and len(entry['versions']) > 0:\n",
    "        # Versions are typically in chronological order, so last one is latest\n",
    "        latest_version = entry['versions'][-1]\n",
    "        version_no = latest_version.get('version', '').replace('v', '')\n",
    "    \n",
    "    return {\n",
    "        'id': entry.get('id', ''),\n",
    "        'title': entry.get('title', '').strip(),\n",
    "        'authors_parsed': entry.get('authors_parsed', []),\n",
    "        'submitter': entry.get('submitter', ''),\n",
    "        'categories': entry.get('categories', ''),\n",
    "        'abstract': entry.get('abstract', '').strip(),\n",
    "        'doi': entry.get('doi', ''),\n",
    "        'update_date': entry.get('update_date', ''),\n",
    "        'version_no': version_no\n",
    "    }\n",
    "\n",
    "def parse_json(entries):\n",
    "    \"\"\"\n",
    "    Parse multiple ArXiv JSON entries.\n",
    "    \n",
    "    Args:\n",
    "        entries (list): List of ArXiv paper dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        list: List of parsed entries\n",
    "    \"\"\"\n",
    "    return [parse_arxiv_entry(entry) for entry in entries]\n",
    "\n",
    "def is_valid(entry, allowed_categories=None, allowed_major_categories=None, \n",
    "             allowed_minor_categories=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Check if an ArXiv entry is valid based on categories and date range.\n",
    "    Highly efficient - operates on raw dict without full parsing.\n",
    "    \n",
    "    Args:\n",
    "        entry (dict): Raw ArXiv paper dictionary\n",
    "        allowed_categories (list): List of allowed full categories like ['cs.AI', 'math.ST'] (None to skip check)\n",
    "        allowed_major_categories (list): List of allowed major categories like ['cs', 'math'] (None to skip check)\n",
    "        allowed_minor_categories (list): List of allowed minor categories like ['AI', 'ST'] (None to skip check)\n",
    "        start_date (str): Start date in YYYY-MM-DD format (None to skip check)\n",
    "        end_date (str): End date in YYYY-MM-DD format (None to skip check)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if entry passes all filters, False otherwise\n",
    "    \"\"\"\n",
    "    # Category check\n",
    "    if any(x is not None for x in [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n",
    "        entry_categories = entry.get('categories', '')\n",
    "        if not entry_categories:\n",
    "            return False\n",
    "        \n",
    "        # Split categories and check if any match allowed categories\n",
    "        entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "        \n",
    "        # Check full categories (exact match)\n",
    "        if allowed_categories is not None:\n",
    "            if not any(cat in allowed_categories for cat in entry_cats):\n",
    "                return False\n",
    "        \n",
    "        # Check major categories (before the dot)\n",
    "        if allowed_major_categories is not None:\n",
    "            entry_majors = [cat.split('.')[0] if '.' in cat else cat for cat in entry_cats]\n",
    "            if not any(major in allowed_major_categories for major in entry_majors):\n",
    "                return False\n",
    "        \n",
    "        # Check minor categories (after the dot)\n",
    "        if allowed_minor_categories is not None:\n",
    "            entry_minors = [cat.split('.')[1] if '.' in cat and len(cat.split('.')) > 1 else '' \n",
    "                           for cat in entry_cats]\n",
    "            entry_minors = [minor for minor in entry_minors if minor]  # Remove empty strings\n",
    "            if not any(minor in allowed_minor_categories for minor in entry_minors):\n",
    "                return False\n",
    "    \n",
    "    # Date check\n",
    "    if start_date is not None or end_date is not None:\n",
    "        update_date = entry.get('update_date', '')\n",
    "        if not update_date:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert update_date to datetime for comparison\n",
    "            entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "            \n",
    "            if start_date is not None:\n",
    "                start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                if entry_date < start_dt:\n",
    "                    return False\n",
    "            \n",
    "            if end_date is not None:\n",
    "                end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "                if entry_date > end_dt:\n",
    "                    return False\n",
    "                    \n",
    "        except ValueError:\n",
    "            # Invalid date format\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "    \n",
    "# 1. Get jsons\n",
    "sample = sample_jsons(jsons_fn, 100, 'random', seed=123)  # Random with custom seed\n",
    "\n",
    "# 2. Parse jsons\n",
    "parsed_jsons = parse_json([i for i in sample])\n",
    "\n",
    "print(f\"Parsed {len(parsed_jsons)} entries\")\n",
    "print(\"Sample parsed entry:\")\n",
    "if parsed_jsons:\n",
    "    entry = parsed_jsons[0]\n",
    "    for key, value in entry.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Example of filtering with is_valid\n",
    "print(\"\\nFiltering examples:\")\n",
    "\n",
    "# Filter by categories\n",
    "valid_entries = [entry for entry in jsons if is_valid(entry, allowed_categories=['astro-ph.HE', 'hep-ph'])]\n",
    "print(f\"Entries with allowed categories: {len(valid_entries)}\")\n",
    "\n",
    "# Filter by date range\n",
    "valid_entries = [entry for entry in jsons if is_valid(entry, start_date='2023-01-01', end_date='2023-12-31')]\n",
    "print(f\"Entries in 2023: {len(valid_entries)}\")\n",
    "\n",
    "# Combined filter\n",
    "valid_entries = [entry for entry in jsons if is_valid(\n",
    "    entry, \n",
    "    allowed_categories=['astro-ph.HE'], \n",
    "    start_date='2023-01-01'\n",
    ")]\n",
    "print(f\"Entries with astro-ph.HE category from 2023: {len(valid_entries)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:22:35.913169Z",
     "start_time": "2025-05-26T14:21:47.925259Z"
    }
   },
   "id": "5d1cfdf3e57a0e6d",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'id': '2308.09518',\n  'title': 'Efficient Modeling of Heavy Cosmic Rays Propagation in Evolving\\n  Astrophysical Environments',\n  'authors_parsed': [['Merten', 'Lukas', ''],\n   ['Da Vela', 'Paolo', ''],\n   ['Reimer', 'Anita', ''],\n   ['Boughelilba', 'Margot', ''],\n   ['Lundquist', 'Jon Paul', ''],\n   ['Vorobiov', 'Serguei', ''],\n   ['Tjus', 'Julia Becker', '']],\n  'submitter': 'Lukas Merten',\n  'categories': 'astro-ph.HE',\n  'abstract': 'We present a new energy transport code that models the time dependent and\\nnon-linear evolution of spectra of cosmic-ray nuclei, their secondaries, and\\nphoton target fields. The software can inject an arbitrary chemical composition\\nincluding heavy elements up to iron nuclei. Energy losses and secondary\\nproduction due to interactions of cosmic ray nuclei, secondary mesons, leptons,\\nor gamma-rays with a target photon field are available for all relevant\\nprocesses, e.g., photo-meson production, photo disintegration, synchrotron\\nradiation, Inverse Compton scattering, and more. The resulting x-ray fluxes can\\nbe fed back into the simulation chain to correct the initial photon targets,\\nresulting in a non-linear treatment of the energy transport. The modular\\nstructure of the code facilitates simple extension of interaction or target\\nfield models. We will show how the software can be used to improve predictions\\nof observables in various astrophysical sources such as jetted active galactic\\nnuclei (AGN). Since the software can model the propagation of heavy\\nultrahigh-energy cosmic rays inside the source it can precisely predict the\\nchemical composition at the source. This will also refine predictions of\\nneutrino emissions - they strongly depend on the chemical composition. This\\nhelps in the future to optimize the selection and analyses of data from the\\nIceCube neutrino observatory with the aim to enhance the sensitivity of IceCube\\nand reduce the number of trial factors.',\n  'doi': '10.22323/1.444.1466',\n  'update_date': '2023-08-21',\n  'version_no': '1'},\n {'id': 'math/0511038',\n  'title': 'Rough solutions of a Schroedinger - Benjamin - Ono system',\n  'authors_parsed': [['Pecher', 'Hartmut', '']],\n  'submitter': 'Hartmut Pecher',\n  'categories': 'math.AP',\n  'abstract': 'The Cauchy problem for a coupled Schroedinger and Benjamin - Ono system is\\nshown to be globally well-posed for a class of data without finite energy. The\\nproof uses the I-method introduced by Colliander, Keel, Staffilani, Takaoka,\\nand Tao.',\n  'doi': None,\n  'update_date': '2007-05-23',\n  'version_no': '1'},\n {'id': '1801.10506',\n  'title': 'Invariant Operators, Orthogonal Bases and Correlators in General Tensor\\n  Models',\n  'authors_parsed': [['Diaz', 'Pablo', ''], ['Rey', 'Soo-Jong', '']],\n  'submitter': 'Pablo Diaz Benito',\n  'categories': 'hep-th',\n  'abstract': 'We study invariant operators in general tensor models. We show that\\nrepresentation theory provides an efficient framework to count and classify\\ninvariants in tensor models. In continuation and completion of our earlier\\nwork, we present two natural ways of counting invariants, one for arbitrary\\nrank of the group and another valid for large rank. We construct basis of\\ninvariant operators based on the counting, and compute correlators of their\\nelements. The basis associated with finite rank diagonalizes two-point\\nfunction. It is analogous to the restricted Schur basis used in matrix models.\\nWe show that the constructions get almost identical as we swap the\\nLittlewood-Richardson numbers in multi-matrix models with Kronecker\\ncoefficients in general tensor models. We explore this parallelism between\\nmatrix model and tensor model in depth from the perspective of representation\\ntheory and comment on several ideas for future investigation.',\n  'doi': '10.1016/j.nuclphysb.2018.05.013',\n  'update_date': '2018-07-13',\n  'version_no': '4'},\n {'id': '2407.06659',\n  'title': 'The quantum metric of electrons with spin-momentum locking',\n  'authors_parsed': [['Sala', 'Giacomo', ''],\n   ['Mercaldo', 'Maria Teresa', ''],\n   ['Domi', 'Klevis', ''],\n   ['Gariglio', 'Stefano', ''],\n   ['Cuoco', 'Mario', ''],\n   ['Ortix', 'Carmine', ''],\n   ['Caviglia', 'Andrea D.', '']],\n  'submitter': 'Giacomo Sala',\n  'categories': 'cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.str-el',\n  'abstract': 'Quantum materials are characterized by electromagnetic responses\\nintrinsically linked to the geometry and topology of the electronic\\nwavefunctions. These properties are encoded in the quantum metric and Berry\\ncurvature. While Berry curvature-mediated transport effects such as the\\nanomalous and nonlinear Hall effects have been identified in several magnetic\\nand nonmagnetic systems, quantum metric-induced transport phenomena remain\\nlimited to topological antiferromagnets. Here we show that spin-momentum\\nlocking -- a general characteristic of the electronic states at surfaces and\\ninterfaces of spin-orbit coupled materials -- leads to a finite quantum metric.\\nThis metric activates a nonlinear in-plane magnetoresistance that we measure\\nand electrically control in 111-oriented LaAlO$_3$/SrTiO$_3$ interfaces. These\\nfindings demonstrate the existence of quantum metric effects in a vast class of\\nmaterials and provide new strategies to design functionalities based on the\\nquantum geometry.',\n  'doi': None,\n  'update_date': '2024-10-02',\n  'version_no': '2'},\n {'id': '2407.19739',\n  'title': 'Nomadic Non-Public Networks for 6G: Use Cases and Key Performance\\n  Indicators',\n  'authors_parsed': [['Lindenschmitt', 'Daniel', ''],\n   ['Veith', 'Benedikt', ''],\n   ['Alam', 'Khurshid', ''],\n   ['Daurembekova', 'Ainur', ''],\n   ['Gundall', 'Michael', ''],\n   ['Habibi', 'Mohammad Asif', ''],\n   ['Han', 'Bin', ''],\n   ['Krummacker', 'Dennis', ''],\n   ['Rosemann', 'Philipp', ''],\n   ['Schotten', 'Hans D.', '']],\n  'submitter': 'Daniel Lindenschmitt',\n  'categories': 'cs.NI cs.ET',\n  'abstract': 'The landscape of wireless communication systems is evolving rapidly, with a\\npivotal role envisioned for dynamic network structures and self-organizing\\nnetworks in upcoming technologies like the 6G mobile communications standard.\\nThis evolution is fueled by the growing demand from diverse sectors, including\\nindustry, manufacturing, agriculture, and the public sector, each with\\nincreasingly specific requirements. The establishment of non-public networks in\\nthe current 5G standard has laid a foundation, enabling independent operation\\nwithin certain frequencies and local limitations, notably for Internet of\\nThings applications. This paper explores the progression from non-public\\nnetworks to nomadic non-public networks and their significance in the context\\nof the forthcoming 6G era.\\n  Building on existing work in dynamic network structures, non-public networks\\nregulations, and alternative technological solutions, this paper introduces\\nspecific use cases enhanced by nomadic networks. In addition, relevant Key\\nPerformance Indicators are discussed on the basis of the presented use cases.\\nThese serve as a starting point for the definition of requirement clusters and\\nthus for a evaluation metric of nomadic non-public networks. This work lays the\\ngroundwork for understanding the potential of nomadic non-public networks in\\nthe dynamic landscape of 6G wireless communication systems.',\n  'doi': None,\n  'update_date': '2024-08-06',\n  'version_no': '2'},\n {'id': 'quant-ph/0112140',\n  'title': 'Entangled-Photon Generation from Parametric Down-Conversion in Media\\n  with Inhomogeneous Nonlinearity',\n  'authors_parsed': [['Di Giuseppe', 'Giovanni', ''],\n   ['Atature', 'Mete', ''],\n   ['Shaw', 'Matthew D.', ''],\n   ['Sergienko', 'Alexander V.', ''],\n   ['Saleh', 'Bahaa E. A.', ''],\n   ['Teich', 'Malvin C.', '']],\n  'submitter': 'Mete Atature',\n  'categories': 'quant-ph',\n  'abstract': 'We develop and experimentally verify a theory of Type-II spontaneous\\nparametric down-conversion (SPDC) in media with inhomogeneous distributions of\\nsecond-order nonlinearity. As a special case, we explore interference effects\\nfrom SPDC generated in a cascade of two bulk crystals separated by an air gap.\\nThe polarization quantum-interference pattern is found to vary strongly with\\nthe spacing between the two crystals. This is found to be a cooperative effect\\ndue to two mechanisms: the chromatic dispersion of the medium separating the\\ncrystals and spatiotemporal effects which arise from the inclusion of\\ntransverse wave vectors. These effects provide two concomitant avenues for\\ncontrolling the quantum state generated in SPDC. We expect these results to be\\nof interest for the development of quantum technologies and the generation of\\nSPDC in periodically varying nonlinear materials.',\n  'doi': '10.1103/PhysRevA.66.013801',\n  'update_date': '2019-10-18',\n  'version_no': '1'},\n {'id': '2410.01618',\n  'title': 'SGBA: Semantic Gaussian Mixture Model-Based LiDAR Bundle Adjustment',\n  'authors_parsed': [['Ji', 'Xingyu', ''],\n   ['Yuan', 'Shenghai', ''],\n   ['Li', 'Jianping', ''],\n   ['Yin', 'Pengyu', ''],\n   ['Cao', 'Haozhi', ''],\n   ['Xie', 'Lihua', '']],\n  'submitter': 'Shenghai Yuan',\n  'categories': 'cs.CV cs.RO',\n  'abstract': 'LiDAR bundle adjustment (BA) is an effective approach to reduce the drifts in\\npose estimation from the front-end. Existing works on LiDAR BA usually rely on\\npredefined geometric features for landmark representation. This reliance\\nrestricts generalizability, as the system will inevitably deteriorate in\\nenvironments where these specific features are absent. To address this issue,\\nwe propose SGBA, a LiDAR BA scheme that models the environment as a semantic\\nGaussian mixture model (GMM) without predefined feature types. This approach\\nencodes both geometric and semantic information, offering a comprehensive and\\ngeneral representation adaptable to various environments. Additionally, to\\nlimit computational complexity while ensuring generalizability, we propose an\\nadaptive semantic selection framework that selects the most informative\\nsemantic clusters for optimization by evaluating the condition number of the\\ncost function. Lastly, we introduce a probabilistic feature association scheme\\nthat considers the entire probability density of assignments, which can manage\\nuncertainties in measurement and initial pose estimation. We have conducted\\nvarious experiments and the results demonstrate that SGBA can achieve accurate\\nand robust pose refinement even in challenging scenarios with low-quality\\ninitial pose estimation and limited geometric features. We plan to open-source\\nthe work for the benefit of the community https://github.com/Ji1Xinyu/SGBA.',\n  'doi': '10.1109/LRA.2024.3479699',\n  'update_date': '2025-04-07',\n  'version_no': '2'},\n {'id': '0907.0862',\n  'title': 'Backwards uniqueness of the mean curvature flow',\n  'authors_parsed': [['Huang', 'Hong', '']],\n  'submitter': 'Hong Huang',\n  'categories': 'math.DG math.AP',\n  'abstract': 'In this note we prove the backwards uniqueness of the mean curvature flow for\\n(codimension one) hypersurfaces in a Euclidean space. More precisely, let $F_t,\\n\\\\widetilde{F}_t:M^n \\\\rightarrow \\\\mathbb{R}^{n+1}$ be two complete solutions of\\nthe mean curvature flow on $M^n \\\\times [0,T]$ with bounded second fundamental\\nforms. Suppose $F_T=\\\\widetilde{F}_T$, then $F_t=\\\\widetilde{F}_t$ on $M^n \\\\times\\n[0,T]$. This is an analog of a result of Kotschwar on the Ricci flow.',\n  'doi': '10.1007/s10711-019-00424-6',\n  'update_date': '2019-01-10',\n  'version_no': '4'},\n {'id': '1908.00823',\n  'title': 'Generalised Joint Regression for Count Data with a Focus on Modelling\\n  Football Matches',\n  'authors_parsed': [['van der Wurp', 'Hendrik', ''],\n   ['Groll', 'Andreas', ''],\n   ['Kneib', 'Thomas', ''],\n   ['Marra', 'Giampiero', ''],\n   ['Radice', 'Rosalba', '']],\n  'submitter': 'Hendrik van der Wurp',\n  'categories': 'stat.AP stat.ME',\n  'abstract': \"We propose a versatile joint regression framework for count responses. The\\nmethod is implemented in the R add-on package GJRM and allows for modelling\\nlinear and non-linear dependence through the use of several copulae. Moreover,\\nthe parameters of the marginal distributions of the count responses and of the\\ncopula can be specified as flexible functions of covariates. Motivated by a\\nfootball application, we also discuss an extension which forces the regression\\ncoefficients of the marginal (linear) predictors to be equal via a suitable\\npenalisation. Model fitting is based on a trust region algorithm which\\nestimates simultaneously all the parameters of the joint models. We investigate\\nthe proposal's empirical performance in two simulation studies, the first one\\ndesigned for arbitrary count data, the other one reflecting football-specific\\nsettings. Finally, the method is applied to FIFA World Cup data, showing its\\ncompetitiveness to the standard approach with regard to predictive performance.\",\n  'doi': None,\n  'update_date': '2019-08-22',\n  'version_no': '2'},\n {'id': '1207.2282',\n  'title': 'On an equivariant analogue of the monodromy zeta function',\n  'authors_parsed': [['Gusein-Zade', 'Sabir M.', '']],\n  'submitter': 'Sabir M. Gusein-Zade',\n  'categories': 'math.AG',\n  'abstract': \"We offer an equivariant analogue of the monodromy zeta function of a germ\\ninvariant with respect to an action of finite group G as an element of the\\nGrothendieck ring of finite (Z x G)-sets. We formulate equivariant analogues of\\nthe Sebastiani-Thom theorem and of the A'Campo formula.\",\n  'doi': None,\n  'update_date': '2012-07-11',\n  'version_no': '1'},\n {'id': '1704.05919',\n  'title': 'Black Holes, Dark Wormholes and Solitons in f(T) Gravities',\n  'authors_parsed': [['Mai', 'Zhan-Feng', ''], ['Lu', 'H.', '']],\n  'submitter': 'Zhan-Feng Mai',\n  'categories': 'hep-th gr-qc',\n  'abstract': 'By choosing an appropriate vielbein basis, we obtain a class of\\nspherically-symmetric solutions in $f(T)$ gravities. The solutions are\\nasymptotic to Minkowski spacetimes with leading falloffs the same as those of\\nthe Schwarzschild black hole. In general, these solutions have branch-cut\\nsingularities in the middle. For appropriately chosen $f(T)$ functions,\\nextremal black holes can also emerge. Furthermore, we obtain wormhole\\nconfigurations whose spatial section is analogous to an Ellis wormhole, but\\n$-g_{tt}$ runs from 0 to 1 as the proper radial coordinate runs from $-\\\\infty$\\nto $+\\\\infty$. Thus a signal sent from $-\\\\infty$ to $+\\\\infty$ through the\\nwormhole will be infinitely red-shifted. We call such a spacetime configuration\\na dark wormhole. By introducing a bare cosmological constant $\\\\Lambda_0$, we\\nconstruct smooth solitons that are asymptotic to local AdS with an effective\\n$\\\\Lambda_{\\\\rm eff}$. In the middle of bulk, the soliton metric behaves like the\\nAdS of bare $\\\\Lambda_0$ in global coordinates. We also embed AdS planar and\\nLifshitz black holes in $f(T)$ gravities. Finally we couple the Maxwell field\\nto the $f(T)$ theories and construct electrically-charged solutions.',\n  'doi': '10.1103/PhysRevD.95.124024',\n  'update_date': '2017-06-21',\n  'version_no': '2'},\n {'id': '2505.07192',\n  'title': 'Bifurcations of synchronized solutions in a continuum limit of the\\n  Kuramoto model with two-mode interaction depending on two graphs',\n  'authors_parsed': [['Yagasaki', 'Kazuyuki', '']],\n  'submitter': 'Kazuyuki Yagasaki',\n  'categories': 'math.DS',\n  'abstract': \"We study bifurcations of the completely synchronized state in a continuum\\nlimit (CL) for the Kuramoto model (KM) of identical oscillators with two-mode\\ninteraction depending on two graphs. Here one of the graphs is uniform but may\\nbe deterministic dense, random dense or random sparse, and the other is a\\ndeterministic finite nearest neighbor. We use the center manifold reduction\\ntechnique, which is a standard one in dynamical systems, and prove that the CL\\nsuffers bifurcations at which the one-parameter family of completely\\nsynchronized state becomes unstable and a stable two-parameter family of\\n$\\\\ell$-humped sinusoidal shape stationary solutions ($\\\\ell\\\\ge 2$) appears,\\nwhere $n$ represents the node number. This contrasts the author's recent result\\non the classical KM in which bifurcation behavior in its CL is very different\\nfrom ones in the KM and difficult to explain by standard techniques in\\ndynamical systems such as the center manifold reduction. Moreover, similar\\nbifurcation behavior is shown to occur in the KM, based on the previous\\nfundamental results. The occurrence of such bifurcations were suggested by\\nnumerical simulations for the deterministic graphs in a previous study. We also\\ndemonstrate our theoretical results by numerical simulations for the KM with\\nthe zero natural frequency.\",\n  'doi': None,\n  'update_date': '2025-05-13',\n  'version_no': '1'},\n {'id': '2006.04545',\n  'title': 'Rotating vortices in two-dimensional inhomogeneous strongly coupled\\n  dusty plasmas: shear and spiral-density waves',\n  'authors_parsed': [['Dharodi', 'Vikram S.', '']],\n  'submitter': 'Vikram Singh Dharodi',\n  'categories': 'physics.plasm-ph',\n  'abstract': 'Dusty plasma experiments can be performed quite easily in strong coupling\\nregime. In our previous work [Phys. Plasmas 21, 073705 (2014)], we numerically\\nexplored such plasmas with constant density and observed the transverse shear\\n(TS) waves from a rotating vortex. Laboratory dusty plasmas are good examples\\nof homogeneous plasmas however heterogeneity (e.g. density, temperature,\\ncharge) may be due to the existence of voids, different domains with different\\norientations, presence of external forces like magnetic and/or electric,\\nsize/charge imbalance, etc. Here, we examine how the density heterogeneity in\\ndusty plasmas responds to the circularly rotating vortex monopoles, namely\\nsmooth and sharp cut-off. For this purpose we have carried out a series of\\ntwo-dimensional viscoelastic fluid simulations in the framework of generalized\\nhydrodynamics (GHD) fluid model. The rotating vortices are placed at the\\ninterface of two incompressible fluids with different densities. The smooth\\nrotating vortex causes two things: First, the densities are stretched to form\\nthe spiral density waves; secondly, the TS waves propagate radially into the\\nsurrounding media according to the shear wave speed. We notice that the spiral\\ndensity arms are distinguishable in the early time while later get smeared out.\\nThe sharp rotating vortex creates sharp shear flows which in turn favor the\\nKelvin-Helmholtz (KH) instability across the interfaces. In such flows for the\\nGHD system, the interplay between the emitted TS waves and the vortices of KH\\ninstability distorts the formation of the regular spiral density arms around\\nthe rotor',\n  'doi': '10.1103/PhysRevE.102.043216',\n  'update_date': '2020-11-04',\n  'version_no': '1'},\n {'id': '1006.4087',\n  'title': 'Cooperative atom-light interaction in a blockaded Rydberg ensemble',\n  'authors_parsed': [['Pritchard', 'J. D.', ''],\n   ['Maxwell', 'D.', ''],\n   ['Gauguet', 'A.', ''],\n   ['Weatherill', 'K. J.', ''],\n   ['Jones', 'M. P. A.', ''],\n   ['Adams', 'C. S.', '']],\n  'submitter': 'Jonathan Pritchard Mr.',\n  'categories': 'quant-ph physics.atom-ph',\n  'abstract': 'By coupling a probe transition to a Rydberg state using electro-magnetically\\ninduced transparency (EIT) we map the strong dipole-dipole interactions onto an\\noptical field. We characterize the resulting cooperative optical non-linearity\\nas a function of probe strength and density. We show that the effect of dipole\\nblockade cannot be described using a mean-field but requires an $N$-atom\\ncooperative model. Good quantitative agreement is obtained for three atoms per\\nblockade with the $n=60$ Rydberg state. We place an upper-limit on the\\ndephasing rate of the blockade spheres of $<110$ kHz.',\n  'doi': '10.1103/PhysRevLett.105.193603',\n  'update_date': '2010-11-08',\n  'version_no': '1'},\n {'id': '2505.07813',\n  'title': 'DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies',\n  'authors_parsed': [['Tao', 'Tony', ''],\n   ['Srirama', 'Mohan Kumar', ''],\n   ['Liu', 'Jason Jingzhou', ''],\n   ['Shaw', 'Kenneth', ''],\n   ['Pathak', 'Deepak', '']],\n  'submitter': 'Long Tao',\n  'categories': 'cs.RO cs.AI cs.CV cs.LG cs.SY eess.SY',\n  'abstract': 'Large-scale, diverse robot datasets have emerged as a promising path toward\\nenabling dexterous manipulation policies to generalize to novel environments,\\nbut acquiring such datasets presents many challenges. While teleoperation\\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\\nwhat if people could use their own hands, just as they do in everyday life, to\\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\\ncollect hours of interactions across a multitude of environments and objects.\\nTo record this data, we create DexWild-System, a low-cost, mobile, and\\neasy-to-use device. The DexWild learning framework co-trains on both human and\\nrobot demonstrations, leading to improved performance compared to training on\\neach dataset individually. This combination results in robust robot policies\\ncapable of generalizing to novel environments, tasks, and embodiments with\\nminimal additional robot-specific data. Experimental results demonstrate that\\nDexWild significantly improves performance, achieving a 68.5% success rate in\\nunseen environments-nearly four times higher than policies trained with robot\\ndata only-and offering 5.8x better cross-embodiment generalization. Video\\nresults, codebases, and instructions at https://dexwild.github.io',\n  'doi': None,\n  'update_date': '2025-05-13',\n  'version_no': '1'},\n {'id': '2007.03315',\n  'title': 'Manifold Learning via Manifold Deflation',\n  'authors_parsed': [['Ting', 'Daniel', ''], ['Jordan', 'Michael I.', '']],\n  'submitter': 'Daniel Ting',\n  'categories': 'stat.ML cs.LG math.DG',\n  'abstract': 'Nonlinear dimensionality reduction methods provide a valuable means to\\nvisualize and interpret high-dimensional data. However, many popular methods\\ncan fail dramatically, even on simple two-dimensional manifolds, due to\\nproblems such as vulnerability to noise, repeated eigendirections, holes in\\nconvex bodies, and boundary bias. We derive an embedding method for Riemannian\\nmanifolds that iteratively uses single-coordinate estimates to eliminate\\ndimensions from an underlying differential operator, thus \"deflating\" it. These\\ndifferential operators have been shown to characterize any local, spectral\\ndimensionality reduction method. The key to our method is a novel, incremental\\ntangent space estimator that incorporates global structure as coordinates are\\nadded. We prove its consistency when the coordinates converge to true\\ncoordinates. Empirically, we show our algorithm recovers novel and interesting\\nembeddings on real-world and synthetic datasets.',\n  'doi': None,\n  'update_date': '2020-07-08',\n  'version_no': '1'},\n {'id': 'physics/0607242',\n  'title': 'Full-wave simulations of electromagnetic cloaking structures',\n  'authors_parsed': [['Cummer', 'Steven A.', ''],\n   ['Popa', 'Bogdan-Ioan', ''],\n   ['Schurig', 'David', ''],\n   ['Smith', 'David R.', ''],\n   ['Pendry', 'John', '']],\n  'submitter': 'Steven Cummer',\n  'categories': 'physics.optics',\n  'abstract': 'Based on a coordinate transformation approach, Pendry {\\\\it et al.} have\\nreported electromagnetically anisotropic and inhomogeneous shells that, in\\ntheory, completely shield an interior structure of arbitrary size from\\nelectromagnetic fields without perturbing the external fields. We report\\nfull-wave simulations of the cylindrical version of this cloaking structure\\nusing ideal and nonideal (but physically realizable) electromagnetic parameters\\nin an effort to understand the challenges of realizing such a structure in\\npractice. The simulations indicate that the performance of the electromagnetic\\ncloaking structure is not especially sensitive to modest permittivity and\\npermeability variations. This is in contrast to other applications of\\nengineered electromagnetic materials, such as subwavelength focusing using\\nnegative refractive index materials. The cloaking performance degrades smoothly\\nwith increasing loss, and effective low-reflection shielding can be achieved\\nwith a cylindrical shell composed of an eight (homogeneous) layer approximation\\nof the ideal continuous medium.',\n  'doi': '10.1103/PhysRevE.74.036621',\n  'update_date': '2007-05-23',\n  'version_no': '1'},\n {'id': '2502.15606',\n  'title': 'Local signatures of altermagnetism',\n  'authors_parsed': [['Gondolf', 'Jannik', ''],\n   ['Kreisel', 'Andreas', ''],\n   ['Roig', 'Mercè', ''],\n   ['Yu', 'Yue', ''],\n   ['Agterberg', 'Daniel F.', ''],\n   ['Andersen', 'Brian M.', '']],\n  'submitter': 'Jannik Gondolf',\n  'categories': 'cond-mat.str-el cond-mat.mtrl-sci',\n  'abstract': \"Altermagnets constitute a class of collinear compensated N\\\\'eel ordered\\nmagnets that break time-reversal symmetry and feature spin-split band\\nstructures. Based on versatile microscopic models able to capture the\\naltermagnetic sublattice degrees of freedom, we study characteristic local\\nsignatures of altermagnetism near disorder sites. We give a complete list of\\ntwo-dimensional models that exhibit altermagnetism classified by their\\ncorresponding layer groups. Specifically, we calculate the local density of\\nstates in the vicinity of pointlike nonmagnetic impurities and expose its\\nspatial dependence for two minimal models showcasing $d$-wave and $g$-wave\\naltermagnetism. The momentum structure of the nodes ($d$-wave, $g$-wave, etc.)\\nis directly imprinted on the total local density of states, thus measurable by\\nscanning tunneling conductance experiments. This signature is present both in\\nthe spin-resolved as well as the spin-summed local density of states. We find a\\nweaker response in the nonmagnetic state from the anisotropic crystal\\nenvironment and uncover the importance of the sublattice degree of freedom to\\nmodel altermagnets. We also study coexistence phases of altermagnetism and\\nsuperconductivity and provide predictions for the local impurity response of\\nin-gap bound states. The response of impurity bound states strongly enhances\\nthe distinct altermagnetic signature.\",\n  'doi': None,\n  'update_date': '2025-02-24',\n  'version_no': '1'},\n {'id': '1208.6174',\n  'title': 'Generalized Hurst exponent and multifractal function of original and\\n  translated texts mapped into frequency and length time series',\n  'authors_parsed': [['Ausloos', 'Marcel', '']],\n  'submitter': 'Marcel Ausloos',\n  'categories': 'physics.data-an cond-mat.stat-mech nlin.PS physics.soc-ph',\n  'abstract': 'A nonlinear dynamics approach can be used in order to quantify complexity in\\nwritten texts. As a first step, a one-dimensional system is examined : two\\nwritten texts by one author (Lewis Carroll) are considered, together with one\\ntranslation, into an artificial language, i.e. Esperanto are mapped into time\\nseries. Their corresponding shuffled versions are used for obtaining a \"base\\nline\". Two different one-dimensional time series are used here: (i) one based\\non word lengths (LTS), (ii) the other on word frequencies (FTS). It is shown\\nthat the generalized Hurst exponent $h(q)$ and the derived $f(\\\\alpha)$ curves\\nof the original and translated texts show marked differences. The original\\n\"texts\" are far from giving a parabolic $f(\\\\alpha)$ function, - in contrast to\\nthe shuffled texts. Moreover, the Esperanto text has more extreme values. This\\nsuggests cascade model-like, with multiscale time asymmetric features as\\nfinally written texts. A discussion of the difference and complementarity of\\nmapping into a LTS or FTS is presented. The FTS $f(\\\\alpha)$ curves are more\\nopened than the LTS ones',\n  'doi': '10.1103/PhysRevE.86.031108',\n  'update_date': '2012-09-11',\n  'version_no': '1'},\n {'id': '0908.0439',\n  'title': 'Profinite Groups Associated to Sofic Shifts are Free',\n  'authors_parsed': [['Costa', 'Alfredo', ''], ['Steinberg', 'Benjamin', '']],\n  'submitter': 'Benjamin Steinberg',\n  'categories': 'math.GR',\n  'abstract': 'We show that the maximal subgroup of the free profinite semigroup associated\\nby Almeida to an irreducible sofic shift is a free profinite group,\\ngeneralizing an earlier result of the second author for the case of the full\\nshift (whose corresponding maximal subgroup is the maximal subgroup of the\\nminimal ideal). A corresponding result is proved for certain relatively free\\nprofinite semigroups. We also establish some other analogies between the kernel\\nof the free profinite semigroup and the $\\\\J$-class associated to an irreducible\\nsofic shift.',\n  'doi': '10.1112/plms/pdq024',\n  'update_date': '2014-02-26',\n  'version_no': '1'},\n {'id': '2503.11093',\n  'title': 'OmniDiff: A Comprehensive Benchmark for Fine-grained Image Difference\\n  Captioning',\n  'authors_parsed': [['Liu', 'Yuan', ''],\n   ['Hou', 'Saihui', ''],\n   ['Hou', 'Saijie', ''],\n   ['Du', 'Jiabao', ''],\n   ['Meng', 'Shibei', ''],\n   ['Huang', 'Yongzhen', '']],\n  'submitter': 'Yuan Liu',\n  'categories': 'cs.CV',\n  'abstract': \"Image Difference Captioning (IDC) aims to generate natural language\\ndescriptions of subtle differences between image pairs, requiring both precise\\nvisual change localization and coherent semantic expression. Despite recent\\nadvancements, existing datasets often lack breadth and depth, limiting their\\napplicability in complex and dynamic environments: (1) from a breadth\\nperspective, current datasets are constrained to limited variations of objects\\nin specific scenes, and (2) from a depth perspective, prior benchmarks often\\nprovide overly simplistic descriptions. To address these challenges, we\\nintroduce OmniDiff, a comprehensive dataset comprising 324 diverse\\nscenarios-spanning real-world complex environments and 3D synthetic\\nsettings-with fine-grained human annotations averaging 60 words in length and\\ncovering 12 distinct change types. Building on this foundation, we propose\\nM$^3$Diff, a MultiModal large language model enhanced by a plug-and-play\\nMulti-scale Differential Perception (MDP) module. This module improves the\\nmodel's ability to accurately identify and describe inter-image differences\\nwhile maintaining the foundational model's generalization capabilities. With\\nthe addition of the OmniDiff dataset, M$^3$Diff achieves state-of-the-art\\nperformance across multiple benchmarks, including Spot-the-Diff, IEdit,\\nCLEVR-Change, CLEVR-DC, and OmniDiff, demonstrating significant improvements in\\ncross-scenario difference recognition accuracy compared to existing methods.\\nThe dataset, code, and models will be made publicly available to support\\nfurther research.\",\n  'doi': None,\n  'update_date': '2025-03-17',\n  'version_no': '1'},\n {'id': '2201.00452',\n  'title': 'Cellulose-Based Reflective Liquid Crystal Films as Optical Filters and\\n  Solar Gain Regulators',\n  'authors_parsed': [['De La Cruz', 'Joshua A.', ''],\n   ['Liu', 'Qingkun', ''],\n   ['Senyuk', 'Bohdan', ''],\n   ['Frazier', 'Allister W.', ''],\n   ['Peddireddy', 'Karthik', ''],\n   ['Smalyukh', 'Ivan I.', '']],\n  'submitter': 'Bohdan Senyuk',\n  'categories': 'cond-mat.mtrl-sci cond-mat.soft physics.optics',\n  'abstract': 'Many promising approaches for designing interactions of synthetic materials\\nwith light involve solid optical monocrystals and nanofabricated photonic\\ncrystal structures with spatially periodic variations of refractive index.\\nAlthough their high costs limit current technological applications, remarkably,\\nsuch photonic and optically anisotropic materials have also evolved throughout\\nnature and enable narrow or broad-band spectral reflection of light. Here we\\nuse self-assembly of biomaterial cellulose nanocrystals to obtain three-layer\\nfilms with helicoidal and nematic-like organization of the cellulose\\nnanoparticles, which mimics naturally occurring polarization-insensitive\\nreflectors found in the wings of Plusiotis resplendens beetles. These films\\nwere characterized with polarized optical microscopy and circular dichroism\\nspectrometry, as well as scanning and transmission electron microscopies. These\\nfilms exhibit high reflectivity tunable within the visible and near-infrared\\nregions of the optical spectrum and may find applications ranging from color\\nfilters to smart cloth designs and in solar-gain-regulating building\\ntechnologies.',\n  'doi': '10.1021/acsphotonics.8b00289',\n  'update_date': '2022-01-04',\n  'version_no': '1'},\n {'id': '2309.14794',\n  'title': 'TELAMON: Effelsberg Monitoring of AGN Jets with Very-High-Energy\\n  Astroparticle Emissions -- Polarization properties',\n  'authors_parsed': [['Heßdörfer', 'J.', ''],\n   ['Kadler', 'M.', ''],\n   ['Benke', 'P.', ''],\n   ['Debbrecht', 'L.', ''],\n   ['Eich', 'J.', ''],\n   ['Eppel', 'F.', ''],\n   ['Gokus', 'A.', ''],\n   ['Hämmerich', 'S.', ''],\n   ['Kirchner', 'D.', ''],\n   ['Paraschos', 'G. F.', ''],\n   ['Rösch', 'F.', ''],\n   ['Schulga', 'W.', ''],\n   ['Sinapius', 'J.', ''],\n   ['Weber', 'P.', ''],\n   ['Bach', 'U.', ''],\n   ['Berge', 'D.', ''],\n   ['Buson', 'S.', ''],\n   ['Dorner', 'D.', ''],\n   ['Edwards', 'P. G.', ''],\n   ['Fromm', 'C. M.', ''],\n   ['Giroletti', 'M.', ''],\n   ['Hervet', 'O.', ''],\n   ['Kappes', 'A.', ''],\n   ['Koyama', 'S.', ''],\n   ['Kraus', 'A.', ''],\n   ['Krichbaum', 'T. P.', ''],\n   ['Lindfors', 'E.', ''],\n   ['Mannheim', 'K.', ''],\n   ['Ojha', 'R.', ''],\n   ['Pueschel', 'E.', ''],\n   ['Ros', 'E.', ''],\n   ['Schleicher', 'B.', ''],\n   ['Sitarek', 'J.', ''],\n   ['Wilms', 'J.', ''],\n   ['Zacharias', 'M.', ''],\n   ['Zensus', 'J. A.', '']],\n  'submitter': 'Jonas He{\\\\ss}d\\\\\"orfer',\n  'categories': 'astro-ph.HE',\n  'abstract': 'We present recent results of the TELAMON program, which is using the\\nEffelsberg 100-m telescope to monitor the radio spectra of active galactic\\nnuclei (AGN) under scrutiny in astroparticle physics, namely TeV blazars and\\nneutrino-associated AGN. Our sample includes all known Northern TeV-emitting\\nblazars as well as blazars positionally coincident with IceCube neutrino\\nalerts. Polarization can give additional insight into the source properties, as\\nthe polarized emission is often found to vary on different timescales and\\namplitudes than the total intensity emission. Here, we present an overview of\\nthe polarization properties of the TeV-emitting TELAMON sources at four\\nfrequencies in the 20 mm and 7 mm bands. While at 7 mm roughly $82\\\\,\\\\%$ of all\\nobserved sources are found to be significantly polarized, for 20 mm the\\npercentage is $\\\\sim58\\\\,\\\\%$. We find that most of the sources exhibit mean\\nfractional polarizations of $<5\\\\%$, matching the expectations of rather low\\npolarization levels in these sources from previous studies at lower radio\\nfrequencies. Nevertheless, we demonstrate examples of how the polarized\\nemission can provide additional information over the total intensity.',\n  'doi': None,\n  'update_date': '2023-11-01',\n  'version_no': '2'},\n {'id': '1702.03533',\n  'title': 'Skeletal stochastic differential equations for continuous-state\\n  branching process',\n  'authors_parsed': [['Fekete', 'Dorottya', ''],\n   ['Fontbona', 'Joaquin', ''],\n   ['Kyprianou', 'Andreas E.', '']],\n  'submitter': 'Andreas Kyprianou A.E.',\n  'categories': 'math.PR',\n  'abstract': 'It is well understood that a supercritical continuous-state branching process\\n(CSBP) is equal in law to a discrete continuous-time Galton Watson process (the\\nskeleton of prolific individuals) whose edges are dressed in a Poissonian way\\nwith immigration which initiates subcritial CSBPs (non-prolific mass). Equally\\nwell understood in the setting of CSBPs and super-processes is the notion of a\\nspine or immortal particle dressed in a Poissonian way with immigration which\\ninitiates copies of the original CSBP, which emerges when conditioning the\\nprocess to survive eternally.\\n  In this article, we revisit these notions for CSBPs and put them in a common\\nframework using the language of (coupled) SDEs. In this way, we are able to\\ndeal simultaneously with all types of CSBPs (supercritical, critical and\\nsubcritical) as well as understanding how the backbone representation becomes,\\nin the sense of weak convergence, a spinal decomposition when conditioning on\\nsurvival. Our principal motivation is to prepare the way to expand the SDE\\napproach to the spatial setting of super-processes, where recent results have\\nincreasingly sought the use of skeletal decompositions to transfer results from\\nthe branching particle setting to the setting of measure valued processes.',\n  'doi': None,\n  'update_date': '2019-04-16',\n  'version_no': '4'},\n {'id': 'cond-mat/0209648',\n  'title': 'Effect of a magnetic field on long-range magnetic order in stage-4 and\\n  stage-6 superconducting La2CuO(4+y)',\n  'authors_parsed': [['Khaykovich', 'B.', ''],\n   ['Birgeneau', 'R. J.', ''],\n   ['Chou', 'F. C.', ''],\n   ['Erwin', 'R. W.', ''],\n   ['Kastner', 'M. A.', ''],\n   ['Lee', 'S. -H.', ''],\n   ['Lee', 'Y. S.', ''],\n   ['Smeibidl', 'P.', ''],\n   ['Vorderwisch', 'P.', ''],\n   ['Wakimoto', 'S.', '']],\n  'submitter': 'B. Khaykovich',\n  'categories': 'cond-mat.str-el cond-mat.supr-con',\n  'abstract': 'We have measured the enhancement of the static incommensurate spin-density\\nwave (SDW) order by an applied magnetic field in stage-4 and stage-6 samples of\\nsuperconducting La2CuO(4+y). We show that the stage-6 La2CuO(4+y) (Tc=32 K)\\nforms static long-range SDW order with the same wave-vector as that in the\\npreviously studied stage-4 material. We have measured the field dependence of\\nthe SDW magnetic Bragg peaks in both stage-4 and stage-6 materials at fields up\\nto 14.5 T. A recent model of competing SDW order and superconductivity\\ndescribes these data well.',\n  'doi': '10.1103/PhysRevB.67.054501',\n  'update_date': '2009-11-07',\n  'version_no': '2'},\n {'id': '2112.01111',\n  'title': 'Antiferromagnetic spin pumping via hyperfine interaction',\n  'authors_parsed': [['Cahaya', 'Adam B.', '']],\n  'submitter': 'Adam B. Cahaya Dr.',\n  'categories': 'cond-mat.mes-hall physics.atom-ph quant-ph',\n  'abstract': 'Spin pumping is an interfacial spin current generation from the ferromagnetic\\nlayer to the non-magnetic metal at its interface. The polarization of the\\npumped spin current $\\\\textbf{J}_s \\\\propto \\\\textbf{m}\\\\times \\\\dot{\\\\textbf{m}}$\\ndepends on the dynamics of the magnetic moment $\\\\textbf{m}$. When the materials\\nare based on light transition metals, mechanism behind the spin current\\ntransfer is dominated by the exchange interaction between spin of localized\\nd-electrons and itinerant conduction electrons. In heavier transition metals,\\nhowever, the interaction is not limited to the exchange interaction. The spin\\nof the conduction electron can interact to its nuclear spin by means of\\nhyperfine interaction, as observed in the shift of NMR frequency. By studying\\nthe spin polarization of conduction electron of the non-magnetic metallic layer\\ndue to a nuclear magnetic moment $\\\\textbf{I}$ of the ferromagnetic layer, we\\nshow that the hyperfine interaction can mediate the spin pumping. The\\npolarization of the spin current generation is shown to have a similar form\\n$J_s\\\\propto \\\\textbf{I}\\\\times\\\\dot{\\\\textbf{I}}$.',\n  'doi': '10.1007/s10751-021-01780-0',\n  'update_date': '2023-10-25',\n  'version_no': '1'},\n {'id': 'nucl-th/0212005',\n  'title': 'Hadron wave functions and the issue of nucleon deformation',\n  'authors_parsed': [['Alexandrou', 'C.', '', 'Univ. of Cyprus'],\n   ['de Forcrand', 'Ph.', '', 'ETH Zurich and CERN'],\n   ['Tsapalis', 'A.', '', 'Univ. of Cyprus']],\n  'submitter': 'Constantia Alexandrou',\n  'categories': 'nucl-th hep-lat',\n  'abstract': 'Using gauge invariant hadronic two- and three- density correlators we extract\\ninformation on the spatial distributions of quarks in hadrons, and on hadron\\nshape and multipole moments within quenched lattice QCD. Combined with the\\ncalculation of N to Delta transition amplitudes the issue of nucleon\\ndeformation can be addressed.',\n  'doi': '10.1016/S0375-9474(03)01240-5',\n  'update_date': '2009-11-07',\n  'version_no': '2'},\n {'id': '1306.1699',\n  'title': 'The ultra-long GRB 111209A - II. Prompt to afterglow and afterglow\\n  properties',\n  'authors_parsed': [['Stratta', 'G.', ''],\n   ['Gendre', 'B.', ''],\n   ['Atteia', 'J. L.', ''],\n   ['Boër', 'M.', ''],\n   ['Coward', 'D. M.', ''],\n   ['De Pasquale', 'M.', ''],\n   ['Howell', 'E.', ''],\n   ['Klotz', 'A.', ''],\n   ['Oates', 'S.', ''],\n   ['Piro', 'L.', '']],\n  'submitter': 'Giulia Stratta',\n  'categories': 'astro-ph.HE astro-ph.CO',\n  'abstract': 'The \"ultra-long\" Gamma Ray Burst GRB 111209A at redshift z=0.677, is so far\\nthe longest GRB ever observed, with rest frame prompt emission duration of ~4\\nhours. In order to explain the bursts exceptional longevity, a low metallicity\\nblue supergiant progenitor has been invoked. In this work, we further\\ninvestigate this peculiar burst by performing a multi-band temporal and\\nspectral analysis of both the prompt and the afterglow emission. We use\\nproprietary and publicly available data from Swift, Konus Wind, XMM-Newton,\\nTAROT as well as from other ground based optical and radio telescopes. We find\\nsome peculiar properties that are possibly connected to the exceptional nature\\nof this burst, namely: i) an unprecedented large optical delay of 410+/-50 s is\\nmeasured between the peak epochs of a marked flare observed also in gamma-rays\\nafter about 2 ks from the first Swift/BAT trigger; ii) if the optical and\\nX-ray/gamma-ray photons during the prompt emission share a common origin, as\\nsuggested by their similar temporal behavior, a certain amount of dust in the\\ncircumburst environment should be introduced, with rest frame visual dust\\nextinction of AV=0.3-1.5 mag; iii) at the end of the X-ray \"steep decay phase\"\\nand before the start of the X-ray afterglow, we detect the presence of a hard\\nspectral extra power law component never revealed so far. On the contrary, the\\noptical afterglow since the end of the prompt emission shows more common\\nproperties, with a flux power law decay with index alpha=1.6+/-0.1 and a late\\nre-brightening feature at 1.1 day. We discuss our findings in the context of\\nseveral possible interpretations given so far to the complex multi-band GRB\\nphenomenology. We also attempt to exploit our results to further constrain the\\nprogenitor nature properties of this exceptionally long GRB, suggesting a\\nbinary channel formation for the proposed blue supergiant progenitor.',\n  'doi': '10.1088/0004-637X/779/1/66',\n  'update_date': '2015-06-16',\n  'version_no': '2'},\n {'id': '2207.08187',\n  'title': 'Federated Self-Supervised Learning in Heterogeneous Settings: Limits of\\n  a Baseline Approach on HAR',\n  'authors_parsed': [['Ek', 'Sannara', ''],\n   ['Rombourg', 'Romain', ''],\n   ['Portet', 'François', ''],\n   ['Lalanda', 'Philippe', '']],\n  'submitter': 'Fran\\\\c{c}ois Portet',\n  'categories': 'cs.LG cs.AI',\n  'abstract': 'Federated Learning is a new machine learning paradigm dealing with\\ndistributed model learning on independent devices. One of the many advantages\\nof federated learning is that training data stay on devices (such as\\nsmartphones), and only learned models are shared with a centralized server. In\\nthe case of supervised learning, labeling is entrusted to the clients. However,\\nacquiring such labels can be prohibitively expensive and error-prone for many\\ntasks, such as human activity recognition. Hence, a wealth of data remains\\nunlabelled and unexploited. Most existing federated learning approaches that\\nfocus mainly on supervised learning have mostly ignored this mass of unlabelled\\ndata. Furthermore, it is unclear whether standard federated Learning approaches\\nare suited to self-supervised learning. The few studies that have dealt with\\nthe problem have limited themselves to the favorable situation of homogeneous\\ndatasets. This work lays the groundwork for a reference evaluation of federated\\nLearning with Semi-Supervised Learning in a realistic setting. We show that\\nstandard lightweight autoencoder and standard Federated Averaging fail to learn\\na robust representation for Human Activity Recognition with several realistic\\nheterogeneous datasets. These findings advocate for a more intensive research\\neffort in Federated Self Supervised Learning to exploit the mass of\\nheterogeneous unlabelled data present on mobile devices.',\n  'doi': '10.1109/PerComWorkshops53856.2022.9767369',\n  'update_date': '2022-07-19',\n  'version_no': '1'},\n {'id': '1710.08263',\n  'title': 'Machine learning methods for locating re-entrant drivers from\\n  electrograms in a model of atrial fibrillation',\n  'authors_parsed': [['McGillivray', 'Max Falkenberg', ''],\n   ['Cheng', 'William', ''],\n   ['Peters', 'Nicholas S.', ''],\n   ['Christensen', 'Kim', '']],\n  'submitter': 'Max Falkenberg McGillivray',\n  'categories': 'q-bio.TO',\n  'abstract': 'Mapping resolution has recently been identified as a key limitation in\\nsuccessfully locating the drivers of atrial fibrillation. Using a simple\\ncellular automata model of atrial fibrillation, we demonstrate a method by\\nwhich re-entrant drivers can be located quickly and accurately using a\\ncollection of indirect electrogram measurements. The method proposed employs\\nsimple, out of the box machine learning algorithms to correlate characteristic\\nelectrogram gradients with the displacement of an electrogram recording from a\\nre-entrant driver. Such a method is less sensitive to local fluctuations in\\nelectrical activity. As a result, the method successfully locates 95.4% of\\ndrivers in tissues containing a single driver, and 94.8% (92.5%) for the first\\n(second) driver in tissues containing two drivers of atrial fibrillation.\\nAdditionally, we demonstrate how the technique can be applied to tissues with\\nan arbitrary number of drivers. Extending the technique for use in clinical\\npractice could alleviate the limitations in current ablation techniques that\\narise from limited mapping resolution.',\n  'doi': '10.1098/rsos.172434',\n  'update_date': '2020-01-27',\n  'version_no': '1'},\n {'id': '2212.03699',\n  'title': 'Persona-Based Conversational AI: State of the Art and Challenges',\n  'authors_parsed': [['Liu', 'Junfeng', ''],\n   ['Symons', 'Christopher', ''],\n   ['Vatsavai', 'Ranga Raju', '']],\n  'submitter': 'Junfeng Liu',\n  'categories': 'cs.CL cs.AI cs.LG',\n  'abstract': 'Conversational AI has become an increasingly prominent and practical\\napplication of machine learning. However, existing conversational AI techniques\\nstill suffer from various limitations. One such limitation is a lack of\\nwell-developed methods for incorporating auxiliary information that could help\\na model understand conversational context better. In this paper, we explore how\\npersona-based information could help improve the quality of response generation\\nin conversations. First, we provide a literature review focusing on the current\\nstate-of-the-art methods that utilize persona information. We evaluate two\\nstrong baseline methods, the Ranking Profile Memory Network and the\\nPoly-Encoder, on the NeurIPS ConvAI2 benchmark dataset. Our analysis elucidates\\nthe importance of incorporating persona information into conversational\\nsystems. Additionally, our study highlights several limitations with current\\nstate-of-the-art methods and outlines challenges and future research directions\\nfor advancing personalized conversational AI technology.',\n  'doi': '10.1109/ICDMW58026.2022.00129',\n  'update_date': '2025-03-25',\n  'version_no': '1'},\n {'id': '2211.12071',\n  'title': 'Research-Data Management Planning in the German Mathematical Community',\n  'authors_parsed': [['Boege', 'Tobias', ''],\n   ['Fritze', 'René', ''],\n   ['Görgen', 'Christiane', ''],\n   ['Hanselman', 'Jeroen', ''],\n   ['Iglezakis', 'Dorothea', ''],\n   ['Kastner', 'Lars', ''],\n   ['Koprucki', 'Thomas', ''],\n   ['Krause', 'Tabea', ''],\n   ['Lehrenfeld', 'Christoph', ''],\n   ['Polla', 'Silvia', ''],\n   ['Reidelbach', 'Marco', ''],\n   ['Riedel', 'Christian', ''],\n   ['Saak', 'Jens', ''],\n   ['Schembera', 'Björn', ''],\n   ['Tabelow', 'Karsten', ''],\n   ['Weber', 'Marcus', '']],\n  'submitter': 'Christiane G\\\\\"orgen',\n  'categories': 'math.HO',\n  'abstract': \"In this paper we discuss the notion of research data for the field of\\nmathematics and report on the status quo of research-data management and\\nplanning. A number of decentralized approaches are presented and compared to\\nneeds and challenges faced in three use cases from different mathematical\\nsubdisciplines. We highlight the importance of tailoring research-data\\nmanagement plans to mathematicians' research processes and discuss their usage\\nall along the data life cycle.\",\n  'doi': None,\n  'update_date': '2022-11-23',\n  'version_no': '1'},\n {'id': '2402.06642',\n  'title': 'From GARCH to Neural Network for Volatility Forecast',\n  'authors_parsed': [['Zhao', 'Pengfei', ''],\n   ['Zhu', 'Haoren', ''],\n   ['NG', 'Wilfred Siu Hung', ''],\n   ['Lee', 'Dik Lun', '']],\n  'submitter': 'Haoren Zhu',\n  'categories': 'q-fin.ST cs.LG',\n  'abstract': 'Volatility, as a measure of uncertainty, plays a crucial role in numerous\\nfinancial activities such as risk management. The Econometrics and Machine\\nLearning communities have developed two distinct approaches for financial\\nvolatility forecasting: the stochastic approach and the neural network (NN)\\napproach. Despite their individual strengths, these methodologies have\\nconventionally evolved in separate research trajectories with little\\ninteraction between them. This study endeavors to bridge this gap by\\nestablishing an equivalence relationship between models of the GARCH family and\\ntheir corresponding NN counterparts. With the equivalence relationship\\nestablished, we introduce an innovative approach, named GARCH-NN, for\\nconstructing NN-based volatility models. It obtains the NN counterparts of\\nGARCH models and integrates them as components into an established NN\\narchitecture, thereby seamlessly infusing volatility stylized facts (SFs)\\ninherent in the GARCH models into the neural network. We develop the GARCH-LSTM\\nmodel to showcase the power of the GARCH-NN approach. Experiment results\\nvalidate that amalgamating the NN counterparts of the GARCH family models into\\nestablished NN models leads to enhanced outcomes compared to employing the\\nstochastic and NN models in isolation.',\n  'doi': None,\n  'update_date': '2024-02-13',\n  'version_no': '1'},\n {'id': '1106.2942',\n  'title': 'Suzaku View of the Swift/Bat Active Galactic Nuclei. IV. Nature of Two\\n  Narrow-Line Radio Galaxies (3C 403 and IC 5063)',\n  'authors_parsed': [['Tazaki', 'Fumie', ''],\n   ['Ueda', 'Yoshihiro', ''],\n   ['Terashima', 'Yuichi', ''],\n   ['Mushotzky', 'Richard F.', '']],\n  'submitter': 'Fumie Tazaki',\n  'categories': 'astro-ph.HE',\n  'abstract': 'We report the results of Suzaku broad band X-ray observations of the two\\nnarrow-line radio galaxies (NLRGs), 3C 403 and IC 5063. Combined with the\\nSwift/BAT spectra averaged for 58 months, we are able to accurately constrain\\ntheir spectral properties over the 0.5--200 keV band. The spectra of both\\nnuclei are well represented with an absorbed cut-off power law, an absorbed\\nreflection component from cold matter with an iron-K emission line, and an\\nunabsorbed soft component, which gives a firm upper limit for the scattered\\nemission. The reflection strength normalized to the averaged BAT flux is R =\\n\\\\Omega/2\\\\pi ~ 0.6 in both targets, implying that their tori have a sufficiently\\nlarge solid angle to produce the reprocessed emission. A numerical torus model\\nwith an opening angle of ~ 50 deg well reproduces the observed spectra. We\\ndiscuss the possibility that the amount of the normal gas responsible for\\nThomson scattering is systematically smaller in radio galaxies compared with\\nSeyfert galaxies.',\n  'doi': '10.1088/0004-637X/738/1/70',\n  'update_date': '2015-05-28',\n  'version_no': '1'},\n {'id': 'hep-lat/0103037',\n  'title': 'Meson Screening Masses at high Temperature in quenched QCD with improved\\n  Wilson Quarks',\n  'authors_parsed': [['Laermann', 'Edwin', ''], ['Schmidt', 'Peter', '']],\n  'submitter': 'Edwin Laermann',\n  'categories': 'hep-lat',\n  'abstract': 'We report on a lattice investigation of improved quenched Wilson fermions\\nabove and below the confinement-deconfinement phase transition. Results on\\nmeson screening masses as well as spatial wave functions are presented.\\nMoreover, the meson dispersion relation is studied. Below the critical\\ntemperature we do not observe any significant temperature effect while above\\n$T_c$ the data are consistent with a leading free quark behavior.',\n  'doi': '10.1007/s100520100682',\n  'update_date': '2009-01-07',\n  'version_no': '1'},\n {'id': '1712.07706',\n  'title': 'High-precision measurements and theoretical calculations of indium\\n  excited-state polarizabilities',\n  'authors_parsed': [['Vilas', 'N. B.', ''],\n   ['Wang', 'B. -Y.', ''],\n   ['Rupasinghe', 'P. M.', ''],\n   ['Maser', 'D. L.', ''],\n   ['Safronova', 'M. S.', ''],\n   ['Safronova', 'U. I.', ''],\n   ['Majumder', 'P. K.', '']],\n  'submitter': 'Daniel Maser',\n  'categories': 'physics.atom-ph',\n  'abstract': 'We report measurements of the $^{115}$In $7p_{1/2}$ and $7p_{3/2}$ scalar and\\ntensor polarizabilities using two-step diode laser spectroscopy in an atomic\\nbeam. The scalar polarizabilities are one to two orders of magnitude larger\\nthan for lower lying indium states due to the close proximity of the $7p$ and\\n$6d$ states. For the scalar polarizabilities, we find values (in atomic units)\\nof $1.811(4) \\\\times 10^5$ $a_0^3$ and $2.876(6) \\\\times 10^5$ $a_0^3$ for the\\n$7p_{1/2}$ and $7p_{3/2}$ states respectively. We estimate the smaller tensor\\npolarizability component of the $7p_{3/2}$ state to be $-1.43(18) \\\\times 10^4$\\n$a_0^3$. These measurements represent the first high-precision benchmarks of\\ntransition properties of such high excited states of trivalent atomic systems.\\nWe also present new ab initio calculations of these quantities and other In\\npolarizabilities using two high-precision relativistic methods to make a global\\ncomparison of the accuracies of the two approaches. The precision of the\\nexperiment is sufficient to differentiate between the two theoretical methods\\nas well as to allow precise determination of the indium $7p-6d$ matrix\\nelements. The results obtained in this work are applicable to other heavier and\\nmore complicated systems, and provide much needed guidance for the development\\nof even more precise theoretical approaches.',\n  'doi': '10.1103/PhysRevA.97.022507',\n  'update_date': '2018-02-21',\n  'version_no': '2'},\n {'id': 'nucl-ex/0610009',\n  'title': 'Hard Probe Capabilities of CMS in Heavy Ion Collisions at the LHC',\n  'authors_parsed': [['Roland', 'Gunther', '', 'for the CMS Collaboration']],\n  'submitter': 'Gunther Roland',\n  'categories': 'nucl-ex',\n  'abstract': 'Heavy ion collisions at the Large Hadron Collider (LHC) will produce strongly\\ninteracting matter at unprecedented energy densities. At LHC collision\\nenergies, new hard probes of the dense initial collision system will become\\nreadily available. We present an overview of the capabilities of the Compact\\nMuon Solenoid (CMS) detector to use these probes for a detailed study of QCD\\nphenomenology at the highest energy densities.',\n  'doi': '10.1016/j.nuclphysa.2006.11.094',\n  'update_date': '2019-08-14',\n  'version_no': '2'},\n {'id': '1507.07267',\n  'title': 'Network MIMO with Partial Cooperation between Radar and Cellular Systems',\n  'authors_parsed': [['Abdelhadi', 'Ahmed', ''], ['Clancy', 'T. Charles', '']],\n  'submitter': 'Ahmed Abdelhadi',\n  'categories': 'cs.IT math.IT',\n  'abstract': 'To meet the growing spectrum demands, future cellular systems are expected to\\nshare the spectrum of other services such as radar. In this paper, we consider\\na network multiple-input multiple-output (MIMO) with partial cooperation model\\nwhere radar stations cooperate with cellular base stations (BS)s to deliver\\nmessages to intended mobile users. So the radar stations act as BSs in the\\ncellular system. However, due to the high power transmitted by radar stations\\nfor detection of far targets, the cellular receivers could burnout when\\nreceiving these high radar powers. Therefore, we propose a new projection\\nmethod called small singular values space projection (SSVSP) to mitigate these\\nharmful high power and enable radar stations to collaborate with cellular base\\nstations. In addition, we formulate the problem into a MIMO interference\\nchannel with general constraints (MIMO-IFC-GC). Finally, we provide a solution\\nto minimize the weighted sum mean square error minimization problem (WSMMSE)\\nwith enforcing power constraints on both radar and cellular stations.',\n  'doi': '10.1109/ICCNC.2016.7440576',\n  'update_date': '2016-10-25',\n  'version_no': '3'},\n {'id': '2409.01598',\n  'title': 'Global stability of first order endotactic reaction systems',\n  'authors_parsed': [['Xu', 'Chuang', '']],\n  'submitter': 'Chuang Xu',\n  'categories': 'math.DS',\n  'abstract': 'Reaction networks are a general framework widely used in modelling diverse\\nphenomena in different science disciplines. The dynamical process of a reaction\\nnetwork endowed with mass-action kinetics is a mass-action system. In this\\npaper we study dynamics of first order mass-action systems. We prove that every\\nfirst order endotactic mass-action system has a weakly reversible deficiency\\nzero realization, and has a unique equilibrium which is exponentially globally\\nasymptotically stable (and is positive) in each (positive) stoichiometric\\ncompatibility class. In particular, we prove that global attractivity\\nconjecture holds for every linear complex balanced mass-action system. In this\\nway, we exclude the possibility of first order endotactic mass-action systems\\nto admit multistationarity or multistability. The result indicates that the\\nimportance of binding molecules in reactants is crucial for (endotactic)\\nreaction networks to have complicated dynamics like limit cycles. The proof\\nrelies on the fact that $\\\\mathcal{A}$-endotacticity of first order reaction\\nnetworks implies endotacticity for a finite set $\\\\mathcal{A}$, which is also\\nproved in this paper.\\n  Out of independent interest, we provide a sufficient condition for\\nendotacticity of reaction networks which are not necessarily of first order.',\n  'doi': None,\n  'update_date': '2024-09-04',\n  'version_no': '1'},\n {'id': 'cond-mat/0410570',\n  'title': 'From the second magnetization peak to peak effect. A study of\\n  superconducting properties in Nb films and MgB2 bulk samples',\n  'authors_parsed': [['Stamopoulos', 'Dimosthenis', ''],\n   ['Speliotis', 'Athanasios', ''],\n   ['Niarchos', 'Dimitris', '']],\n  'submitter': 'Dimosthenis Stamopoulos',\n  'categories': 'cond-mat.supr-con',\n  'abstract': 'We report on magnetic and magnetoresistance measurements in two categories of\\nsuperconducting Nb films grown via magnetron sputtering and MgB2 bulk samples.\\nIn the first category, films of Tc = 9.25 K were produced by annealing during\\ndeposition. In these films, the magnetic measurements exhibited the so-called\\nsecond magnetization peak (SMP), which is accompanied by thermomagnetic\\ninstabilities (TMI). The characteristic field Hfj, where the first flux jump\\noccurs, has been studied as a function of the sweep rate of the magnetic field.\\nInterestingly, in the regime T < 6.4 K, the respective line Hfj(T) is constant,\\nHfj(T < 6.4 K) = 40 Oe. A comparison to TMI observed in MgB2 bulk samples is\\nalso performed. Our experimental findings cannot be described accurately by\\ncurrent theories on TMI. In the second category, films of Tc = 8.3 K were\\nproduced without annealing during deposition. In such films, we observed a peak\\neffect (PE). In high magnetic fields the PE is accompanied by a sharp drop and\\na narrow hysteretic behaviour in the measured magnetoresistance. In contrast to\\nexperimental works presented in the past, the comparison of our magnetic\\nmeasurements with the magnetoresistance data suggests that the appearance of\\nsurface superconductivity rather than the melting transition of vortex matter\\nis the cause of the observed behaviour.',\n  'doi': '10.1088/0953-2048/17/11/006',\n  'update_date': '2009-11-10',\n  'version_no': '1'},\n {'id': '1903.05259',\n  'title': 'Conditional past-future correlation induced by non-Markovian dephasing\\n  reservoirs',\n  'authors_parsed': [['Budini', 'Adrian A.', '']],\n  'submitter': 'Adrian Budini',\n  'categories': 'quant-ph',\n  'abstract': 'Memory effects can be studied through a conditional past-future correlation,\\nwhich measures departure with respect to a conditional past-future independence\\nvalid in a memoryless Markovian regime. In a quantum regime this property leads\\nto an operational definition of quantum non-Markovianity based on three\\nconsecutive system measurement processes and postselection [Budini, Phys. Rev.\\nLett. 121, 240401 (2018)]. Here, we study the conditional past-future\\ncorrelation for a qubit system coupled to different dephasing environments.\\nExact solutions are obtained for a quantum spin bath as well as for classically\\nfluctuating random Hamiltonian models. The developing of memory effects and\\ndepartures from Born-Markov or white-noise approximations are related to a\\nmeasurement back action that changes the system dynamics between consecutive\\nmeasurements. It is shown that this effect may develop even when the former\\nsystem evolution is given by a time-independent Lindblad equation. This unusual\\nnon-Markovian case arises when the characteristic parameters of the dynamics\\nbecome Lorentzian random distributed variables.',\n  'doi': '10.1103/PhysRevA.99.052125',\n  'update_date': '2019-06-05',\n  'version_no': '1'},\n {'id': '2502.17182',\n  'title': 'Continuous variable quantum teleportation, $U(2)$ invariant squeezing\\n  and non-Gaussian resource states',\n  'authors_parsed': [['Sharma', 'Mohak', ''],\n   ['Kumar', 'Chandan', ''],\n   ['Arora', 'Shikhar', ''],\n   ['Arvind', '', '']],\n  'submitter': 'Chandan Kumar',\n  'categories': 'quant-ph',\n  'abstract': 'We investigate the role of quadrature squeezing in the quantum teleportation\\nprotocol for coherent states, using non-Gaussian resource states. For the\\ntwo-mode systems, the non-Gaussian resource states that we use are obtained by\\nan experimentally realizable scheme of photon subtraction, photon addition, and\\nphoton catalysis, on the two-mode squeezed vacuum, and two-mode squeezed\\nthermal states. We first analyze the non-classical attribute of quadrature\\nsqueezing in these generated non-Gaussian states using the $U(2)$ invariant\\nsqueezing approach, which allows us to account for all possible quadratures. We\\nthen show that the presence of such non-classicality in non-Gaussian resource\\nstates is not necessary for successful quantum teleportation, a finding which\\nis at variance with an earlier result in this direction. This result is\\nimportant since it demonstrates how non-classicality other than quadrature\\nsqueezing present in the resource can be utilized for quantum teleportation.',\n  'doi': None,\n  'update_date': '2025-02-25',\n  'version_no': '1'},\n {'id': '1507.03691',\n  'title': 'Dynamic Sleep Control in Green Relay-Assisted Networks for Energy Saving\\n  and QoS Improving',\n  'authors_parsed': [['Chen', 'Fang', ''],\n   ['Yang', 'Bo', ''],\n   ['Han', 'Qiaoni', ''],\n   ['Chen', 'Cailian', ''],\n   ['Guan', 'Xinping', '']],\n  'submitter': 'Fang Chen',\n  'categories': 'cs.NI',\n  'abstract': \"We study the relay station (RS) sleep control mechanism targeting on reducing\\nenergy consumption while improving users' quality of service (QoS) in green\\nrelay-assisted cellular networks, where the base station (BS) is powered by\\ngrid power and the RSs are powered by renewable energy. By adopting green RSs,\\nthe grid power consumption of the BS is greatly reduced. But due to the\\nuncertainty and stochastic characteristics of the renewable energy, power\\nsupply for RSs is not always sufficient. Thus the harvested energy needs to be\\nscheduled appropriately to cater to the dynamic traffic so as to minimize the\\nenergy saving in the long term. An optimization problem is formulated to find\\nthe optimal sleep ratio of RSs to match the time variation of energy harvesting\\nand traffic arrival. To fully use the renewable energy, green-RS-first\\nprinciple is adopted in the user association process. The optimal RS sleeping\\npolicy is obtained through dynamic programming (DP) approach, which divides the\\noriginal optimization problem into per-stage subproblems. A reduced DP\\nalgorithm and a greedy algorithm are further proposed to greatly reduce the\\ncomputation complexity. By simulations, the reduced DP algorithm outperforms\\nthe greedy algorithm in achieving satisfactory energy saving and QoS\\nperformance.\",\n  'doi': None,\n  'update_date': '2015-07-15',\n  'version_no': '1'},\n {'id': '1404.6925',\n  'title': 'Unconditionally secure bit commitment by causally independent\\n  encryptions',\n  'authors_parsed': [['Cheung', 'Chi-Yee', '']],\n  'submitter': 'Chi-Yee Cheung',\n  'categories': 'quant-ph',\n  'abstract': \"We propose a new classical bit commitment protocol using the relativistic\\nconstraint that signals cannot travel faster than the speed of light $c$. This\\nprotocol is unconditionally secure against both classical or quantum attacks.\\nThe sender (Alice) and the receiver (Bob) each controls two secure stations\\nseparated by a large distance $d$, and they communicate by exchanging classical\\ninformation only. Alice commits by sending from her stations two causally\\nindependent encrypted messages to the neighboring Bob's stations, after that\\nthe protocol is out of her control and she plays no role in the unveiling\\nphase. The commitment remains concealed for a period of $\\\\Delta t=d/2c$. This\\nprotocol requires only limited communication resources and is readily\\nimplementable with current technologies.\",\n  'doi': None,\n  'update_date': '2014-04-29',\n  'version_no': '1'},\n {'id': '2410.01292',\n  'title': 'Robust Imitation Learning for Mobile Manipulator Focusing on\\n  Task-Related Viewpoints and Regions',\n  'authors_parsed': [['Ishida', 'Yutaro', ''],\n   ['Noguchi', 'Yuki', ''],\n   ['Kanai', 'Takayuki', ''],\n   ['Shintani', 'Kazuhiro', ''],\n   ['Bito', 'Hiroshi', '']],\n  'submitter': 'Yutaro Ishida',\n  'categories': 'cs.RO',\n  'abstract': \"We study how to generalize the visuomotor policy of a mobile manipulator from\\nthe perspective of visual observations. The mobile manipulator is prone to\\nocclusion owing to its own body when only a single viewpoint is employed and a\\nsignificant domain shift when deployed in diverse situations. However, to the\\nbest of the authors' knowledge, no study has been able to solve occlusion and\\ndomain shift simultaneously and propose a robust policy. In this paper, we\\npropose a robust imitation learning method for mobile manipulators that focuses\\non task-related viewpoints and their spatial regions when observing multiple\\nviewpoints. The multiple viewpoint policy includes attention mechanism, which\\nis learned with an augmented dataset, and brings optimal viewpoints and robust\\nvisual embedding against occlusion and domain shift. Comparison of our results\\nfor different tasks and environments with those of previous studies revealed\\nthat our proposed method improves the success rate by up to 29.3 points. We\\nalso conduct ablation studies using our proposed method. Learning task-related\\nviewpoints from the multiple viewpoints dataset increases robustness to\\nocclusion than using a uniquely defined viewpoint. Focusing on task-related\\nregions contributes to up to a 33.3-point improvement in the success rate\\nagainst domain shift.\",\n  'doi': None,\n  'update_date': '2024-10-03',\n  'version_no': '1'},\n {'id': '2412.20192',\n  'title': 'Learning physical unknowns from hydrodynamic shock and material\\n  interface features in ICF capsule implosions',\n  'authors_parsed': [['Serino', 'Daniel A.', ''],\n   ['Bell', 'Evan', ''],\n   ['Klasky', 'Marc', ''],\n   ['Southworth', 'Ben S.', ''],\n   ['Nadiga', 'Balasubramanya', ''],\n   ['Wilcox', 'Trevor', ''],\n   ['Korobkin', 'Oleg', '']],\n  'submitter': 'Daniel Serino',\n  'categories': 'physics.comp-ph cs.LG hep-ph',\n  'abstract': 'In high energy density physics (HEDP) and inertial confinement fusion (ICF),\\npredictive modeling is complicated by uncertainty in parameters that\\ncharacterize various aspects of the modeled system, such as those\\ncharacterizing material properties, equation of state (EOS), opacities, and\\ninitial conditions. Typically, however, these parameters are not directly\\nobservable. What is observed instead is a time sequence of radiographic\\nprojections using X-rays. In this work, we define a set of sparse hydrodynamic\\nfeatures derived from the outgoing shock profile and outer material edge, which\\ncan be obtained from radiographic measurements, to directly infer such\\nparameters. Our machine learning (ML)-based methodology involves a pipeline of\\ntwo architectures, a radiograph-to-features network (R2FNet) and a\\nfeatures-to-parameters network (F2PNet), that are trained independently and\\nlater combined to approximate a posterior distribution for the parameters from\\nradiographs. We show that the estimated parameters can be used in a\\nhydrodynamics code to obtain density fields and hydrodynamic shock and outer\\nedge features that are consistent with the data. Finally, we demonstrate that\\nfeatures resulting from an unknown EOS model can be successfully mapped onto\\nparameters of a chosen analytical EOS model, implying that network predictions\\nare learning physics, with a degree of invariance to the underlying choice of\\nEOS model.',\n  'doi': None,\n  'update_date': '2024-12-31',\n  'version_no': '1'},\n {'id': 'astro-ph/0010155',\n  'title': 'A Hard Tail in the Broad Band Spectrum of the Dipper XB 1254-690',\n  'authors_parsed': [['Iaria', 'R.', ''],\n   ['Di Salvo', 'T.', ''],\n   ['Burderi', 'L.', ''],\n   ['Robba', 'N. R.', '']],\n  'submitter': 'Rosario Iaria',\n  'categories': 'astro-ph',\n  'abstract': 'We report on the results of spectral analysis of the dipping source XB\\n1254-690 observed by the BeppoSAX satellite. We find that the X-ray dips are\\nnot present during the BeppoSAX observation, in line with recent RXTE results.\\nThe broad band (0.1-100 keV) energy spectrum is well fitted by a\\nthree-component model consisting of a multicolor disk blackbody with an inner\\ndisk temperature of ~0.85 keV, a comptonized spectrum with an electron\\ntemperature of ~2 keV, and a bremsstrahlung at a temperature of ~20 keV.\\nAdopting a distance of 10 kpc and taking into account a spectral hardening\\nfactor of ~1.7 (because of electron scattering which modifies the blackbody\\nspectrum emitted by the disk) we estimated that the inner disk radius is\\n$R_{\\\\rm in} \\\\sqrt{\\\\cos i} \\\\sim 11$ km, where i is the inclination angle of the\\nsystem with respect to the line of sight. The comptonized component could\\noriginate in a spherical corona or boundary layer, surrounding the neutron\\nstar, with optical depth ~19. The bremsstrahlung emission, contributing ~4% of\\nthe total luminosity, probably originates in an extended accretion disk corona\\nwith radius $\\\\sim 10^{10}$ cm. In this scenario we calculated that the optical\\ndepth of this region is ~0.71 and its mean electron density is $N_e \\\\sim 2.7\\n\\\\times 10^{14}$ cm$^{-3}$. This last component might also be present in other\\nlow mass X-ray binaries, but, because of its low intrinsic luminosity, it is\\nnot easily observable. We also find an absorption edge at ~1.27 keV with an\\noptical depth of ~0.15. Its energy could correspond to the L-edge of Fe XVII,\\nor K-edge of Ne X or neutral Mg.',\n  'doi': '10.1086/319010',\n  'update_date': '2009-10-31',\n  'version_no': '1'},\n {'id': '1101.1969',\n  'title': 'Electromagnetic extraction of energy from black hole-neutron star\\n  binaries',\n  'authors_parsed': [['McWilliams', 'Sean T.', ''], ['Levin', 'Janna', '']],\n  'submitter': 'Sean McWilliams',\n  'categories': 'astro-ph.HE astro-ph.CO gr-qc',\n  'abstract': 'The coalescence of black hole-neutron star binaries is expected to be a\\nprincipal source of gravitational waves for the next generation of detectors,\\nAdvanced LIGO and Advanced Virgo. Ideally, these and other gravitational wave\\nsources would have a distinct electromagnetic counterpart, as significantly\\nmore information could be gained through two separate channels. In addition,\\nsince these detectors will probe distances with non-negligible redshift, a\\ncoincident observation of an electromagnetic counterpart to a gravitational\\nwave signal would facilitate a novel measurement of dark energy [1]. For black\\nhole masses not much larger than the neutron star mass, the tidal disruption\\nand subsequent accretion of the neutron star by the black hole provides one\\navenue for generating an electromagnetic counterpart [2]. However, in this\\nwork, we demonstrate that, for all black hole-neutron star binaries observable\\nby Advanced LIGO/Virgo, the interaction of the black hole with the magnetic\\nfield of the neutron star will drive a Poynting flux. This Poynting flux\\ngenerates synchrotron/curvature radiation as the electron-positron plasma in\\nthe neutron star magnetosphere is accel- erated, and thermal radiation as the\\nplasma is focused onto the neutron star magnetic poles, creating a \"hot spot\"\\non the neutron star surface. This novel effect will gener- ate copious\\nluminosity, comparable to supernovae and active galactic nuclei, so that black\\nhole-neutron star coalescences detectable with gravitational waves by Advanced\\nLIGO/Virgo could also potentially be detectable electromagnetically.',\n  'doi': '10.1088/0004-637X/742/2/90',\n  'update_date': '2015-05-27',\n  'version_no': '1'},\n {'id': '2205.15628',\n  'title': 'Seniorities and Minimal Clearing in Financial Network Games',\n  'authors_parsed': [['Hoefer', 'Martin', ''], ['Wilhelmi', 'Lisa', '']],\n  'submitter': 'Lisa Wilhelmi',\n  'categories': 'cs.GT',\n  'abstract': 'Financial network games model payment incentives in the context of networked\\nliabilities. In this paper, we advance the understanding of incentives in\\nfinancial networks in two important directions: minimal clearing (arising,\\ne.g., as a result of sequential execution of payments) and seniorities (i.e.,\\npriorities over debt contracts). We distinguish between priorities that are\\nchosen endogenously or exogenously. For endogenous priorities and standard\\n(maximal) clearing, the games exhibit a coalitional form of weak acyclicity. A\\nstrong equilibrium exists and can be reached after a polynomial number of\\ndeviations. Moreover, there is a strong equilibrium that is optimal for a wide\\nvariety of social welfare functions. In contrast, for minimal clearing there\\nare games in which no optimal strategy profile exists, even for standard\\nutilitarian social welfare. Perhaps surprisingly, a strong equilibrium still\\nexists and, for a wide range of strategies, can be reached after a polynomial\\nnumber of deviations. In contrast, for exogenous priorities, equilibria can be\\nabsent and equilibrium existence is NP-hard to decide, for both minimal and\\nmaximal clearing.',\n  'doi': None,\n  'update_date': '2022-06-01',\n  'version_no': '1'},\n {'id': '2103.01898',\n  'title': 'The search for the neutron electric dipole moment at PSI',\n  'authors_parsed': [['Pignol', 'Guillaume', ''],\n   ['Schmidt-Wellenburg', 'Philipp', '']],\n  'submitter': 'Philipp Schmidt-Wellenburg',\n  'categories': 'hep-ex physics.ins-det',\n  'abstract': 'The existence of a nonzero permanent electric dipole moment (EDM) of the\\nneutron would reveal a new source of CP violation and shed light on the origin\\nof the matter--antimatter asymmetry of the Universe. The sensitivity of current\\nexperiments using stored ultracold neutrons (UCN) probes new physics beyond the\\nTeV scale. Using the UCN source at the Paul Scherrer Institut, the nEDM\\ncollaboration has performed the most sensitive measurement of the neutron EDM\\nto date, still compatible with zero ($|d_n|<1.8\\\\times 10^{-26} \\\\, e {\\\\rm cm}$,\\nC.L.90%). A new experiment designed to improve the sensitivity by an order of\\nmagnitude, n2EDM, is currently in construction.',\n  'doi': None,\n  'update_date': '2021-03-03',\n  'version_no': '1'},\n {'id': 'hep-th/0102191',\n  'title': \"Wigner's little group, gauge transformations and dimensional descent\",\n  'authors_parsed': [['Banerjee', 'Rabin', ''],\n   ['Chakraborty', 'Biswajit', '']],\n  'submitter': 'Rabin Banerjee',\n  'categories': 'hep-th',\n  'abstract': \"We propose a technique called dimensional descent to show that Wigner's\\nlittle group for massless particles, which acts as a generator of gauge\\ntransformation for usual Maxwell theory, has an identical role even for\\ntopologically massive gauge theories. The examples of $B\\\\wedge F$ theory and\\nMaxwell-Chern-Simons theory are analyzed in details.\",\n  'doi': '10.1088/0305-4470/35/9/308',\n  'update_date': '2008-11-26',\n  'version_no': '2'},\n {'id': '0706.4435',\n  'title': 'Discovery of Very High Energy gamma-rays from 1ES 1011+496 at z=0.212',\n  'authors_parsed': [['MAGIC Collaboration', '', ''], ['Albert', 'J.', '']],\n  'submitter': 'Daniel Mazin',\n  'categories': 'astro-ph',\n  'abstract': 'We report on the discovery of Very High Energy (VHE) gamma-ray emission from\\nthe BL Lacertae object 1ES1011+496. The observation was triggered by an optical\\noutburst in March 2007 and the source was observed with the MAGIC telescope\\nfrom March to May 2007. Observing for 18.7 hr we find an excess of 6.2 sigma\\nwith an integrated flux above 200 GeV of (1.58$\\\\pm0.32) 10^{-11}$ photons\\ncm$^{-2}$ s$^{-1}$. The VHE gamma-ray flux is >40% higher than in March-April\\n2006 (reported elsewhere), indicating that the VHE emission state may be\\nrelated to the optical emission state. We have also determined the redshift of\\n1ES1011+496 based on an optical spectrum that reveals the absorption lines of\\nthe host galaxy. The redshift of z=0.212 makes 1ES1011+496 the most distant\\nsource observed to emit VHE gamma-rays up to date.',\n  'doi': '10.1086/521982',\n  'update_date': '2008-11-26',\n  'version_no': '2'},\n {'id': '0806.4634',\n  'title': 'B0-B0bar mixing',\n  'authors_parsed': [['Schneider', 'Olivier', '']],\n  'submitter': 'Olivier Schneider',\n  'categories': 'hep-ex',\n  'abstract': 'The subject of particle-antiparticle mixing in the neutral B meson systems is\\nreviewed. The formalism of B0-B0bar mixing is recalled and basic Standard Model\\npredictions are given, before experimental issues are discussed and the latest\\ncombinations of experimental results on mixing parameters are presented,\\nincluding those on mixing-induced CP violation, mass differences, and\\ndecay-width differences. Finally, time-integrated mixing results are used to\\nimprove our knowledge on the fractions of the various b-hadron species produced\\nin Z decays and at high-energy colliders.',\n  'doi': None,\n  'update_date': '2008-07-01',\n  'version_no': '1'},\n {'id': '0901.1367',\n  'title': 'Rashba-induced transverse pure spin currents in a four-terminal quantum\\n  dot ring',\n  'authors_parsed': [['Gong', 'Weijiang', ''],\n   ['Han', 'Yu', ''],\n   ['Wei', 'Guozhu', ''],\n   ['Zheng', 'Yisong', '']],\n  'submitter': 'Weijiang Gong',\n  'categories': 'cond-mat.mes-hall cond-mat.str-el',\n  'abstract': 'By applying a local Rashba spin-orbit interaction on an individual quantum\\ndot of a four-terminal four-quantum-dot ring and introducing a finite bias\\nbetween the longitudinal terminals, we theoretically investigate the charge and\\nspin currents in the transverse terminals. It is found that when the quantum\\ndot levels are separate from the chemical potentials of the transverse\\nterminals, notable pure spin currents appear in the transverse terminals with\\nthe same amplitude and opposite polarization directions. Besides, the\\npolarization directions of such pure spin currents can be inverted by altering\\nstructure parameters, i.e., the magnetic flux, the bias voltage, and the values\\nof quantum dot levels with respect to the chemical potentials of the transverse\\nterminals.',\n  'doi': '10.1016/j.ssc.2009.07.005',\n  'update_date': '2015-05-13',\n  'version_no': '1'},\n {'id': '1703.02277',\n  'title': '\"Mass Without Mass\" and Nuclear Matter',\n  'authors_parsed': [['Rho', 'Mannque', '']],\n  'submitter': 'Mannque Rho',\n  'categories': 'nucl-th hep-ph',\n  'abstract': 'This is a brief account of the chief accomplishment of the 5-year activity\\n(2008-2013) in the World Class University III Program at Hanyang University\\nwith the theme of exploring \"From Dense Matter to Compact Stars.\" The principal\\nobjective was to explore and foresee what could be a break-through research\\nthat could be initiated at the RIB machine in project \"RAON\" at the upcoming\\nambitious Institute for Basic Science (IBS) in Korea. What came out was a\\npossibility for unraveling the mystery of proton\\'s \"mass without mass\" via\\nnuclear matter and its impact on RAON-type physics and compact stars.',\n  'doi': None,\n  'update_date': '2017-03-08',\n  'version_no': '1'},\n {'id': 'nlin/0403051',\n  'title': 'Integrable equations in nonlinear geometrical optics',\n  'authors_parsed': [['Konopelchenko', 'Boris G.', ''],\n   ['Moro', 'Antonio', '']],\n  'submitter': 'Antonio Moro',\n  'categories': 'nlin.SI physics.class-ph',\n  'abstract': 'Geometrical optics limit of the Maxwell equations for nonlinear media with\\nthe Cole-Cole dependence of dielectric function and magnetic permeability on\\nthe frequency is considered. It is shown that for media with slow variation\\nalong one axis such a limit gives rise to the dispersionless Veselov-Novikov\\nequation for the refractive index. It is demonstrated that the Veselov-Novikov\\nhierarchy is amenable to the quasiclassical DBAR-dressing method. Under more\\nspecific requirements for the media, one gets the dispersionless\\nKadomtsev-Petviashvili equation. Geometrical optics interpretation of some\\nsolutions of the above equations is discussed.',\n  'doi': '10.1111/j.0022-2526.2004.01536.x',\n  'update_date': '2012-10-01',\n  'version_no': '1'},\n {'id': '2206.01211',\n  'title': 'Electrically pumped quantum-dot lasers grown on 300 mm patterned Si\\n  photonic wafers',\n  'authors_parsed': [['Shang', 'Chen', ''],\n   ['Feng', 'Kaiyin', ''],\n   ['Hughes', 'Eamonn T.', ''],\n   ['Clark', 'Andrew', ''],\n   ['Debnath', 'Mukul', ''],\n   ['Koscica', 'Rosalyn', ''],\n   ['Leake', 'Gerald', ''],\n   ['Herman', 'Joshua', ''],\n   ['Harame', 'David', ''],\n   ['Ludewig', 'Peter', ''],\n   ['Wan', 'Yating', ''],\n   ['Bowers', 'John E.', '']],\n  'submitter': 'Chen Shang',\n  'categories': 'physics.optics cs.ET',\n  'abstract': 'Monolithic integration of quantum dot (QD) gain materials onto Si photonic\\nplatforms via direct epitaxial growth is a promising solution for on-chip light\\nsources. Recent developments have demonstrated superior device reliability in\\nblanket hetero-epitaxy of III-V devices on Si at elevated temperatures. Yet,\\nthick, defect management epi designs prevent vertical light coupling from the\\ngain region to the Si-on-Insulator (SOI) waveguides. Here, we demonstrate the\\nfirst electrically pumped QD lasers grown on a 300 mm patterned (001) Si wafer\\nwith a butt-coupled configuration by molecular beam epitaxy (MBE). Unique\\ngrowth and fabrication challenges imposed by the template architecture have\\nbeen resolved, contributing to continuous wave lasing to 60 {\\\\deg}C and a\\nmaximum double-side output power of 126.6 mW at 20 {\\\\deg}C with a double-side\\nwall plug efficiency of 8.6%. The potential for robust on-chip laser operation\\nand efficient low-loss light coupling to Si photonic circuits makes this\\nheteroepitaxial integration platform on Si promising for scalable and low-cost\\nmass production.',\n  'doi': None,\n  'update_date': '2022-06-06',\n  'version_no': '1'},\n {'id': '1708.07834',\n  'title': 'Origin of chemically distinct discs in the Auriga cosmological\\n  simulations',\n  'authors_parsed': [['Grand', 'Robert J. J.', ''],\n   ['Bustamante', 'Sebastián', ''],\n   ['Gómez', 'Facundo A.', ''],\n   ['Kawata', 'Daisuke', ''],\n   ['Marinacci', 'Federico', ''],\n   ['Pakmor', 'Rüdiger', ''],\n   ['Rix', 'Hans-Walter', ''],\n   ['Simpson', 'Christine M.', ''],\n   ['Sparre', 'Martin', ''],\n   ['Springel', 'Volker', '']],\n  'submitter': 'Robert Grand',\n  'categories': 'astro-ph.GA astro-ph.CO astro-ph.SR',\n  'abstract': 'The stellar disk of the Milky Way shows complex spatial and abundance\\nstructure that is central to understanding the key physical mechanisms\\nresponsible for shaping our Galaxy. In this study, we use six very high\\nresolution cosmological zoom simulations of Milky Way-sized haloes to study the\\nprevalence and formation of chemically distinct disc components. We find that\\nour simulations develop a clearly bimodal distribution in the $[\\\\rm \\\\alpha/Fe]$\\n-- $[\\\\rm Fe/H]$ plane. We find two main pathways to creating this dichotomy\\nwhich operate in different regions of the galaxies: a) an early ($z>1$) and\\nintense high-$\\\\rm[\\\\alpha/Fe]$ star formation phase in the inner region\\n($R\\\\lesssim 5$ kpc) induced by gas-rich mergers, followed by more quiescent\\nlow-$\\\\rm[\\\\alpha/Fe]$ star formation; and b) an early phase of\\nhigh-$\\\\rm[\\\\alpha/Fe]$ star formation in the outer disc followed by a shrinking\\nof the gas disc owing to a temporarily lowered gas accretion rate, after which\\ndisc growth resumes. In process b), a double-peaked star formation history\\naround the time and radius of disc shrinking accentuates the dichotomy. If the\\nearly star formation phase is prolonged (rather than short and intense),\\nchemical evolution proceeds as per process a) in the inner region, but the\\ndichotomy is less clear. In the outer region, the dichotomy is only evident if\\nthe first intense phase of star formation covers a large enough radial range\\nbefore disc shrinking occurs; otherwise, the outer disc consists of only\\nlow-$\\\\rm[\\\\alpha/Fe]$ sequence stars. We discuss the implication that both\\nprocesses occurred in the Milky Way.',\n  'doi': '10.1093/mnras/stx3025',\n  'update_date': '2017-12-27',\n  'version_no': '2'},\n {'id': '1603.04800',\n  'title': 'A Dressed Spin Qubit in Silicon',\n  'authors_parsed': [['Laucht', 'Arne', ''],\n   ['Kalra', 'Rachpon', ''],\n   ['Simmons', 'Stephanie', ''],\n   ['Dehollain', 'Juan P.', ''],\n   ['Muhonen', 'Juha T.', ''],\n   ['Mohiyaddin', 'Fahd A.', ''],\n   ['Freer', 'Solomon', ''],\n   ['Hudson', 'Fay E.', ''],\n   ['Itoh', 'Kohei M.', ''],\n   ['Jamieson', 'David N.', ''],\n   ['McCallum', 'Jeffrey C.', ''],\n   ['Dzurak', 'Andrew S.', ''],\n   ['Morello', 'A.', '']],\n  'submitter': 'Arne Laucht Dr.',\n  'categories': 'cond-mat.mes-hall quant-ph',\n  'abstract': 'Coherent dressing of a quantum two-level system provides access to a new\\nquantum system with improved properties - a different and easily tuneable level\\nsplitting, faster control, and longer coherence times. In our work we\\ninvestigate the properties of the dressed, donor-bound electron spin in\\nsilicon, and probe its potential for the use as quantum bit in scalable\\narchitectures. The two dressed spin-polariton levels constitute a quantum bit\\nthat can be coherently driven with an oscillating magnetic field, an\\noscillating electric field, by frequency modulating the driving field, or by a\\nsimple detuning pulse. We measure coherence times of $T_{2\\\\rho}^*=2.4$ ms and\\n$T_{2\\\\rho}^{\\\\rm Hahn}=9$ ms, one order of magnitude longer than those of the\\nundressed qubit. Furthermore, the use of the dressed states enables coherent\\ncoupling of the solid-state spins to electric fields and mechanical\\noscillations.',\n  'doi': '10.1038/nnano.2016.178',\n  'update_date': '2016-10-21',\n  'version_no': '1'},\n {'id': '2201.09865',\n  'title': 'RePaint: Inpainting using Denoising Diffusion Probabilistic Models',\n  'authors_parsed': [['Lugmayr', 'Andreas', ''],\n   ['Danelljan', 'Martin', ''],\n   ['Romero', 'Andres', ''],\n   ['Yu', 'Fisher', ''],\n   ['Timofte', 'Radu', ''],\n   ['Van Gool', 'Luc', '']],\n  'submitter': 'Andreas Lugmayr',\n  'categories': 'cs.CV',\n  'abstract': 'Free-form inpainting is the task of adding new content to an image in the\\nregions specified by an arbitrary binary mask. Most existing approaches train\\nfor a certain distribution of masks, which limits their generalization\\ncapabilities to unseen mask types. Furthermore, training with pixel-wise and\\nperceptual losses often leads to simple textural extensions towards the missing\\nareas instead of semantically meaningful generation. In this work, we propose\\nRePaint: A Denoising Diffusion Probabilistic Model (DDPM) based inpainting\\napproach that is applicable to even extreme masks. We employ a pretrained\\nunconditional DDPM as the generative prior. To condition the generation\\nprocess, we only alter the reverse diffusion iterations by sampling the\\nunmasked regions using the given image information. Since this technique does\\nnot modify or condition the original DDPM network itself, the model produces\\nhigh-quality and diverse output images for any inpainting form. We validate our\\nmethod for both faces and general-purpose image inpainting using standard and\\nextreme masks.\\n  RePaint outperforms state-of-the-art Autoregressive, and GAN approaches for\\nat least five out of six mask distributions.\\n  Github Repository: git.io/RePaint',\n  'doi': None,\n  'update_date': '2022-09-01',\n  'version_no': '4'},\n {'id': 'cond-mat/0002406',\n  'title': 'Quenched noise and over-active sites in sandpile dynamics',\n  'authors_parsed': [['Alava', 'Mikko J.', ''],\n   ['Lauritsen', 'Kent Bækgaard', '']],\n  'submitter': 'Mikko Alava',\n  'categories': 'cond-mat.stat-mech',\n  'abstract': 'The dynamics of sandpile models are mapped to discrete interface equations.\\nWe study in detail the Bak-Tang-Wiesenfeld model, a stochastic model with\\nrandom thresholds, and the Manna model. These are, respectively,\\ndiscretizations of the quenched Edwards-Wilkinson equation with columnar,\\npoint-like and correlated noise, with the constraint that the interface\\nvelocity is either zero or exactly one. The constraint, embedded in the\\nsandpile rules, gives rise to another noise component. This term has for the\\nBak-Tang-Wiesenfeld model long-range on-site correlations and reveals that with\\nopen boundary conditions there is no spatial translational invariance.',\n  'doi': '10.1209/epl/i2001-00189-8',\n  'update_date': '2009-10-31',\n  'version_no': '2'},\n {'id': '1408.0615',\n  'title': 'Ground state of a homogeneous Bose gas of hard spheres',\n  'authors_parsed': [['Yukalov', 'V. I.', ''], ['Yukalova', 'E. P.', '']],\n  'submitter': 'Vyacheslav Yukalov',\n  'categories': 'cond-mat.quant-gas',\n  'abstract': 'The ground state of a homogeneous Bose gas of hard spheres is treated in\\nself-consistent mean-field theory. It is shown that this approach provides an\\naccurate description of the ground state of a Bose-Einstein condensed gas for\\narbitrarily strong interactions. The results are in good agreement with Monte\\nCarlo numerical calculations. Since all other mean-field approximations are\\nvalid only for very small gas parameters, the present self-consistent theory is\\na unique mean-field approach allowing for an accurate description of Bose\\nsystems at arbitrary values of the gas parameter.',\n  'doi': '10.1103/PhysRevA.90.013627',\n  'update_date': '2015-06-22',\n  'version_no': '1'},\n {'id': '1302.6338',\n  'title': 'Term Graph Representations for Cyclic Lambda-Terms',\n  'authors_parsed': [['Grabmayer',\n    'Clemens',\n    '',\n    'Department of Philosophy, Utrecht University, The\\n  Netherlands'],\n   ['Rochel',\n    'Jan',\n    '',\n    'Department of Computing Sciences, Utrecht\\n  University, The Netherlands']],\n  'submitter': 'EPTCS',\n  'categories': 'cs.LO cs.PL',\n  'abstract': \"We study various representations for cyclic lambda-terms as higher-order or\\nas first-order term graphs. We focus on the relation between\\n'lambda-higher-order term graphs' (lambda-ho-term-graphs), which are\\nfirst-order term graphs endowed with a well-behaved scope function, and their\\nrepresentations as 'lambda-term-graphs', which are plain first-order term\\ngraphs with scope-delimiter vertices that meet certain scoping requirements.\\nSpecifically we tackle the question: Which class of first-order term graphs\\nadmits a faithful embedding of lambda-ho-term-graphs in the sense that (i) the\\nhomomorphism-based sharing-order on lambda-ho-term-graphs is preserved and\\nreflected, and (ii) the image of the embedding corresponds closely to a natural\\nclass (of lambda-term-graphs) that is closed under homomorphism?\\n  We systematically examine whether a number of classes of lambda-term-graphs\\nhave this property, and we find a particular class of lambda-term-graphs that\\nsatisfies this criterion. Term graphs of this class are built from application,\\nabstraction, variable, and scope-delimiter vertices, and have the\\ncharacteristic feature that the latter two kinds of vertices have back-links to\\nthe corresponding abstraction.\\n  This result puts a handle on the concept of subterm sharing for higher-order\\nterm graphs, both theoretically and algorithmically: We obtain an easily\\nimplementable method for obtaining the maximally shared form of\\nlambda-ho-term-graphs. Furthermore, we open up the possibility to pull back\\nproperties from first-order term graphs to lambda-ho-term-graphs, properties\\nsuch as the complete lattice structure of bisimulation equivalence classes with\\nrespect to the sharing order.\",\n  'doi': '10.4204/EPTCS.110.7',\n  'update_date': '2013-02-27',\n  'version_no': '1'},\n {'id': '2107.12872',\n  'title': 'LOB modeling using Hawkes processes with a state-dependent factor',\n  'authors_parsed': [['Sfendourakis', 'Emmanouil', ''],\n   ['Toke', 'Ioane Muni', '']],\n  'submitter': 'Ioane Muni Toke',\n  'categories': 'q-fin.TR q-fin.ST',\n  'abstract': 'A point process model for order flows in limit order books is proposed, in\\nwhich the conditional intensity is the product of a Hawkes component and a\\nstate-dependent factor. In the LOB context, state observations may include the\\nobserved imbalance or the observed spread. Full technical details for the\\ncomputationally-efficient estimation of such a process are provided, using\\neither direct likelihood maximization or EM-type estimation. Applications\\ninclude models for bid and ask market orders, or for upwards and downwards\\nprice movements. Empirical results on multiple stocks traded in Euronext Paris\\nunderline the benefits of state-dependent formulations for LOB modeling, e.g.\\nin terms of goodness-of-fit to financial data.',\n  'doi': None,\n  'update_date': '2021-12-06',\n  'version_no': '2'},\n {'id': '1303.2530',\n  'title': 'Infinite-dimensional Bayesian filtering for detection of quasi-periodic\\n  phenomena in spatio-temporal data',\n  'authors_parsed': [['Solin', 'Arno', ''], ['Särkkä', 'Simo', '']],\n  'submitter': 'Arno Solin',\n  'categories': 'stat.CO',\n  'abstract': 'This paper introduces a spatio-temporal resonator model and an inference\\nmethod for detection and estimation of nearly periodic temporal phenomena in\\nspatio-temporal data. The model is derived as a spatial extension of a\\nstochastic harmonic resonator model, which can be formulated in terms of a\\nstochastic differential equation (SDE). The spatial structure is included by\\nintroducing linear operators, which affect both the oscillations and damping,\\nand by choosing the appropriate spatial covariance structure of the driving\\ntime-white noise process. With the choice of the linear operators as partial\\ndifferential operators, the resonator model becomes a stochastic partial\\ndifferential equation (SPDE), which is compatible with infinite-dimensional\\nKalman filtering. The resulting infinite-dimensional Kalman filtering problem\\nallows for a computationally efficient solution as the computational cost\\nscales linearly with measurements in the temporal dimension. This framework is\\napplied to weather prediction and to physiological noise elimination in fMRI\\nbrain data.',\n  'doi': '10.1103/PhysRevE.88.052909',\n  'update_date': '2013-12-23',\n  'version_no': '2'},\n {'id': '2401.06417',\n  'title': 'Machine learning holographic black hole from lattice QCD equation of\\n  state',\n  'authors_parsed': [['Chen', 'Xun', ''], ['Huang', 'Mei', '']],\n  'submitter': 'Xun Chen',\n  'categories': 'hep-ph hep-lat',\n  'abstract': 'Based on lattice QCD results of equation of state (EOS) and baryon number\\nsusceptibility at zero baryon chemical potential, and supplemented by machine\\nlearning techniques, we construct the analytic form of the holographic black\\nhole metric in the Einstein-Maxwell-Dilaton (EMD) framework for pure gluon,\\n2-flavor, and 2+1-flavor systems, respectively. The dilaton potentials solved\\nfrom Einstein equations are in good agreement with the extended non-conformal\\nDeWolfe-Gubser-Rosen (DGR) type dilaton potentials fixed by lattice QCD EOS,\\nwhich indicates the robustness of the EMD framework. The predicted critical\\nendpoint (CEP) in the 2+1-flavor system is located at $(T^c$=0.094GeV,\\n$\\\\mu^c_B$=0.74GeV), which is close to the results from the realistic\\nPolyakov-Nambu-Jona-Lasinio(PNJL) model, the functional renormalization group,\\nand the holographic model with extended DeWolfe-Gubser-Rosen dilaton potential.',\n  'doi': None,\n  'update_date': '2024-04-02',\n  'version_no': '2'},\n {'id': '1611.06993',\n  'title': 'An ultraviolet excess in the superluminous supernova Gaia16apd reveals a\\n  powerful central engine',\n  'authors_parsed': [['Nicholl', 'M.', ''],\n   ['Berger', 'E.', ''],\n   ['Margutti', 'R.', ''],\n   ['Blanchard', 'P. K.', ''],\n   ['Milisavljevic', 'D.', ''],\n   ['Challis', 'P.', ''],\n   ['Metzger', 'B. D.', ''],\n   ['Chornock', 'R.', '']],\n  'submitter': 'Matt Nicholl',\n  'categories': 'astro-ph.SR astro-ph.CO astro-ph.HE',\n  'abstract': 'Since the discovery of superluminous supernovae (SLSNe) in the last decade,\\nit has been known that these events exhibit bluer spectral energy distributions\\nthan other supernova subtypes, with significant output in the ultraviolet.\\nHowever, the event Gaia16apd seems to outshine even the other SLSNe at\\nrest-frame wavelengths below $\\\\sim 3000$ \\\\AA. Yan et al (2016) have recently\\npresented HST UV spectra and attributed the UV flux to low metallicity and\\nhence reduced line blanketing. Here we present UV and optical light curves over\\na longer baseline in time, revealing a rapid decline at UV wavelengths despite\\na typical optical evolution. Combining the published UV spectra with our own\\noptical data, we demonstrate that Gaia16apd has a much hotter continuum than\\nvirtually any SLSN at maximum light, but it cools rapidly thereafter and is\\nindistinguishable from the others by $\\\\sim 10$-15 days after peak. Comparing\\nthe equivalent widths of UV absorption lines with those of other events, we\\nshow that the excess UV continuum is a result of a more powerful central power\\nsource, rather than a lack of UV absorption relative to other SLSNe or an\\nadditional component from interaction with the surrounding medium. These\\nfindings strongly support the central-engine hypothesis for hydrogen-poor\\nSLSNe. An explosion ejecting $M_{\\\\rm ej} = 4 (0.2/\\\\kappa)$ M$_\\\\odot$, where\\n$\\\\kappa$ is the opacity in cm$^2$g$^{-1}$, and forming a magnetar with spin\\nperiod $P=2$ ms, and $B=2\\\\times10^{14}$ G (lower than other SLSNe with\\ncomparable rise-times) can consistently explain the light curve evolution and\\nhigh temperature at peak. The host metallicity, $Z=0.18$ Z$_\\\\odot$, is\\ncomparable to other SLSNe.',\n  'doi': '10.3847/2041-8213/aa56c5',\n  'update_date': '2017-01-23',\n  'version_no': '3'},\n {'id': '2307.13531',\n  'title': 'Weyl-invariant scalar-tensor gravities from purely metric theories',\n  'authors_parsed': [['Anastasiou', 'Giorgos', ''],\n   ['Araya', 'Ignacio J.', ''],\n   ['Chakraborty', 'Avik', '']],\n  'submitter': 'Avik Chakraborty',\n  'categories': 'hep-th gr-qc',\n  'abstract': 'We describe a method to generate scalar-tensor theories with Weyl symmetry,\\nstarting from arbitrary purely metric higher derivative gravity theories. The\\nmethod consists in the definition of a conformally-invariant metric\\n$\\\\hat{g}_{\\\\mu \\\\nu}$, that is a rank (0,2)-tensor constructed out of the metric\\ntensor and the scalar field. This new object has zero conformal weight and is\\ngiven by $\\\\phi^{2/\\\\Delta}g_{\\\\mu \\\\nu}$, where ($-\\\\Delta$) is the conformal\\ndimension of the scalar. As $g_{\\\\mu \\\\nu}$ has conformal dimension of 2, the\\nresulting tensor is trivially a conformal invariant. Then, the generated\\nscalar-tensor theory, which we call the Weyl uplift of the original purely\\nmetric theory, is obtained by replacing the metric by $\\\\hat{g}_{\\\\mu \\\\nu}$ in\\nthe action that defines the original theory. This prescription allowed us to\\ndefine the Weyl uplift of theories with terms of higher order in the Riemannian\\ncurvature. Furthermore, the prescription for scalar-tensor theories coming from\\nterms that have explicit covariant derivatives in the Lagrangian is discussed.\\nThe same mechanism can also be used for the derivation of the equations of\\nmotion of the scalar-tensor theory from the original field equations in the\\nEinstein frame. Applying this method of Weyl uplift allowed us to reproduce the\\nknown result for the conformal scalar coupling to Lovelock gravity and to\\nderive that of Einsteinian cubic gravity. Finally, we show that the\\nrenormalization of the theory given by the conformal scalar coupling to\\nEinstein-Anti-de Sitter gravity originates from the Weyl uplift of the original\\nrenormalized theory, which is relevant in the framework of conformal\\nrenormalization.',\n  'doi': None,\n  'update_date': '2023-12-12',\n  'version_no': '3'},\n {'id': '2408.06779',\n  'title': 'ED$^4$: Explicit Data-level Debiasing for Deepfake Detection',\n  'authors_parsed': [['Cheng', 'Jikang', ''],\n   ['Zhang', 'Ying', ''],\n   ['Zou', 'Qin', ''],\n   ['Yan', 'Zhiyuan', ''],\n   ['Liang', 'Chao', ''],\n   ['Wang', 'Zhongyuan', ''],\n   ['Li', 'Chen', '']],\n  'submitter': 'Jikang Cheng',\n  'categories': 'cs.CV',\n  'abstract': 'Learning intrinsic bias from limited data has been considered the main reason\\nfor the failure of deepfake detection with generalizability. Apart from the\\ndiscovered content and specific-forgery bias, we reveal a novel spatial bias,\\nwhere detectors inertly anticipate observing structural forgery clues appearing\\nat the image center, also can lead to the poor generalization of existing\\nmethods. We present ED$^4$, a simple and effective strategy, to address\\naforementioned biases explicitly at the data level in a unified framework\\nrather than implicit disentanglement via network design. In particular, we\\ndevelop ClockMix to produce facial structure preserved mixtures with arbitrary\\nsamples, which allows the detector to learn from an exponentially extended data\\ndistribution with much more diverse identities, backgrounds, local manipulation\\ntraces, and the co-occurrence of multiple forgery artifacts. We further propose\\nthe Adversarial Spatial Consistency Module (AdvSCM) to prevent extracting\\nfeatures with spatial bias, which adversarially generates spatial-inconsistent\\nimages and constrains their extracted feature to be consistent. As a\\nmodel-agnostic debiasing strategy, ED$^4$ is plug-and-play: it can be\\nintegrated with various deepfake detectors to obtain significant benefits. We\\nconduct extensive experiments to demonstrate its effectiveness and superiority\\nover existing deepfake detection approaches.',\n  'doi': None,\n  'update_date': '2024-08-14',\n  'version_no': '1'},\n {'id': '0805.3601',\n  'title': '3D Lyman-alpha radiation transfer. III. Constraints on gas and stellar\\n  properties of z~3 Lyman break galaxies (LBG) and implications for high-z LBGs\\n  and Lyman-alpha emitters(LAEs)',\n  'authors_parsed': [['Verhamme', 'Anne', '', 'ObsGE'],\n   ['Schaerer', 'Daniel', '', 'ObsGE, OMP'],\n   ['Atek', 'Hakim', '', 'IAP'],\n   ['Tapken', 'Christian', '', 'MPIA']],\n  'submitter': 'Anne Verhamme',\n  'categories': 'astro-ph',\n  'abstract': 'The Aim of our study is to understand the variety of observed Lyman-alpha\\n(Lya) line profiles and strengths in Lyman Break Galaxies (LBGs) and Lya\\nemitters (LAEs), the physical parameters governing them, and hence deriving\\nconstraints on the gas and dust content and stellar populations of these\\nobjects.\\n  Using our 3D Lya radiation transfer code including gas and dust (Verhamme et\\nal. 2006), we fit 11 LBGs from the FORS Deep Field with redshifts between 2.8\\nand 5 observed by Tapken et al. (2007). A simple geometry of a spherically\\nexpanding shell of HI is adopted.\\n  RESULTS : The variety of observed Lya profiles is successfully reproduced.\\nMost objects show outflow velocities of 150-200 km/s; two objects are most\\nlikely quasi-static. The radial HI column density ranges from NH=2.10^{19} to\\n7.10^{20} cm^{-2}. Our Lya profile fits yield values of E(B-V)~0.05-0.2 for the\\ngas extinction. We find indications for a dust-to-gas ratio higher than the\\nGalactic value, and for a substantial scatter. The escape fraction of Lya\\nphotons is found to be determined primarily by the extinction, and a simple fit\\nformula is proposed. Intrinsic EW(Lya)~50-100 Angstroms are found for 8/11\\nobjects, as expected for stellar populations forming constantly over long\\nperiods (> 10-100 Myr). In three cases we found indications for younger\\npopulations. Correlations between the observed EW(Lya) and other observables\\nsuch as FWHM(Lya), E(B-V),SFR(UV) etc, are reproduced. We also show that there\\nis a clear overlap between LBGs and LAEs. Radiation transfer and dust effects\\nexplain the increase of the LAE/LBG ratio, and a higher percentage of LBGs with\\nstrong Lya emission with increasing redshift. [shortened]',\n  'doi': '10.1051/0004-6361:200809648',\n  'update_date': '2009-11-13',\n  'version_no': '1'},\n {'id': '2207.06043',\n  'title': 'Characterization of micro-Capsules Deformation in Branching Channels',\n  'authors_parsed': [['Coclite', 'Alessandro', ''],\n   ['de Tullio', 'Marco D.', ''],\n   ['Pascazio', 'Giuseppe', ''],\n   ['Politi', 'Tiziano', '']],\n  'submitter': 'Alessandro Coclite',\n  'categories': 'physics.flu-dyn cs.NA math.NA',\n  'abstract': 'In this paper, the dynamic of inertial capsules into microfluidic\\nbifurcations is studied. The fluid evolution is based on the solution of the\\nBGK -- lattice Boltzmann scheme including a forcing term accounting for\\nimmersed geometries. The dynamic-Immersed Boundary forcing strategy is adopted\\nfor imposing no-slip boundary conditions on moving deformable or rigid\\nstructures, while, on fixed immersed geometries the Bouzidi-Firdaouss-Lallemand\\nsecond-order bounce back technique is implemented. The proposed computational\\nframework is employed to detail dynamics and deformation of rigid and\\ndeformable capsules traveling into a branching duct. This journey is\\ncharacterized in terms of i) the capsule/bifurcation interaction depending on\\nthe sharpness of the branching channels junction; ii) daughter branches\\naperture angle; iii) occlusion ratio, the ratio between capsule size and main\\nchannel diameter; iv) flowing capsules stiffness; v) number of flowing\\nparticles.',\n  'doi': '10.1016/j.amc.2022.127445',\n  'update_date': '2022-08-10',\n  'version_no': '1'},\n {'id': '1711.05510',\n  'title': 'Scalar one-loop vertex integrals as meromorphic functions of space-time\\n  dimension d',\n  'authors_parsed': [['Bluemlein', 'Johannes', '', 'DESY'],\n   ['Phan', 'Khiem Hong', '', 'DESY', 'Vietnam National University'],\n   ['Riemann', 'Tord', '', 'DESY', 'University of Silesia']],\n  'submitter': 'Tord Riemann',\n  'categories': 'hep-ph',\n  'abstract': 'Representations are derived for the basic scalar one-loop vertex Feynman\\nintegrals as meromorphic functions of the space-time dimension $d$ in terms of\\n(generalized) hypergeometric functions $_2F_1$ and $F_1$. Values at asymptotic\\nor exceptional kinematic points as well as expansions around the singular\\npoints at $d=4+2n$, $n$ non-negative integers, may be derived from the\\nrepresentations easily. The Feynman integrals studied here may be used as\\nbuilding blocks for the calculation of one-loop and higher-loop scalar and\\ntensor amplitudes. From the recursion relation presented, higher n-point\\nfunctions may be obtained in a straightforward manner.',\n  'doi': '10.5506/APhysPolB.48.2313',\n  'update_date': '2018-05-09',\n  'version_no': '1'},\n {'id': '0905.0868',\n  'title': 'Search for B^0 Meson Decays to \\\\pi^0 K^0_SK^0_S, \\\\eta K^0_S K^0_S, and\\n  \\\\eta^{\\\\prime}K^0_SK^0_S',\n  'authors_parsed': [['The BABAR Collaboration', '', ''],\n   ['Aubert', 'B.', '']],\n  'submitter': 'Pietro Biassoni',\n  'categories': 'hep-ex',\n  'abstract': 'We describe searches for $B^0$ meson decays to the charmless final states\\n$\\\\pi^0 K^0_SK^0_S$, $\\\\eta K^0_S K^0_S$, and $\\\\eta^{\\\\prime}K^0_SK^0_S$. The data\\nsample corresponds to $467 \\\\times 10^{6}$ $B\\\\bar{B}$ pairs produced in $e^+e^-$\\nannihilation and collected with the BABAR detector at the SLAC National\\nAccelerator Laboratory. We find no significant signals and determine the 90%\\nconfidence level upper limits on the branching fractions, in units of\\n$10^{-7}$, $\\\\cal{B}(B^0 \\\\ra \\\\pi^0K^0_SK^0_S) <9 $, $\\\\cal{B}(B^0 \\\\ra \\\\eta\\nK^0_SK^0_S) <10$, and $\\\\cal{B}(B^0 \\\\ra \\\\eta^{\\\\prime}K^0_SK^0_S) <20$.',\n  'doi': '10.1103/PhysRevD.80.011101',\n  'update_date': '2010-04-12',\n  'version_no': '2'},\n {'id': '1704.08112',\n  'title': 'Categorical Accommodation of Graded Fuzzy Topological System, Graded\\n  Frame and Fuzzy Topological Space with Graded inclusion',\n  'authors_parsed': [['Jana', 'Purbita', ''], ['Chakraborty', 'Mihir K.', '']],\n  'submitter': 'Purbita Jana',\n  'categories': 'math.GM',\n  'abstract': 'A detailed study of graded frame, graded fuzzy topological system and fuzzy\\ntopological space with graded inclusion is already done in our earlier paper.\\nThe notions of graded fuzzy topological system and fuzzy topological space with\\ngraded inclusion were obtained via fuzzy geometric logic with graded con-\\nsequence. As an off shoot the notion of graded frame has been developed. This\\npaper deals with a detailed categorical study of graded frame, graded fuzzy\\ntopological system and fuzzy topological space with graded inclusion and their\\ninterrelation.',\n  'doi': None,\n  'update_date': '2017-04-27',\n  'version_no': '1'},\n {'id': 'hep-ph/0008231',\n  'title': 'Single neutral heavy lepton production at electron-muon colliders',\n  'authors_parsed': [['Almeida', 'F. M. L.', 'Jr.'],\n   ['Coutinho', 'Y. A.', ''],\n   ['Simoes', 'J. A. Martins', ''],\n   ['Vale', 'M. A. B. do', '']],\n  'submitter': 'Yara do Amaral Coutinho',\n  'categories': 'hep-ph',\n  'abstract': 'New heavy Majorana and Dirac neutrinos production at future electron-muon\\ncolliders are investigated. The production of a single heavy neutrino is shown\\nto be more relevant than pair production when comparing cross sections and\\nneutrino mass ranges. The process $e^\\\\pm \\\\mu^\\\\mp \\\\longrightarrow {\\\\nu}\\n\\\\ell^{\\\\pm} W^{\\\\mp}$ is studied including on-shell and off-shell heavy neutrino\\neffects. Distributions are calculated including hadronization effects and\\nexperimental cuts that suppress background, in order to have a clear signal for\\nheavy neutral leptons.',\n  'doi': '10.1016/S0370-2693(00)01195-3',\n  'update_date': '2019-08-17',\n  'version_no': '2'},\n {'id': '0803.0221',\n  'title': 'Masses and Magnetic Moments of Charmed Baryons Using Hyper Central Model',\n  'authors_parsed': [['Patel', 'Bhavin', ''],\n   ['Rai', 'Ajay Kumar', ''],\n   ['Vinodkumar', 'P. C.', '']],\n  'submitter': 'P C Vinodkumar',\n  'categories': 'hep-ph',\n  'abstract': 'Heavy flavour baryons containing one or two charm quarks with light flavour\\ncombinations are studied using the hyper central description of the three-body\\nsystem. The confinement potential is assumed as hyper central coulomb plus\\npower potential with power index $\\\\nu$. The ground state masses and the\\nmagnetic moments of charmed, $J^P={1/2}^+$ and ${3/2}^+$ baryons are computed\\nfor different power index, $ \\\\nu$ starting from 0.5 to 2.0.',\n  'doi': None,\n  'update_date': '2008-03-04',\n  'version_no': '1'},\n {'id': '2209.11998',\n  'title': 'Physically constrained neural networks to solve the inverse problem for\\n  neuron models',\n  'authors_parsed': [['Ferrante', 'Matteo', ''],\n   ['Duggento', 'Andera', ''],\n   ['Toschi', 'Nicola', '']],\n  'submitter': 'Matteo Ferrante',\n  'categories': 'cs.NE',\n  'abstract': 'Systems biology and systems neurophysiology in particular have recently\\nemerged as powerful tools for a number of key applications in the biomedical\\nsciences. Nevertheless, such models are often based on complex combinations of\\nmultiscale (and possibly multiphysics) strategies that require ad hoc\\ncomputational strategies and pose extremely high computational demands. Recent\\ndevelopments in the field of deep neural networks have demonstrated the\\npossibility of formulating nonlinear, universal approximators to estimate\\nsolutions to highly nonlinear and complex problems with significant speed and\\naccuracy advantages in comparison with traditional models. After synthetic data\\nvalidation, we use so-called physically constrained neural networks (PINN) to\\nsimultaneously solve the biologically plausible Hodgkin-Huxley model and infer\\nits parameters and hidden time-courses from real data under both variable and\\nconstant current stimulation, demonstrating extremely low variability across\\nspikes and faithful signal reconstruction. The parameter ranges we obtain are\\nalso compatible with prior knowledge. We demonstrate that detailed biological\\nknowledge can be provided to a neural network, making it able to fit complex\\ndynamics over both simulated and real data.',\n  'doi': None,\n  'update_date': '2022-09-27',\n  'version_no': '1'},\n {'id': '0810.1539',\n  'title': 'The Fundamental Group of Balanced Simplicial Complexes and Posets',\n  'authors_parsed': [['Klee', 'Steven', '']],\n  'submitter': 'Steven Klee',\n  'categories': 'math.CO',\n  'abstract': 'We establish an upper bound on the cardinality of a minimal generating set\\nfor the fundamental group of a large family of connected, balanced simplicial\\ncomplexes and, more generally, simplicial posets.',\n  'doi': None,\n  'update_date': '2009-04-29',\n  'version_no': '2'},\n {'id': '2006.06485',\n  'title': 'Deep Structural Causal Models for Tractable Counterfactual Inference',\n  'authors_parsed': [['Pawlowski', 'Nick', ''],\n   ['Castro', 'Daniel C.', ''],\n   ['Glocker', 'Ben', '']],\n  'submitter': 'Nick Pawlowski',\n  'categories': 'stat.ML cs.LG',\n  'abstract': \"We formulate a general framework for building structural causal models (SCMs)\\nwith deep learning components. The proposed approach employs normalising flows\\nand variational inference to enable tractable inference of exogenous noise\\nvariables - a crucial step for counterfactual inference that is missing from\\nexisting deep causal learning methods. Our framework is validated on a\\nsynthetic dataset built on MNIST as well as on a real-world medical dataset of\\nbrain MRI scans. Our experimental results indicate that we can successfully\\ntrain deep SCMs that are capable of all three levels of Pearl's ladder of\\ncausation: association, intervention, and counterfactuals, giving rise to a\\npowerful new approach for answering causal questions in imaging applications\\nand beyond. The code for all our experiments is available at\\nhttps://github.com/biomedia-mira/deepscm.\",\n  'doi': None,\n  'update_date': '2020-10-26',\n  'version_no': '2'},\n {'id': '2207.07041',\n  'title': 'Multi-Agent Deep Reinforcement Learning-Driven Mitigation of Adverse\\n  Effects of Cyber-Attacks on Electric Vehicle Charging Station',\n  'authors_parsed': [['Basnet', 'M.', ''], ['Ali', 'MH', '']],\n  'submitter': 'Manoj Basnet',\n  'categories': 'eess.SY cs.SY',\n  'abstract': 'An electric vehicle charging station (EVCS) infrastructure is the backbone of\\ntransportation electrification. However, the EVCS has myriads of exploitable\\nvulnerabilities in software, hardware, supply chain, and incumbent legacy\\ntechnologies such as network, communication, and control. These standalone or\\nnetworked EVCS open up large attack surfaces for the local or state-funded\\nadversaries. The state-of-the-art approaches are not agile and intelligent\\nenough to defend against and mitigate advanced persistent threats (APT). We\\npropose the data-driven model-free distributed intelligence based on multiagent\\nDeep Reinforcement Learning (MADRL)-- Twin Delayed Deep Deterministic Policy\\nGradient (TD3) -- that efficiently learns the control policy to mitigate the\\ncyberattacks on the controllers of EVCS. Also, we have proposed two additional\\nmitigation methods: the manual/Bruteforce mitigation and the controller\\nclone-based mitigation. The attack model considers the APT designed to\\nmalfunction the duty cycles of the EVCS controllers with Type-I low-frequency\\nattack and Type-II constant attack. The proposed model restores the EVCS\\noperation under threat incidence in any/all controllers by correcting the\\ncontrol signals generated by the legacy controllers. Also, the TD3 algorithm\\nprovides higher granularity by learning nonlinear control policies as compared\\nto the other two mitigation methods. Index Terms: Cyberattack, Deep\\nReinforcement Learning(DRL), Electric Vehicle Charging Station, Mitigation.',\n  'doi': None,\n  'update_date': '2022-07-15',\n  'version_no': '1'},\n {'id': '2309.06444',\n  'title': 'Connecting Everyday Objects with the Metaverse: A Unified Recognition\\n  Framework',\n  'authors_parsed': [['Xu', 'Liming', ''],\n   ['Towey', 'Dave', ''],\n   ['French', 'Andrew P.', ''],\n   ['Benford', 'Steve', '']],\n  'submitter': 'Liming Xu',\n  'categories': 'cs.HC',\n  'abstract': 'The recent Facebook rebranding to Meta has drawn renewed attention to the\\nmetaverse. Technology giants, amongst others, are increasingly embracing the\\nvision and opportunities of a hybrid social experience that mixes physical and\\nvirtual interactions. As the metaverse gains in traction, it is expected that\\neveryday objects may soon connect more closely with virtual elements. However,\\ndiscovering this \"hidden\" virtual world will be a crucial first step to\\ninteracting with it in this new augmented world. In this paper, we address the\\nproblem of connecting physical objects with their virtual counterparts,\\nespecially through connections built upon visual markers. We propose a unified\\nrecognition framework that guides approaches to the metaverse access points. We\\nillustrate the use of the framework through experimental studies under\\ndifferent conditions, in which an interactive and visually attractive\\ndecoration pattern, an Artcode, is used as the approach to enable the\\nconnection. This paper will be of interest to, amongst others, researchers\\nworking in Interaction Design or Augmented Reality who are seeking techniques\\nor guidelines for augmenting physical objects in an unobtrusive, complementary\\nmanner.',\n  'doi': '10.1109/COMPSAC54236.2022.00063',\n  'update_date': '2023-09-25',\n  'version_no': '1'},\n {'id': '1704.07972',\n  'title': 'Molecular Cloud Formation Via Thermal Instability of Finite Resistive\\n  Viscous Radiating Plasma with Finite Larmor Radius Corrections',\n  'authors_parsed': [['Kaothekar', 'Sachin', '']],\n  'submitter': 'Sachin Kaothekar',\n  'categories': 'physics.plasm-ph',\n  'abstract': 'The effect of radiative heat-loss function and finite ion Larmor radius (FLR)\\ncorrections on the thermal instability of infinite homogeneous viscous plasma\\nhas been investigated incorporating the effects of thermal conductivity and\\nfinite electrical resistivity for the formation of a molecular cloud. The\\ngeneral dispersion relation is derived using the normal mode analysis method\\nwith the help of relevant linearized perturbation equations of the problem.\\nFurthermore the wave propagation along and perpendicular to the direction of\\nexternal magnetic field has been discussed. Stability of the medium is\\ndiscussed by applying Routh Hurwitzs criterion and it is found that thermal\\ninstability criterion determines the stability of the medium. We find that the\\npresence of radiative heat-loss function and thermal conductivity modify the\\nfundamental criterion of thermal instability into radiatively driven thermal\\ninstability criterion. In longitudinal direction FLR corrections, viscosity,\\nmagnetic field and finite resistivity have no effect on thermal instability\\ncriterion. The presence of radiative heat-loss function and thermal\\nconductivity modify the fundamental thermal instability criterion into\\nradiatively driven thermal instability criterion. Also the FLR corrections\\nmodify the growth rate of the Alfven mode. For transverse wave propagation FLR\\ncorrections, radiative heat-loss function, magnetic field and thermal\\nconductivity modify the thermal instability criterion. From the curves it is\\nclear that heat-loss function, FLR corrections and viscosity have stabilizing\\neffect, while finite resistivity has destabilizing effect on the thermal modes.\\nOur results show that the FLR corrections and radiative heat-loss functions\\naffect the evolution of interstellar molecular clouds and star formation.',\n  'doi': '10.1007/s10509-017-3085-0',\n  'update_date': '2017-04-27',\n  'version_no': '1'},\n {'id': '1311.6309',\n  'title': 'A parallel repetition theorem for entangled two-player one-round games\\n  under product distributions',\n  'authors_parsed': [['Jain', 'Rahul', ''],\n   ['Pereszlényi', 'Attila', ''],\n   ['Yao', 'Penghui', '']],\n  'submitter': 'Penghui Yao',\n  'categories': 'quant-ph cs.CC',\n  'abstract': 'We show a parallel repetition theorem for the entangled value $\\\\omega^*(G)$\\nof any two-player one-round game $G$ where the questions $(x,y) \\\\in\\n\\\\mathcal{X}\\\\times\\\\mathcal{Y}$ to Alice and Bob are drawn from a product\\ndistribution on $\\\\mathcal{X}\\\\times\\\\mathcal{Y}$. We show that for the $k$-fold\\nproduct $G^k$ of the game $G$ (which represents the game $G$ played in parallel\\n$k$ times independently),\\n  $ \\\\omega^*(G^k)\\n=\\\\left(1-(1-\\\\omega^*(G))^3\\\\right)^{\\\\Omega\\\\left(\\\\frac{k}{\\\\log(|\\\\mathcal{A}|\\n\\\\cdot |\\\\mathcal{B}|)}\\\\right)} $, where $\\\\mathcal{A}$ and $\\\\mathcal{B}$\\nrepresent the sets from which the answers of Alice and Bob are drawn.',\n  'doi': None,\n  'update_date': '2014-06-16',\n  'version_no': '2'},\n {'id': '2103.00763',\n  'title': 'Comparisons of Order Statistics from Some Heterogeneous Discrete\\n  Distributions',\n  'authors_parsed': [['Chowdhury', 'Shovan', ''],\n   ['Kundu', 'Amarjit', ''],\n   ['Mishra', 'Surja Kanta', '']],\n  'submitter': 'Shovan Chowdhury',\n  'categories': 'math.ST stat.TH',\n  'abstract': 'In this paper, we compare extreme order statistics through vector\\nmajorization arising from heterogeneous Poisson and geometric random variables.\\nThese comparisons are carried out with respect to usual stochastic ordering.',\n  'doi': None,\n  'update_date': '2021-03-02',\n  'version_no': '1'},\n {'id': '2311.17569',\n  'title': 'Characterizing the ambiguity in topological entanglement entropy',\n  'authors_parsed': [['Li', 'Yingcheng', '']],\n  'submitter': 'Yingcheng Li',\n  'categories': 'cond-mat.str-el hep-th math-ph math.MP',\n  'abstract': 'Topological entanglement entropy (TEE), the sub-leading term in the\\nentanglement entropy of topological order, is the direct evidence of the\\nlong-range entanglement. While effective in characterizing topological orders\\non closed manifolds, TEE is model-dependent when entanglement cuts intersect\\nwith physical gapped boundaries. In this paper, we study the origin of this\\nmodel-dependence by introducing a model-independent picture of partitioning the\\ntopological orders with gapped boundaries. In our picture, the entanglement\\nboundaries (EBs), i.e. the virtual boundaries of each subsystem induced by the\\nentanglement cuts, are assumed to be gapped boundaries with boundary defects.\\nAt this model-independent stage, there are two choices one has to make manually\\nin defining the bi-partition: the boundary condition on the EBs, and the\\ncoherence between certain boundary states. We show that TEE appears because of\\na constraint on the defect configurations on the EBs, which is choice-dependent\\nin the cases where the EBs touch gapped boundaries. This choice-dependence is\\nknown as the ambiguity in entanglement entropy. Different models intrinsically\\nemploy different choices, rendering TEE model-dependent. For Z2 toric code, the\\nambiguity can be fully characterized by two parameters that respectively\\nquantifies the EB condition and the coherence. In particular, calculations\\ncompatible with the folding trick naturally choose EB conditions that respect\\nelectric-magnetic duality and set specific parameter values.',\n  'doi': None,\n  'update_date': '2023-12-04',\n  'version_no': '3'},\n {'id': '1609.02181',\n  'title': 'Geometry and a natural symplectic structure of phase tropical\\n  hypersurfaces',\n  'authors_parsed': [['Kim', 'Young Rock', ''], ['Nisse', 'Mounir', '']],\n  'submitter': 'Mounir Nisse',\n  'categories': 'math.AG',\n  'abstract': \"First, we define phase tropical hypersurfaces in terms of a degeneration data\\nof smooth complex algebraic hypersurfaces in $(\\\\mathbb{C}^*)^n$. Next, we prove\\nthat complex hyperplanes are diffeomorphic to their degeneration called phase\\ntropical hyperplanes. More generally, using Mikhalkin's decomposition into\\npairs-of-pants of smooth algebraic hypersurfaces, we show that phase tropical\\nhypersurfaces with smooth tropicalization, possess naturally a smooth\\ndifferentiable structure. Moreover, we prove that phase tropical hypersurfaces\\npossess a natural symplectic structure.\",\n  'doi': None,\n  'update_date': '2016-09-09',\n  'version_no': '1'},\n {'id': '2104.06676',\n  'title': 'Massive and massless two-dimensional Dirac particles in electric quantum\\n  dots',\n  'authors_parsed': [['Kuru', 'S.', ''],\n   ['Negro', 'J.', ''],\n   ['Nieto', 'L. M.', ''],\n   ['Sourrouille', 'L.', '']],\n  'submitter': 'Luis M. Nieto',\n  'categories': 'quant-ph cond-mat.other',\n  'abstract': 'In this work we investigate the confining properties of charged particles of\\na Dirac material in the plane subject to an electrostatic potential well, that\\nis, in an electric quantum dot. Our study focuses on the effect of mass and\\nangular momenta on such confining properties. To have a global picture of\\nconfinement, both bound and resonance states are considered. The resonances\\nwill be examined by means of the Wigner time delay of the scattering states, as\\nwell as through the complex eigenvalues of outgoing states in order to show\\nthat they are physically meaningful. By tuning the potential intensity of the\\nwell, electron captures and atomic collapses are observed for critical values.\\nIn these processes, the bound states of the discrete spectrum become resonances\\nof the continuous spectrum or vice versa. For massive charges, the atomic\\ncollapse phenomenon keeps the number of bound levels in the quantum dot below a\\nmaximum value. In the massless case, the bound states have zero energy and\\noccur only for some discrete values of the potential depth, as is known. We\\nalso show that although the intensity of the resonances for massive particles\\nis not significantly influenced by angular momenta, on the contrary, for\\nmassless particles they are quite sensitive to angular momenta, as it is the\\ncase of graphene.',\n  'doi': '10.1016/j.physe.2022.115312',\n  'update_date': '2022-06-15',\n  'version_no': '3'},\n {'id': '2008.00618',\n  'title': 'LIPSS-Sticks: Laser induced double self organization enhances the\\n  broadband light harvesting of TiO2 nanotube arrays',\n  'authors_parsed': [['Arul', 'Rakesh', ''],\n   ['Dong', 'Junzhe', ''],\n   ['Simpson', 'M. Cather', ''],\n   ['Gao', 'Wei', '']],\n  'submitter': 'Rakesh Arul',\n  'categories': 'physics.app-ph cond-mat.mes-hall cond-mat.mtrl-sci physics.optics',\n  'abstract': 'Sub-wavelength laser induced periodic surface structures (LIPSS-Sticks)\\ncreated by ultrashort pulsed laser irradiation on the surface of titanium are\\nused for the first time to template the electrochemical growth of titanium\\ndioxide nanotube arrays. This is an example of a double self-organized process,\\nas both LIPSS formation and electrochemical anodization involve spontaneous\\ngeneration of order from initially non-ordered precursors. LIPSS-Sticks have a\\n2x greater visible to near infrared light (400 - 1400 nm) collection efficiency\\ncompared to flat titanium dioxide due to the enhanced light scattering from\\ngrating-like structures. The growth of nanostructures with time was modelled\\nelectrostatically to explain the features of a templated anodization process\\nthat differ from the usual anodization of flat surfaces. This new templated\\ngrowth method is general and can also be applied to Cu, W, Fe, Ti alloys and Al\\nfor the fabrication of hierarchically nanostructured surfaces using two\\ncomplementary fabrication techniques: ultrashort pulsed laser ablation and\\nelectrochemical anodization.',\n  'doi': None,\n  'update_date': '2020-08-04',\n  'version_no': '1'},\n {'id': '1209.5417',\n  'title': 'Model based neuro-fuzzy ASR on Texas processor',\n  'authors_parsed': [['Ekhtiyar', 'Hesam', ''],\n   ['Sheida', 'Mehdi', ''],\n   ['Moghadam', 'Somaye Sobati', '']],\n  'submitter': 'Hesam Ekhtiyar',\n  'categories': 'cs.CV',\n  'abstract': 'In this paper an algorithm for recognizing speech has been proposed. The\\nrecognized speech is used to execute related commands which use the MFCC and\\ntwo kind of classifiers, first one uses MLP and second one uses fuzzy inference\\nsystem as a classifier. The experimental results demonstrate the high gain and\\nefficiency of the proposed algorithm. We have implemented this system based on\\ngraphical design and tested on a fix point digital signal processor (DSP) of\\n600 MHz, with reference DM6437-EVM of Texas instrument.',\n  'doi': None,\n  'update_date': '2012-09-26',\n  'version_no': '1'},\n {'id': 'astro-ph/0312372',\n  'title': 'Chemical compositions of four barium stars',\n  'authors_parsed': [['Liang', 'Y. C.', ''],\n   ['Zhao', 'G.', ''],\n   ['Chen', 'Y. Q.', ''],\n   ['Qiu', 'H. M.', ''],\n   ['Zhang', 'B.', '']],\n  'submitter': 'Yanchun Liang',\n  'categories': 'astro-ph',\n  'abstract': 'Chemical compositions of four barium stars HD 26886, HD 27271, HD 50082 and\\nHD 98839 are studied based on high resolution, high signal-to-noise Echelle\\nspectra. Results show that all of them are disk stars. Their \\\\alpha and iron\\npeak elements are similar to the solar abundances. The neutron-capture process\\nelements are overabundant relative to the Solar. The heavy-element abundances\\nof the strong Ba star HD 50082 are higher than those of other three mild Ba\\nstars. Its mass is 1.32Msun (+0.28,-0.22Msun), and is consistent with the\\naverage mass of strong Ba stars (1.5Msun). For mild Ba star HD 27271 and HD\\n26886, the derived masses are 1.90Msun (+0.25,-0.20Msun) and 2.78Msun\\n(+0.75,-0.78M_sun), respectively, which are consistent with the average mass of\\nmild Ba stars. We also calculate the theoretical abundances of Ba stars by\\ncombining the AGB stars nucleosynthesis and wind accretion formation scenario\\nof Ba binary systems. The comparisons between the observed abundance patterns\\nof the sample stars with the theoretical results show that wind accretion\\nscenario can explain the abundance patterns of HD 50082 and HD 27271 well, but\\nfail to explain the abundances of HD 26886. It means that the mild Ba star HD\\n26886, with shorter orbital period (P<1600 d), may be formed from other\\nscenarios. The high mass mild Ba star HD 98839, with 3.62M_sun, and with very\\nlong orbital period (P>11000 d), may be either a star with the heavy elements\\nenriched by itself or a \"true Ba\" star.',\n  'doi': '10.1051/0004-6361:22021460',\n  'update_date': '2009-11-10',\n  'version_no': '1'},\n {'id': '2501.13936',\n  'title': 'Evaluating Computational Accuracy of Large Language Models in Numerical\\n  Reasoning Tasks for Healthcare Applications',\n  'authors_parsed': [['Malghan', 'Arjun R.', '']],\n  'submitter': 'Arjun Malghan',\n  'categories': 'cs.AI cs.CL cs.LG',\n  'abstract': \"Large Language Models (LLMs) have emerged as transformative tools in the\\nhealthcare sector, demonstrating remarkable capabilities in natural language\\nunderstanding and generation. However, their proficiency in numerical\\nreasoning, particularly in high-stakes domains like in clinical applications,\\nremains underexplored. Numerical reasoning is critical in healthcare\\napplications, influencing patient outcomes, treatment planning, and resource\\nallocation. This study investigates the computational accuracy of LLMs in\\nnumerical reasoning tasks within healthcare contexts. Using a curated dataset\\nof 1,000 numerical problems, encompassing real-world scenarios such as dosage\\ncalculations and lab result interpretations, the performance of a refined LLM\\nbased on the GPT-3 architecture was evaluated. The methodology includes prompt\\nengineering, integration of fact-checking pipelines, and application of\\nregularization techniques to enhance model accuracy and generalization. Key\\nmetrics such as precision, recall, and F1-score were utilized to assess the\\nmodel's efficacy. The results indicate an overall accuracy of 84.10%, with\\nimproved performance in straightforward numerical tasks and challenges in\\nmulti-step reasoning. The integration of a fact-checking pipeline improved\\naccuracy by 11%, underscoring the importance of validation mechanisms. This\\nresearch highlights the potential of LLMs in healthcare numerical reasoning and\\nidentifies avenues for further refinement to support critical decision-making\\nin clinical environments. The findings aim to contribute to the development of\\nreliable, interpretable, and contextually relevant AI tools for healthcare.\",\n  'doi': None,\n  'update_date': '2025-01-27',\n  'version_no': '1'},\n {'id': '1206.7084',\n  'title': 'Anomalous behavior of acoustic phonon mode and central peak in\\n  Pb(Zn1/3Nb2/3)0.85Ti0.15O3 single crystal studied using Brillouin scattering',\n  'authors_parsed': [['Mishra', 'K. K.', ''],\n   ['Sivasubramanian', 'V.', ''],\n   ['Arora', 'A. K.', ''],\n   ['Pradhan', 'Dillip', '']],\n  'submitter': 'Karuna Mishra',\n  'categories': 'cond-mat.mtrl-sci',\n  'abstract': 'Brillouin spectroscopic measurements have been carried out on relaxor\\nferroelectric Pb(Zn1/3Nb2/3)0.85Ti0.15O3 (PZN-PT) single crystal over the\\ntemperature range 300-585 K. The longitudinal acoustic phonon begins to soften\\nbelow 650 K, which is attributed to the Burns temperature (TB). On the other\\nhand, the line width of the longitudinal acoustic (LA) phonon mode exhibits a\\nsharp Landau-Khalatnikov-like maximum and an accompanying anomaly in the LA\\nmode frequency around 463 K, the tetragonal-cubic phase transition temperature\\n(Ttc). In addition, a broad central peak, found below the characteristic\\nintermediate temperature T* ~ 525 K, exhibits critical slowing down upon\\napproaching Ttc indicating an order-disorder nature of the phase transition.\\nThe relaxation time of polar nano regions estimated from the broad central peak\\nis found to be same as that obtained for LA phonon mode suggesting an\\nelectrostrictive coupling between strain and polarization fluctuations. The\\nactivation energy for the PNRs relaxation-dynamics is found to be ~236 meV.\\nPolarized nature of the central peak suggests that the polar nano regions have\\nthe tendency to form long-range polar ordering.',\n  'doi': '10.1063/1.4768441',\n  'update_date': '2015-06-05',\n  'version_no': '1'},\n {'id': 'hep-ph/0301001',\n  'title': 'Hints of Energy Dependences in AGASA EHECR Arrival Directions',\n  'authors_parsed': [['Burgett', 'William S.', ''],\n   [\"O'Malley\", 'Mark R.', '']],\n  'submitter': 'William S. Burgett',\n  'categories': 'hep-ph astro-ph',\n  'abstract': 'A correlation and probability analysis of the distribution of arrival\\ndirections for a sample of AGASA events reported to have energies above\\n4x10^{19} eV shows the small scale clustering to remain significant at the 99.5\\n- 99.9% CL and to be consistent with previous results. For the sample taken as\\na whole, there are no departures from either homogeneity or isotropy on angular\\nscales greater than 5 degrees. The sample of events with E >= 6x10^{19} eV\\npossesses no small scale clustering. Cross correlating subsamples partitioned\\nby energy reveals three uncorrelated distributions in the intervals 4 -\\n5x10^{19} eV, 5 - (8-10)x10^{19} eV, and greater than (8-10)x10^{19} eV. The\\npartition with 5 <= E < 8x10^{19} eV is correlated with the supergalactic\\nequatorial plane while the other two groups are statistically consistent with\\nisotropic distributions. The presence of three distinct energy-partitioned\\ngroups of events could reflect possible changes in primary composition,\\ndifferent source distributions, differing levels of GZK losses, or deflection\\neffects of magnetic fields.',\n  'doi': '10.1103/PhysRevD.67.092002',\n  'update_date': '2009-11-10',\n  'version_no': '2'},\n {'id': '2001.10065',\n  'title': 'Medi-Care AI: Predicting Medications From Billing Codes via Robust\\n  Recurrent Neural Networks',\n  'authors_parsed': [['Liu', 'Deyin', ''],\n   ['Wu', 'Lin', ''],\n   ['Li', 'Xue', '']],\n  'submitter': 'Lin Wu',\n  'categories': 'cs.LG stat.ML',\n  'abstract': 'In this paper, we present an effective deep prediction framework based on\\nrobust recurrent neural networks (RNNs) to predict the likely therapeutic\\nclasses of medications a patient is taking, given a sequence of diagnostic\\nbilling codes in their record. Accurately capturing the list of medications\\ncurrently taken by a given patient is extremely challenging due to undefined\\nerrors and omissions. We present a general robust framework that explicitly\\nmodels the possible contamination through overtime decay mechanism on the input\\nbilling codes and noise injection into the recurrent hidden states,\\nrespectively. By doing this, billing codes are reformulated into its temporal\\npatterns with decay rates on each medical variable, and the hidden states of\\nRNNs are regularised by random noises which serve as dropout to improved RNNs\\nrobustness towards data variability in terms of missing values and multiple\\nerrors. The proposed method is extensively evaluated on real health care data\\nto demonstrate its effectiveness in suggesting medication orders from\\ncontaminated values.',\n  'doi': None,\n  'update_date': '2020-01-29',\n  'version_no': '1'},\n {'id': '1707.06709',\n  'title': 'Point-wise estimates for nonlocal heat kernel of convolution type\\n  operators',\n  'authors_parsed': [['Grigoryan', 'Alexander', ''],\n   ['Kondratiev', 'Yury', ''],\n   ['Piatnitski', 'Andrey', ''],\n   ['Zhizhina', 'Elena', '']],\n  'submitter': 'Andrey Piatnitski',\n  'categories': 'math.FA',\n  'abstract': 'The paper deals with point-wise estimates for the heat kernel of a nonlocal\\nconvolution type operator with a kernel that decays at least exponentially at\\ninfinity. It is shown that the large time behaviour of the heat kernel depends\\nessentially on whether $|x|\\\\ll t$, or $|x|\\\\sim t$, or $|x|\\\\gg t$. We obtain\\nsharp point-wise upper bounds for the heat kernel in all these regions. In the\\nfirst region the nonlocal heat kernel behaves like the classical one, while in\\nthe other regions we observe an essential difference.',\n  'doi': '10.1112/plms.12144',\n  'update_date': '2018-04-25',\n  'version_no': '2'},\n {'id': 'math/0310336',\n  'title': 'Comments on toric varieties',\n  'authors_parsed': [['Thompson', 'Howard M', '']],\n  'submitter': 'Howard M. Thompson',\n  'categories': 'math.AG',\n  'abstract': 'Here are few notes on not necessarily normal toric varieties and resolution\\nby toric blow-up. These notes are independent of, but in the same spirit as the\\nearlier preprint arXiv:math.AG/0306221. That is, they focus on the fact that\\ntoric varieties are locally given by monoid algebras.',\n  'doi': None,\n  'update_date': '2007-05-23',\n  'version_no': '1'},\n {'id': '0902.1453',\n  'title': 'On C*-Extreme Maps and *-Homomorphisms of a Commutative C*-Algebra',\n  'authors_parsed': [['Gregg', 'M. C.', '']],\n  'submitter': 'Martha Gregg',\n  'categories': 'math.OA math.FA',\n  'abstract': 'The generalized state space of a commutative C*-algebra, denoted S_H(C(X)),\\nis the set of positive unital maps from C(X) to the algebra B(H) of bounded\\nlinear operators on a Hilbert space H. C*-convexity is one of several\\nnon-commutative analogs of convexity which have been discussed in this context.\\nIn this paper we show that a C*-extreme point of S_H(C(X)) satisfies a certain\\nspectral condition on the operators in the range of the associated positive\\noperator-valued measure. This result enables us to show that C*-extreme maps\\nfrom C(X) into K^+, the algebra generated by the compact and scalar operators,\\nare multiplicative. This generalizes a result of D. Farenick and P. Morenz. We\\nthen determine the structure of these maps.',\n  'doi': None,\n  'update_date': '2009-02-12',\n  'version_no': '2'},\n {'id': 'math/0511436',\n  'title': 'Noncommutative Superspaces Covariant Under $OSp_q(1|2)$ Algebra',\n  'authors_parsed': [['Aizawa', 'N.', ''], ['Chakrabarti', 'R.', '']],\n  'submitter': 'Naruhiko Aizawa',\n  'categories': 'math.QA',\n  'abstract': \"Using the corepresentation of the quantum group $ SL_q(2)$ a general method\\nfor constructing noncommutative spaces covariant under its coaction is\\ndeveloped. The method allows us to treat the quantum plane and Podle\\\\'s'\\nquantum spheres in a unified way and to construct higher dimensional\\nnoncommutative spaces systematically. Furthermore, we extend the method to the\\nquantum supergroup $ OSp_q(1|2).$ In particular, a one-parameter family of\\ncovariant algebras, which may be interpreted as noncommutative superspheres, is\\nconstructed.\",\n  'doi': None,\n  'update_date': '2007-05-23',\n  'version_no': '1'},\n {'id': '1603.04674',\n  'title': 'How Does Metallicity Affect the Gas and Dust Properties of Galaxies?',\n  'authors_parsed': [['Madden', 'Suzanne C.', ''],\n   ['Cormier', 'Diane', ''],\n   ['Remy-Ruyer', 'Aurelie', '']],\n  'submitter': 'Suzanne Madden',\n  'categories': 'astro-ph.GA',\n  'abstract': 'Comparison of the ISM properties of a wide range of metal-poor galaxies with\\nnormal metal-rich galaxies reveals striking differences. We find that the\\ncombination of the low dust abundance and the active star formation results in\\na very porous ISM filled with hard photons, heating the dust in dwarf galaxies\\nto overall higher temperatures than their metal-rich counterparts. This results\\nin photodissociation of molecular clouds to greater depths, leaving relatively\\nlarge PDR envelopes and difficult-to-detect CO cores. From detailed modeling of\\nthe low-metallicity ISM, we find significant fractions of CO-dark H2 - a\\nreservoir of molecular gas not traced by CO, but present in the [CII] and\\n[CI]-emitting envelopes. Self-consistent analyses of the neutral and ionized\\ngas diagnostics along with the dust SED is the necessary way forward in\\nuncovering the multiphase structure of galaxies',\n  'doi': '10.1017/S1743921316007493',\n  'update_date': '2017-01-11',\n  'version_no': '1'},\n {'id': '1612.02967',\n  'title': 'Dune-CurvilinearGrid: Parallel Dune Grid Manager for Unstructured\\n  Tetrahedral Curvilinear Meshes',\n  'authors_parsed': [['Fomins', 'Aleksejs', ''], ['Oswald', 'Benedikt', '']],\n  'submitter': 'Aleksejs Fomins',\n  'categories': 'cs.CG',\n  'abstract': 'We introduce the dune-curvilineargrid module. The module provides the\\nself-contained, parallel grid manager, as well as the underlying elementary\\ncurvilinear geometry module dune-curvilineargeometry. This work is motivated by\\nthe need for reliable and scalable electromagnetic design of nanooptical\\ndevices. Curvilinear geometries improve both the accuracy of modeling smooth\\nmaterial boundaries, and the h/p-convergence rate of PDE solutions, reducing\\nthe necessary computational effort. dune-curvilineargrid provides a large\\nspectrum of features for scalable parallel implementations of Finite Element\\nand Boundary Integral methods over curvilinear tetrahedral geometries,\\nincluding symbolic polynomial mappings and operations, recursive integration,\\nsparse and dense grid communication, parallel timing and memory footprint\\ndiagnostics utilities. It is written in templated C++ using MPI for\\nparallelization and ParMETIS for grid partitioning, and is provided as a module\\nfor the DUNE interface. The dune-curvilineargrid grid manager is continuously\\ndeveloped and improved, and so is this documentation. For the most recent\\nversion of the documentation, as well as the source code, please refer to the\\nprovided repositories and our website.',\n  'doi': None,\n  'update_date': '2016-12-12',\n  'version_no': '1'}]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jsons"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:22:45.559916Z",
     "start_time": "2025-05-26T14:22:45.513803Z"
    }
   },
   "id": "c168c045b21fd3f7",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def is_valid(entry, allowed_categories=None, allowed_major_categories=None, \n",
    "             allowed_minor_categories=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Check if an ArXiv entry is valid based on categories and date range.\n",
    "    Highly efficient - operates on raw dict without full parsing.\n",
    "    \n",
    "    Args:\n",
    "        entry (dict): Raw ArXiv paper dictionary\n",
    "        allowed_categories (list): List of allowed full categories like ['cs.AI', 'math.ST'] (None to skip check)\n",
    "        allowed_major_categories (list): List of allowed major categories like ['cs', 'math'] (None to skip check)\n",
    "        allowed_minor_categories (list): List of allowed minor categories like ['AI', 'ST'] (None to skip check)\n",
    "        start_date (str): Start date in YYYY-MM-DD format (None to skip check)\n",
    "        end_date (str): End date in YYYY-MM-DD format (None to skip check)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if entry passes all filters, False otherwise\n",
    "    \"\"\"\n",
    "    # Category check\n",
    "    if any(x is not None for x in [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n",
    "        entry_categories = entry.get('categories', '')\n",
    "        if not entry_categories:\n",
    "            return False\n",
    "        \n",
    "        # Split categories and check if any match allowed categories\n",
    "        entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "        \n",
    "        # Check full categories (exact match)\n",
    "        if allowed_categories is not None:\n",
    "            if not any(cat in allowed_categories for cat in entry_cats):\n",
    "                return False\n",
    "        \n",
    "        # Check major categories (before the dot)\n",
    "        if allowed_major_categories is not None:\n",
    "            entry_majors = [cat.split('.')[0] if '.' in cat else cat for cat in entry_cats]\n",
    "            if not any(major in allowed_major_categories for major in entry_majors):\n",
    "                return False\n",
    "        \n",
    "        # Check minor categories (after the dot)\n",
    "        if allowed_minor_categories is not None:\n",
    "            entry_minors = [cat.split('.')[1] if '.' in cat and len(cat.split('.')) > 1 else '' \n",
    "                           for cat in entry_cats]\n",
    "            entry_minors = [minor for minor in entry_minors if minor]  # Remove empty strings\n",
    "            if not any(minor in allowed_minor_categories for minor in entry_minors):\n",
    "                return False\n",
    "    \n",
    "    # Date check\n",
    "    if start_date is not None or end_date is not None:\n",
    "        update_date = entry.get('update_date', '')\n",
    "        if not update_date:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert update_date to datetime for comparison\n",
    "            entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "            \n",
    "            if start_date is not None:\n",
    "                start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                if entry_date < start_dt:\n",
    "                    return False\n",
    "            \n",
    "            if end_date is not None:\n",
    "                end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "                if entry_date > end_dt:\n",
    "                    return False\n",
    "                    \n",
    "        except ValueError:\n",
    "            # Invalid date format\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "valid_entries = [entry for entry in sample if is_valid(entry, allowed_major_categories=['CS'])]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:24:18.813219Z",
     "start_time": "2025-05-26T14:24:18.802562Z"
    }
   },
   "id": "f7d288996cce1009",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_entries"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:24:21.581006Z",
     "start_time": "2025-05-26T14:24:21.575245Z"
    }
   },
   "id": "63d39dbff8cef6b5",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NEW"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d363d45b6eccd15"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "is_valid() missing 1 required positional argument: 'entry'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 300\u001B[39m\n\u001B[32m    294\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m validated_jsons\n\u001B[32m    297\u001B[39m fn = \u001B[33m\"\u001B[39m\u001B[33marxiv-metadata-oai-snapshot.json\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    298\u001B[39m jsons = read_and_filter_jsons_parallel(\n\u001B[32m    299\u001B[39m     fn, \n\u001B[32m--> \u001B[39m\u001B[32m300\u001B[39m     validator_function= \u001B[43mis_valid\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    301\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallowed_major_categories\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcs\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstart_date\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m2020-01-01\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m    303\u001B[39m \u001B[43m        \u001B[49m\u001B[43mend_date\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m2023-12-31\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m    304\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m    305\u001B[39m     max_workers=\u001B[32m8\u001B[39m,\n\u001B[32m    306\u001B[39m     batch_size=\u001B[32m2048\u001B[39m)\n",
      "\u001B[31mTypeError\u001B[39m: is_valid() missing 1 required positional argument: 'entry'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import deque\n",
    "from pathlib import Path # Assuming this might be used by your is_valid or other parts\n",
    "from datetime import datetime # Assuming this might be used by your is_valid\n",
    "\n",
    "from tqdm.auto import tqdm # Using tqdm.auto for flexible environment\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import os\n",
    "\n",
    "def is_valid(entry, allowed_categories=None, allowed_major_categories=None, \n",
    "             allowed_minor_categories=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Check if an ArXiv entry is valid based on categories and date range.\n",
    "    Highly efficient - operates on raw dict without full parsing.\n",
    "    \n",
    "    Args:\n",
    "        entry (dict): Raw ArXiv paper dictionary\n",
    "        allowed_categories (list): List of allowed full categories like ['cs.AI', 'math.ST'] (None to skip check)\n",
    "        allowed_major_categories (list): List of allowed major categories like ['cs', 'math'] (None to skip check)\n",
    "        allowed_minor_categories (list): List of allowed minor categories like ['AI', 'ST'] (None to skip check)\n",
    "        start_date (str): Start date in YYYY-MM-DD format (None to skip check)\n",
    "        end_date (str): End date in YYYY-MM-DD format (None to skip check)\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if entry passes all filters, False otherwise\n",
    "    \"\"\"\n",
    "    # Category check\n",
    "    if any(x is not None for x in [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n",
    "        entry_categories = entry.get('categories', '')\n",
    "        if not entry_categories:\n",
    "            return False\n",
    "        \n",
    "        # Split categories and check if any match allowed categories\n",
    "        entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "        \n",
    "        # Check full categories (exact match)\n",
    "        if allowed_categories is not None:\n",
    "            if not any(cat in allowed_categories for cat in entry_cats):\n",
    "                return False\n",
    "        \n",
    "        # Check major categories (before the dot)\n",
    "        if allowed_major_categories is not None:\n",
    "            entry_majors = [cat.split('.')[0] if '.' in cat else cat for cat in entry_cats]\n",
    "            if not any(major in allowed_major_categories for major in entry_majors):\n",
    "                return False\n",
    "        \n",
    "        # Check minor categories (after the dot)\n",
    "        if allowed_minor_categories is not None:\n",
    "            entry_minors = [cat.split('.')[1] if '.' in cat and len(cat.split('.')) > 1 else '' \n",
    "                           for cat in entry_cats]\n",
    "            entry_minors = [minor for minor in entry_minors if minor]  # Remove empty strings\n",
    "            if not any(minor in allowed_minor_categories for minor in entry_minors):\n",
    "                return False\n",
    "    \n",
    "    # Date check\n",
    "    if start_date is not None or end_date is not None:\n",
    "        update_date = entry.get('update_date', '')\n",
    "        if not update_date:\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            # Convert update_date to datetime for comparison\n",
    "            entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "            \n",
    "            if start_date is not None:\n",
    "                start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                if entry_date < start_dt:\n",
    "                    return False\n",
    "            \n",
    "            if end_date is not None:\n",
    "                end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "                if entry_date > end_dt:\n",
    "                    return False\n",
    "                    \n",
    "        except ValueError:\n",
    "            # Invalid date format\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def _mp_process_line_for_filtering(line_validator_tuple):\n",
    "    \"\"\"\n",
    "    Parses a JSON line and applies a validator. Designed for use with multiprocessing.\n",
    "    Args:\n",
    "        line_validator_tuple (tuple): A tuple containing (line_content_string, validator_function).\n",
    "                                      validator_function can be None.\n",
    "    Returns:\n",
    "        object: The parsed and validated JSON object (dict) if valid, otherwise None.\n",
    "    \"\"\"\n",
    "    line_content, validator_func = line_validator_tuple\n",
    "    if not line_content.strip(): # Skip empty or whitespace-only lines\n",
    "        return None\n",
    "    try:\n",
    "        entry = json.loads(line_content)\n",
    "        if validator_func is None or validator_func(entry):\n",
    "            return entry  # Parsed and validated (or no validator)\n",
    "        return None  # Failed validation\n",
    "    except json.JSONDecodeError:\n",
    "        # Optionally, log this error or count parsing failures\n",
    "        # print(f\"Warning: Could not parse line: {line_content[:100]}\")\n",
    "        return None  # Failed parsing\n",
    "    \n",
    "def sample_jsons(filename, n, method='first', seed=42, validator=None):\n",
    "    \"\"\"\n",
    "    Sample N entries from a JSON lines file. (Non-parallel version as provided)\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Path to the JSON lines file.\n",
    "        n (int): Number of entries to sample.\n",
    "        method (str): Sampling method - 'first', 'random', or 'last'.\n",
    "        seed (int): Random seed for reproducible random sampling.\n",
    "        validator (function, optional): If provided, only returns entries that pass this\n",
    "                                        validation function. This function must take in a\n",
    "                                        parsed JSON dict and output True or False. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of parsed JSON objects (dictionaries).\n",
    "    \"\"\"\n",
    "    if n == 0:\n",
    "        return []\n",
    "\n",
    "    samples = []\n",
    "    \n",
    "    if method == 'first':\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            pbar = tqdm(desc=f\"Finding first {n} valid entries\", total=n, unit=\"entry\")\n",
    "            for line in f:\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    if validator is None or validator(entry):\n",
    "                        samples.append(entry)\n",
    "                        pbar.update(1)\n",
    "                        if len(samples) >= n:\n",
    "                            break\n",
    "                except json.JSONDecodeError:\n",
    "                    tqdm.write(f\"Skipping unparseable line in 'first': {line[:100]}\")\n",
    "            pbar.close()\n",
    "            if len(samples) < n:\n",
    "                tqdm.write(f\"Warning: Found only {len(samples)} valid entries out of {n} requested from the beginning of the file.\")\n",
    "        return samples\n",
    "    \n",
    "    elif method == 'last':\n",
    "        samples_deque = deque(maxlen=n)\n",
    "        total_lines = None\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f_count:\n",
    "                total_lines = sum(1 for _ in f_count)\n",
    "        except (IOError, OSError):\n",
    "            pass # total_lines will remain None\n",
    "\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            with tqdm(desc=f\"Scanning for last {n} valid entries\", total=total_lines, unit=\"line\") as pbar:\n",
    "                for line in f:\n",
    "                    pbar.update(1)\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        if validator is None or validator(entry):\n",
    "                            samples_deque.append(entry)\n",
    "                    except json.JSONDecodeError:\n",
    "                        tqdm.write(f\"Skipping unparseable line in 'last': {line[:100]}\")\n",
    "        return list(samples_deque)\n",
    "    \n",
    "    elif method == 'random':\n",
    "        random.seed(seed)\n",
    "        samples = []\n",
    "        valid_items_seen = 0\n",
    "        total_lines = None\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f_count:\n",
    "                total_lines = sum(1 for _ in f_count)\n",
    "        except (IOError, OSError):\n",
    "            pass\n",
    "\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            with tqdm(desc=f\"Random sampling for {n} valid entries\", total=total_lines, unit=\"line\") as pbar:\n",
    "                for line in f:\n",
    "                    pbar.update(1)\n",
    "                    if not line.strip():\n",
    "                        continue\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        if validator is None or validator(entry):\n",
    "                            valid_items_seen += 1\n",
    "                            if len(samples) < n:\n",
    "                                samples.append(entry)\n",
    "                            else:\n",
    "                                j = random.randint(0, valid_items_seen - 1)\n",
    "                                if j < n:\n",
    "                                    samples[j] = entry\n",
    "                    except json.JSONDecodeError:\n",
    "                        tqdm.write(f\"Skipping unparseable line in 'random': {line[:100]}\")\n",
    "            if len(samples) < n:\n",
    "                tqdm.write(f\"Warning: Found only {len(samples)} valid random entries out of {n} requested.\")\n",
    "        return samples\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"method must be 'first', 'last', or 'random'\")\n",
    "\n",
    "def filter_jsons(json_list, validator_function, max_workers=None):\n",
    "    \"\"\"\n",
    "    Filter a list of JSON objects (already in memory) in parallel using a validator function.\n",
    "    \"\"\"\n",
    "    if not json_list:\n",
    "        return []\n",
    "    \n",
    "    if validator_function is None: # If no validator, return all\n",
    "        return list(json_list)\n",
    "\n",
    "    if max_workers is None:\n",
    "        max_workers = os.cpu_count()\n",
    "\n",
    "    validated_items = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(executor.map(validator_function, tqdm(json_list, desc=\"Filtering in-memory JSONs\", unit=\"entry\")))\n",
    "        \n",
    "        for item, is_valid_flag in zip(json_list, results):\n",
    "            if is_valid_flag:\n",
    "                validated_items.append(item)\n",
    "                \n",
    "    return validated_items\n",
    "\n",
    "\n",
    "def read_and_filter_jsons_parallel(filename, validator_function, max_workers=None, batch_size=2048):\n",
    "    \"\"\"\n",
    "    Reads a JSON lines file, filters its entries in parallel, and returns a list of valid JSON objects.\n",
    "    This is memory-efficient as it processes the file in streaming batches.\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the JSON lines file.\n",
    "        validator_function (function): A function that takes a parsed JSON dict and returns True if valid.\n",
    "        max_workers (int, optional): Max worker processes. Defaults to os.cpu_count().\n",
    "        batch_size (int, optional): Number of lines to process in each parallel batch. Defaults to 2048.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of parsed JSON objects that passed validation.\n",
    "    \"\"\"\n",
    "    if max_workers is None:\n",
    "        max_workers = os.cpu_count()\n",
    "\n",
    "    validated_jsons = []\n",
    "    total_lines = None\n",
    "    \n",
    "    try:\n",
    "        # Pre-count lines for a determinate progress bar. This adds an initial pass.\n",
    "        with open(filename, 'r', encoding='utf-8') as f_count:\n",
    "            total_lines = sum(1 for _line in f_count) \n",
    "    except (IOError, OSError) as e:\n",
    "        tqdm.write(f\"Info: Could not pre-count lines ({e}). Progress bar will be indeterminate for total lines.\")\n",
    "\n",
    "    pbar_desc = \"Reading & filtering JSON lines (parallel)\"\n",
    "    if total_lines is not None:\n",
    "        pbar = tqdm(total=total_lines, desc=pbar_desc, unit=\"line\")\n",
    "    else:\n",
    "        # Indeterminate total, tqdm will show rate and lines processed so far\n",
    "        pbar = tqdm(desc=pbar_desc, unit=\"line\") \n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor, \\\n",
    "         open(filename, 'r', encoding='utf-8') as f:\n",
    "        \n",
    "        lines_batch_for_processing = []\n",
    "\n",
    "        for line_content in f:\n",
    "            lines_batch_for_processing.append((line_content, validator_function))\n",
    "            \n",
    "            if len(lines_batch_for_processing) >= batch_size:\n",
    "                try:\n",
    "                    for entry in executor.map(_mp_process_line_for_filtering, lines_batch_for_processing):\n",
    "                        if entry: # If parsed, validated, and not None\n",
    "                            validated_jsons.append(entry)\n",
    "                except Exception as e: # Catch errors from the process pool more broadly\n",
    "                    tqdm.write(f\"Error processing a batch: {e}\")\n",
    "                \n",
    "                pbar.update(len(lines_batch_for_processing))\n",
    "                lines_batch_for_processing.clear()\n",
    "        \n",
    "        # Process any remaining lines in the last batch\n",
    "        if lines_batch_for_processing:\n",
    "            try:\n",
    "                for entry in executor.map(_mp_process_line_for_filtering, lines_batch_for_processing):\n",
    "                    if entry:\n",
    "                        validated_jsons.append(entry)\n",
    "            except Exception as e:\n",
    "                 tqdm.write(f\"Error processing the final batch: {e}\")\n",
    "            pbar.update(len(lines_batch_for_processing))\n",
    "        \n",
    "    pbar.close()\n",
    "    return validated_jsons\n",
    "\n",
    "\n",
    "fn = \"arxiv-metadata-oai-snapshot.json\"\n",
    "jsons = read_and_filter_jsons_parallel(\n",
    "    fn, \n",
    "    validator_function= is_valid(\n",
    "        entry\n",
    "        allowed_major_categories=['cs'], \n",
    "        start_date='2020-01-01', \n",
    "        end_date='2023-12-31'\n",
    "    ),\n",
    "    max_workers=8,\n",
    "    batch_size=2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:43:56.477776Z",
     "start_time": "2025-05-26T14:43:56.213788Z"
    }
   },
   "id": "4f7d8b611e76fba1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting efficient parallel reading and filtering of 'arxiv-metadata-oai-snapshot.json' with joblib...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Reading & filtering (joblib):   0%|          | 0/2735264 [00:00<?, ?line/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b1ef2520f0f471e8f26ffd399182024"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 619980 'cs' papers from 2020-2023.\n",
      "First valid entry example:\n",
      "  ID: 0704.3504\n",
      "  Title: Smooth R\\'enyi Entropy of Ergodic Quantum Information Sources...\n",
      "  Categories: quant-ph cs.IT math.IT\n",
      "  Update Date: 2018-02-13\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import deque\n",
    "from pathlib import Path  # Assuming this might be used depending on file path needs\n",
    "from datetime import datetime\n",
    "from functools import partial # For creating picklable partial functions\n",
    "\n",
    "from tqdm.auto import tqdm   # For progress bars\n",
    "from joblib import Parallel, delayed # For parallel processing\n",
    "import os                    # For os.cpu_count()\n",
    "\n",
    "# --- Helper Function for Parallel Processing ---\n",
    "def _mp_process_line_for_filtering(line_validator_tuple):\n",
    "    \"\"\"\n",
    "    Parses a JSON line and applies a validator. Designed for use with multiprocessing/joblib.\n",
    "    Args:\n",
    "        line_validator_tuple (tuple): A tuple containing (line_content_string, validator_function).\n",
    "                                      validator_function can be None.\n",
    "    Returns:\n",
    "        object: The parsed and validated JSON object (dict) if valid, otherwise None.\n",
    "    \"\"\"\n",
    "    line_content, validator_func = line_validator_tuple\n",
    "    if not line_content.strip(): # Skip empty or whitespace-only lines\n",
    "        return None\n",
    "    try:\n",
    "        entry = json.loads(line_content)\n",
    "        if validator_func is None or validator_func(entry):\n",
    "            return entry  # Parsed and validated (or no validator)\n",
    "        return None  # Failed validation\n",
    "    except json.JSONDecodeError:\n",
    "        # Optionally, log this error or count parsing failures\n",
    "        # tqdm.write(f\"Warning: Could not parse line: {line_content[:100]}\")\n",
    "        return None  # Failed parsing\n",
    "\n",
    "# --- Validation Function ---\n",
    "def is_valid(entry, allowed_categories=None, allowed_major_categories=None,\n",
    "             allowed_minor_categories=None, start_date=None, end_date=None):\n",
    "    \"\"\"\n",
    "    Check if an ArXiv entry is valid based on categories and date range.\n",
    "    \"\"\"\n",
    "    # Category check\n",
    "    if any(x is not None for x in [allowed_categories, allowed_major_categories, allowed_minor_categories]):\n",
    "        entry_categories = entry.get('categories', '')\n",
    "        if not entry_categories:\n",
    "            return False\n",
    "\n",
    "        entry_cats = [cat.strip() for cat in entry_categories.split()]\n",
    "\n",
    "        if allowed_categories is not None:\n",
    "            if not any(cat in allowed_categories for cat in entry_cats):\n",
    "                return False\n",
    "\n",
    "        if allowed_major_categories is not None:\n",
    "            entry_majors = [cat.split('.')[0] if '.' in cat else cat for cat in entry_cats]\n",
    "            if not any(major in allowed_major_categories for major in entry_majors):\n",
    "                return False\n",
    "\n",
    "        if allowed_minor_categories is not None:\n",
    "            entry_minors = [cat.split('.')[1] if '.' in cat and len(cat.split('.')) > 1 else ''\n",
    "                           for cat in entry_cats]\n",
    "            entry_minors = [minor for minor in entry_minors if minor]\n",
    "            if not any(minor in allowed_minor_categories for minor in entry_minors):\n",
    "                return False\n",
    "\n",
    "    # Date check\n",
    "    if start_date is not None or end_date is not None:\n",
    "        update_date = entry.get('update_date', '')\n",
    "        if not update_date:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            entry_date = datetime.strptime(update_date, '%Y-%m-%d')\n",
    "\n",
    "            if start_date is not None:\n",
    "                start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "                if entry_date < start_dt:\n",
    "                    return False\n",
    "\n",
    "            if end_date is not None:\n",
    "                end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "                if entry_date > end_dt:\n",
    "                    return False\n",
    "        except ValueError:\n",
    "            # Invalid date format\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# --- Sampling Function (Serial version as provided previously) ---\n",
    "def sample_jsons(filename, n, method='first', seed=42, validator=None):\n",
    "    \"\"\"\n",
    "    Sample N entries from a JSON lines file. (Non-parallel version)\n",
    "    \"\"\"\n",
    "    if n == 0: return []\n",
    "    samples = []\n",
    "    if method == 'first':\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            pbar = tqdm(desc=f\"Finding first {n} valid entries\", total=n, unit=\"entry\")\n",
    "            for line in f:\n",
    "                if not line.strip(): continue\n",
    "                try:\n",
    "                    entry = json.loads(line)\n",
    "                    if validator is None or validator(entry):\n",
    "                        samples.append(entry)\n",
    "                        pbar.update(1)\n",
    "                        if len(samples) >= n: break\n",
    "                except json.JSONDecodeError: tqdm.write(f\"Skipping unparseable line in 'first': {line[:100]}\")\n",
    "            pbar.close()\n",
    "            if len(samples) < n: tqdm.write(f\"Warning: Found only {len(samples)} valid entries of {n} requested.\")\n",
    "        return samples\n",
    "    elif method == 'last':\n",
    "        samples_deque = deque(maxlen=n)\n",
    "        total_lines = None\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f_count: total_lines = sum(1 for _ in f_count)\n",
    "        except (IOError, OSError): pass\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            with tqdm(desc=f\"Scanning for last {n} valid entries\", total=total_lines, unit=\"line\") as pbar:\n",
    "                for line in f:\n",
    "                    pbar.update(1)\n",
    "                    if not line.strip(): continue\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        if validator is None or validator(entry): samples_deque.append(entry)\n",
    "                    except json.JSONDecodeError: tqdm.write(f\"Skipping unparseable line in 'last': {line[:100]}\")\n",
    "        return list(samples_deque)\n",
    "    elif method == 'random':\n",
    "        random.seed(seed)\n",
    "        samples = []\n",
    "        valid_items_seen = 0\n",
    "        total_lines = None\n",
    "        try:\n",
    "            with open(filename, 'r', encoding='utf-8') as f_count: total_lines = sum(1 for _ in f_count)\n",
    "        except (IOError, OSError): pass\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            with tqdm(desc=f\"Random sampling for {n} valid entries\", total=total_lines, unit=\"line\") as pbar:\n",
    "                for line in f:\n",
    "                    pbar.update(1)\n",
    "                    if not line.strip(): continue\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        if validator is None or validator(entry):\n",
    "                            valid_items_seen += 1\n",
    "                            if len(samples) < n: samples.append(entry)\n",
    "                            else:\n",
    "                                j = random.randint(0, valid_items_seen - 1)\n",
    "                                if j < n: samples[j] = entry\n",
    "                    except json.JSONDecodeError: tqdm.write(f\"Skipping unparseable line in 'random': {line[:100]}\")\n",
    "            if len(samples) < n: tqdm.write(f\"Warning: Found only {len(samples)} valid random entries of {n} requested.\")\n",
    "        return samples\n",
    "    else: raise ValueError(\"method must be 'first', 'last', or 'random'\")\n",
    "\n",
    "# --- Filtering for In-Memory Lists (Joblib version) ---\n",
    "def filter_jsons(json_list, validator_function, n_jobs=None):\n",
    "    \"\"\"\n",
    "    Filter a list of JSON objects (already in memory) in parallel using a validator function with joblib.\n",
    "    \"\"\"\n",
    "    if not json_list:\n",
    "        return []\n",
    "    if validator_function is None:\n",
    "        return list(json_list)\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1 # Default to all CPUs\n",
    "\n",
    "    # tqdm shows progress for creating delayed task objects\n",
    "    tasks = (delayed(validator_function)(item) for item in tqdm(json_list, desc=\"Preparing tasks for joblib filtering\", unit=\"entry\"))\n",
    "    \n",
    "    # For actual computation progress from joblib, set verbose in Parallel, e.g., verbose=5\n",
    "    is_valid_results = Parallel(n_jobs=n_jobs)(tasks)\n",
    "    \n",
    "    validated_items = []\n",
    "    for item, is_valid_flag in zip(json_list, is_valid_results):\n",
    "        if is_valid_flag:\n",
    "            validated_items.append(item)\n",
    "    return validated_items\n",
    "\n",
    "def read_and_filter_jsons(filename, validator_function, n_jobs=None, batch_size=2048):\n",
    "    \"\"\"\n",
    "    Reads a JSON lines file, filters its entries in parallel using joblib,\n",
    "    and returns a list of valid JSON objects. This is memory-efficient.\n",
    "    \"\"\"\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1 # Default to all CPUs\n",
    "\n",
    "    validated_jsons = []\n",
    "    total_lines = None\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as f_count:\n",
    "            total_lines = sum(1 for _line in f_count)\n",
    "    except (IOError, OSError) as e:\n",
    "        tqdm.write(f\"Info: Could not pre-count lines ({e}). Progress bar for total lines might be indeterminate.\")\n",
    "\n",
    "    pbar_desc = \"Reading & filtering (joblib)\"\n",
    "    if total_lines is not None:\n",
    "        pbar = tqdm(total=total_lines, desc=pbar_desc, unit=\"line\")\n",
    "    else:\n",
    "        pbar = tqdm(desc=pbar_desc, unit=\"line\")\n",
    "\n",
    "    # For joblib execution progress, you can set verbose, e.g., verbose=5\n",
    "    parallel_executor = Parallel(n_jobs=n_jobs)\n",
    "\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines_batch_for_processing = []\n",
    "        for line_content in f:\n",
    "            lines_batch_for_processing.append((line_content, validator_function))\n",
    "            if len(lines_batch_for_processing) >= batch_size:\n",
    "                try:\n",
    "                    tasks = (delayed(_mp_process_line_for_filtering)(item_tuple) for item_tuple in lines_batch_for_processing)\n",
    "                    batch_results = parallel_executor(tasks)\n",
    "                    for entry in batch_results:\n",
    "                        if entry:\n",
    "                            validated_jsons.append(entry)\n",
    "                except Exception as e:\n",
    "                    tqdm.write(f\"Error processing a batch with joblib: {e}\")\n",
    "                pbar.update(len(lines_batch_for_processing))\n",
    "                lines_batch_for_processing.clear()\n",
    "\n",
    "        if lines_batch_for_processing: # Process any remaining lines\n",
    "            try:\n",
    "                tasks = (delayed(_mp_process_line_for_filtering)(item_tuple) for item_tuple in lines_batch_for_processing)\n",
    "                batch_results = parallel_executor(tasks)\n",
    "                for entry in batch_results:\n",
    "                    if entry:\n",
    "                        validated_jsons.append(entry)\n",
    "            except Exception as e:\n",
    "                 tqdm.write(f\"Error processing the final batch with joblib: {e}\")\n",
    "            pbar.update(len(lines_batch_for_processing))\n",
    "    pbar.close()\n",
    "    return validated_jsons\n",
    "\n",
    "# --- Main Execution Block ---\n",
    "if __name__ == '__main__':\n",
    "    # Ensure this file exists or provide the correct path\n",
    "    # Download from: https://www.kaggle.com/datasets/Cornell-University/arxiv\n",
    "    # (or use a smaller JSON Lines test file)\n",
    "    json_lines_file = \"arxiv-metadata-oai-snapshot.json\" \n",
    "\n",
    "    if not Path(json_lines_file).is_file():\n",
    "        print(f\"Error: File '{json_lines_file}' not found.\")\n",
    "        print(\"Please download it or use a different JSON Lines file.\")\n",
    "        # Example of creating a dummy file for testing:\n",
    "        if not Path(\"dummy_arxiv_data.jsonl\").is_file():\n",
    "            print(\"Creating a small dummy_arxiv_data.jsonl for testing...\")\n",
    "            dummy_data = [\n",
    "                {\"id\": \"2001.00001\", \"title\": \"Paper CS 1\", \"categories\": \"cs.AI hep-th\", \"update_date\": \"2020-01-01\", \"abstract\": \"Abstract 1\"},\n",
    "                {\"id\": \"2001.00002\", \"title\": \"Paper Math 1\", \"categories\": \"math.CO cs.CG\", \"update_date\": \"2021-05-15\", \"abstract\": \"Abstract 2\"},\n",
    "                {\"id\": \"2002.00003\", \"title\": \"Paper CS 2\", \"categories\": \"cs.LG\", \"update_date\": \"2020-02-20\", \"abstract\": \"Abstract 3\"},\n",
    "                {\"id\": \"2023.00004\", \"title\": \"Paper CS 3 Recent\", \"categories\": \"cs.CV\", \"update_date\": \"2023-11-05\", \"abstract\": \"Abstract 4\"},\n",
    "                {\"id\": \"cond-mat.00005\", \"title\": \"Paper Phys\", \"categories\": \"cond-mat.stat-mech\", \"update_date\": \"2019-12-31\", \"abstract\": \"Abstract 5\"},\n",
    "            ]\n",
    "            with open(\"dummy_arxiv_data.jsonl\", \"w\") as f_dummy:\n",
    "                for item in dummy_data:\n",
    "                    f_dummy.write(json.dumps(item) + \"\\n\")\n",
    "            json_lines_file = \"dummy_arxiv_data.jsonl\" # Use dummy file if main one not found\n",
    "            print(f\"Using '{json_lines_file}' for this run.\")\n",
    "\n",
    "\n",
    "    # Create a picklable validator function using functools.partial\n",
    "    # This specific validator looks for 'cs' papers between 2020 and 2023.\n",
    "    validation_criteria = partial(is_valid,\n",
    "                                    allowed_major_categories=['cs'],\n",
    "                                    start_date='2018-01-01',\n",
    "                                    end_date='2025-05-20')\n",
    "\n",
    "    print(f\"\\nStarting efficient parallel reading and filtering of '{json_lines_file}' with joblib...\")\n",
    "    \n",
    "    # You can adjust n_jobs and batch_size for performance tuning\n",
    "    # n_jobs=-1 uses all available CPUs\n",
    "    # n_jobs=1 would be sequential (useful for debugging)\n",
    "    # batch_size affects how many lines are grouped for each parallel task submission\n",
    "    \n",
    "    all_valid_cs_papers = read_and_filter_jsons(\n",
    "        json_lines_file,\n",
    "        validator_function=validation_criteria,\n",
    "        n_jobs=-1, \n",
    "        batch_size=4096 # Increased batch_size can sometimes be better for very large files\n",
    "    )\n",
    "\n",
    "    print(f\"\\nFound {len(all_valid_cs_papers)} 'cs' papers from 2020-2023.\")\n",
    "    if all_valid_cs_papers:\n",
    "        print(f\"First valid entry example:\")\n",
    "        entry = all_valid_cs_papers[0]\n",
    "        print(f\"  ID: {entry.get('id', 'N/A')}\")\n",
    "        print(f\"  Title: {entry.get('title','N/A')[:80]}...\")\n",
    "        print(f\"  Categories: {entry.get('categories', 'N/A')}\")\n",
    "        print(f\"  Update Date: {entry.get('update_date', 'N/A')}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:57:03.599540Z",
     "start_time": "2025-05-26T14:54:19.503095Z"
    }
   },
   "id": "5222d32ba3979e78",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(all_valid_cs_papers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T14:58:15.351430Z",
     "start_time": "2025-05-26T14:57:58.274283Z"
    }
   },
   "id": "e13833792579b395",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['update_date'].max()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e07cf7fd0eee72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from src.json_utils import JsonUtils"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1ac655935301c898",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pexpect'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msystem\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpip install pexpect\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/l2d/.venvf/lib/python3.12/site-packages/ipykernel/zmqshell.py:657\u001B[39m, in \u001B[36msystem_piped\u001B[39m\u001B[34m(self, cmd)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/l2d/.venvf/lib/python3.12/site-packages/IPython/utils/_process_posix.py:98\u001B[39m, in \u001B[36msystem\u001B[39m\u001B[34m(self, cmd)\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'pexpect'"
     ]
    }
   ],
   "source": [
    "!pip install pexpect"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T15:15:03.563729Z",
     "start_time": "2025-05-26T15:15:03.528935Z"
    }
   },
   "id": "4e017be869cef6b7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m df = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m../data/clean/arxiv.json\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/.venv_final/lib/python3.11/site-packages/pandas/io/json/_json.py:815\u001B[39m, in \u001B[36mread_json\u001B[39m\u001B[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001B[39m\n\u001B[32m    813\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m json_reader\n\u001B[32m    814\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m815\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/.venv_final/lib/python3.11/site-packages/pandas/io/json/_json.py:1025\u001B[39m, in \u001B[36mJsonReader.read\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1023\u001B[39m         obj = \u001B[38;5;28mself\u001B[39m._get_object_parser(\u001B[38;5;28mself\u001B[39m._combine_lines(data_lines))\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1025\u001B[39m     obj = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.dtype_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib.no_default:\n\u001B[32m   1027\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m obj.convert_dtypes(\n\u001B[32m   1028\u001B[39m         infer_objects=\u001B[38;5;28;01mFalse\u001B[39;00m, dtype_backend=\u001B[38;5;28mself\u001B[39m.dtype_backend\n\u001B[32m   1029\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/.venv_final/lib/python3.11/site-packages/pandas/io/json/_json.py:1051\u001B[39m, in \u001B[36mJsonReader._get_object_parser\u001B[39m\u001B[34m(self, json)\u001B[39m\n\u001B[32m   1049\u001B[39m obj = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1050\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mframe\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1051\u001B[39m     obj = \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1053\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m typ == \u001B[33m\"\u001B[39m\u001B[33mseries\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1054\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, \u001B[38;5;28mbool\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/.venv_final/lib/python3.11/site-packages/pandas/io/json/_json.py:1187\u001B[39m, in \u001B[36mParser.parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1185\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m   1186\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1187\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1189\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1190\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/locresearch/LocResearch/ssl_wrapper/proj/ssl/.venv_final/lib/python3.11/site-packages/pandas/io/json/_json.py:1403\u001B[39m, in \u001B[36mFrameParser._parse\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1399\u001B[39m orient = \u001B[38;5;28mself\u001B[39m.orient\n\u001B[32m   1401\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1402\u001B[39m     \u001B[38;5;28mself\u001B[39m.obj = DataFrame(\n\u001B[32m-> \u001B[39m\u001B[32m1403\u001B[39m         \u001B[43mujson_loads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m, dtype=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1404\u001B[39m     )\n\u001B[32m   1405\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m orient == \u001B[33m\"\u001B[39m\u001B[33msplit\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1406\u001B[39m     decoded = {\n\u001B[32m   1407\u001B[39m         \u001B[38;5;28mstr\u001B[39m(k): v\n\u001B[32m   1408\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m ujson_loads(json, precise_float=\u001B[38;5;28mself\u001B[39m.precise_float).items()\n\u001B[32m   1409\u001B[39m     }\n",
      "\u001B[31mValueError\u001B[39m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"../data/clean/arxiv.json\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-26T16:21:57.155944Z",
     "start_time": "2025-05-26T16:21:56.972121Z"
    }
   },
   "id": "89d2eea2252b1f99",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e151c1e09ca895dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
